{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTT-Dx8R-LpL",
    "outputId": "22fcdf29-468b-420d-85cb-d83ed621f0b5"
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate==0.4.3\n",
    "# !pip install llama-cpp-python==0.1.9\n",
    "# !pip install pinecone-client==5.0.1\n",
    "# !pip install langchain_community==0.2.16\n",
    "# !pip install langchain-chroma==0.1.4\n",
    "# !pip install chromadb==0.5.11\n",
    "# !pip install sentence-transformers==3.1.1\n",
    "# !pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tcb0TE2y9o0S"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader, TextLoader, CSVLoader, UnstructuredWordDocumentLoader, UnstructuredHTMLLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from langchain_chroma.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n",
    "from llama_cpp import Llama\n",
    "from evaluate import load\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qlQsKNbjCsf5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pinecone\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYNkw_TjVs3E"
   },
   "source": [
    "#Лабораторная работа №5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yyAj72M9pSU"
   },
   "source": [
    "##Declaring constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "w2p_plKvbacZ"
   },
   "outputs": [],
   "source": [
    "path_to_index = '/content/VDB'\n",
    "path_to_documents = 'nlp-24-autumn/projects/dataset/20news-bydate-train/comp.graphics' #49960.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XyaoDfoC9bmT"
   },
   "outputs": [],
   "source": [
    "# Словарь, сопоставляющий расширения файлов с соответствующими загрузчиками данных и их параметрами\n",
    "LOADER_MAPPING = {\n",
    "    \".csv\": (CSVLoader, {}),\n",
    "    \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".html\": (UnstructuredHTMLLoader, {}),\n",
    "    \".pdf\": (PDFMinerLoader, {}),\n",
    "    \".txt\": (TextLoader, {\"encoding\": \"ISO-8859-1\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_kofnU15EBEf"
   },
   "outputs": [],
   "source": [
    "# Параметры конфигурации для векторного поиска и разделения текста\n",
    "INDEX_NAME = \"VDB\"  # Название индекса для хранения векторных представлений\n",
    "COLLECTION_NAME = \"document_collection\"\n",
    "EMBEDDINGS = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"  # Название модели эмбеддингов, используемой для векторизации текстов\n",
    "SIZE = 250  # Размер фрагмента текста для разделения документов\n",
    "OVERLAP = 50  # Перекрытие между фрагментами текста для обеспечения контекста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKhOsNCaC-ds"
   },
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Wuqy7ZApCS1-"
   },
   "outputs": [],
   "source": [
    "# Класс для загрузки документов из различных источников, поддерживающий работу с разными форматами файлов\n",
    "class Loader:\n",
    "    def load_single_document(self, file_path: str):\n",
    "        # Метод для загрузки одного документа на основе пути к файлу\n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        if ext in LOADER_MAPPING:\n",
    "            loader_class, loader_args = LOADER_MAPPING[ext]\n",
    "            loader_args['file_path'] = file_path;\n",
    "            loader = loader_class(**loader_args)\n",
    "            document = loader.load()\n",
    "            return document\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "    def load_documents(self, source_dir: str):\n",
    "        # Метод для загрузки всех документов из указанной директории\n",
    "        documents = []\n",
    "        if os.path.isfile(source_dir):\n",
    "          documents.extend(self.load_single_document(file_path))\n",
    "        else:\n",
    "          for root, _, files in os.walk(source_dir):\n",
    "              for file_name in files:\n",
    "                  file_path = os.path.join(root, file_name)\n",
    "                  try:\n",
    "                      document = self.load_single_document(file_path)\n",
    "                      documents.extend(document)\n",
    "                  except ValueError as e:\n",
    "                      print(e)\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4l1GR3fRVgR",
    "outputId": "b8c7cb80-ffc1-43df-e265-12e52add1f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "loader = Loader()\n",
    "\n",
    "example_document = loader.load_documents(path_to_documents)\n",
    "\n",
    "print(example_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDGCH3WV_A8p"
   },
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CvN9kIBmCyDJ"
   },
   "outputs": [],
   "source": [
    "# Класс для разделения документов на фрагменты определённого размера с заданным перекрытием\n",
    "class Splitter:\n",
    "    def __init__(self, chunk_size, chunk_overlap):\n",
    "        # Инициализация параметров разделения: размер фрагмента и величина перекрытия\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def split_documents(self, documents):\n",
    "        fragments = []\n",
    "        for document in documents:\n",
    "            text = document.page_content\n",
    "            doc_meta = document.metadata\n",
    "            start = 0\n",
    "\n",
    "            while start < len(text):\n",
    "                end = min(start + self.chunk_size, len(text))\n",
    "                fragment_text = text[start:end]\n",
    "\n",
    "                fragment = {\n",
    "                    \"text\": fragment_text,\n",
    "                    \"metadata\": doc_meta\n",
    "                }\n",
    "\n",
    "                fragments.append(fragment)\n",
    "                start += self.chunk_size - self.chunk_overlap\n",
    "\n",
    "        return fragments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLvATkgCiK_5",
    "outputId": "d28fd2bf-4001-45e5-bd61-b05e828c5349"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = Splitter(SIZE, OVERLAP)\n",
    "\n",
    "example_fragments = splitter.split_documents(example_document)\n",
    "\n",
    "example_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohzsSpJX9u3n"
   },
   "source": [
    "##Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "soiFkrEC_kPH"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Базовый класс для создания эмбеддингов, обеспечивающий интерфейс для получения модели эмбеддингов\n",
    "class Embedder:\n",
    "    def __init__(self, model_name: str):\n",
    "        # Инициализация эмбеддера\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def get_embedder(self):\n",
    "        # Метод для получения модели эмбеддингов, которая будет использоваться для векторизации текстов\n",
    "        return self.model\n",
    "\n",
    "    def encode(self, texts: list[dict]):\n",
    "        return self.model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "grQtAn0VDPqy"
   },
   "outputs": [],
   "source": [
    "class HuggingFaceEmbedder(Embedder):\n",
    "    def __init__(self):\n",
    "        super().__init__(EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taLZSFKbkbTh",
    "outputId": "2cb9c8d7-c85a-41ac-bed3-79f8685100aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbedder()\n",
    "\n",
    "example_embedded_fragments = embedder.encode(example_fragments)\n",
    "\n",
    "example_embedded_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDIqemV0dL_M"
   },
   "source": [
    "### Базовые классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "dn9FQiJd-8TP"
   },
   "outputs": [],
   "source": [
    "class Element():\n",
    "  def __init__(self, embedding, metadata):\n",
    "    self.embedding = embedding\n",
    "    self.metadata = metadata\n",
    "\n",
    "# Базовый класс для работы с коллекцией документов, поддерживающий добавление, поиск и очистку данных\n",
    "class Collector:\n",
    "    def __init__(self, splitter: Splitter, embedder: Embedder):\n",
    "        self.splitter = splitter\n",
    "        self.embedder = embedder\n",
    "        self.loader = Loader()\n",
    "        self.documents = []\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        # Метод для добавления текстов и связанных с ними метаданных в коллекцию\n",
    "        added_documents = []\n",
    "        embeddings = self.embedder.encode(texts)\n",
    "        for embedding, metadata in zip(embeddings, metadatas):\n",
    "            self.documents.append(Element(embedding=embedding, metadata=metadata))\n",
    "            added_documents.append(Element(embedding=embedding, metadata=metadata))\n",
    "        return added_documents\n",
    "\n",
    "    def add_from_directory(self, dir_path: str):\n",
    "        # Метод для добавления документов в коллекцию из указанной директории\n",
    "        documents = self.loader.load_documents(dir_path)\n",
    "        fragments = self.splitter.split_documents(documents)\n",
    "\n",
    "        texts = [fragment[\"text\"] for fragment in fragments]\n",
    "        metadatas = [{\"file_path\": fragment[\"metadata\"]} for fragment in fragments]\n",
    "\n",
    "        self.add(texts, metadatas)\n",
    "\n",
    "    def query_documents(self, embedding, top_k):\n",
    "        pass\n",
    "\n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "        norm1 = sum(a ** 2 for a in vec1) ** 0.5\n",
    "        norm2 = sum(b ** 2 for b in vec2) ** 0.5\n",
    "        return dot_product / (norm1 * norm2)\n",
    "\n",
    "    def get(self, search_strings: list[str], n_results: int) -> list[Document]:\n",
    "        # Метод для поиска документов по строкам запроса с ограничением на количество результатов\n",
    "        search_embeddings = self.embedder.encode(search_strings)\n",
    "        results = []\n",
    "        for search_embedding in search_embeddings:\n",
    "            result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "            results.extend(result_docs)\n",
    "        return results\n",
    "\n",
    "    def get_documents(self, search_string: str, n_results: int, score_threshold: float) -> list[Document]:\n",
    "        # Метод для поиска документов с учётом порога релевантности и количества возвращаемых результатов\n",
    "        search_embedding = self.embedder.encode([search_string])[0]\n",
    "        result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "        return [doc for doc in result_docs if doc.score >= score_threshold]\n",
    "\n",
    "    def clear(self):\n",
    "        # Метод для очистки коллекции документов\n",
    "        self.documents.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "C9T7ta-q_qDk"
   },
   "outputs": [],
   "source": [
    "class ChromaCollector(Collector):\n",
    "    def __init__(self, splitter: Splitter, embedder: HuggingFaceEmbedder):\n",
    "        super().__init__(splitter, embedder)\n",
    "        self.client = Client()\n",
    "        self.collection = self.client.get_or_create_collection(COLLECTION_NAME)\n",
    "        self.doc_id_counter = 0\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        added_documents = super().add(texts, metadatas)\n",
    "        print(added_documents)\n",
    "\n",
    "        embeddings = [doc.embedding.tolist() for doc in added_documents]\n",
    "        ids = [f\"id_{self.doc_id_counter + i}\" for i in range(len(added_documents))]\n",
    "        self.doc_id_counter += len(added_documents)\n",
    "\n",
    "        self.collection.add(\n",
    "            documents=texts,\n",
    "            embeddings=embeddings,\n",
    "            metadatas=[doc.metadata for doc in added_documents],\n",
    "            ids=ids\n",
    "        )\n",
    "\n",
    "    # def query_documents(self, embedding, top_k):\n",
    "    #     return self.collection.query(embedding, top_k=top_k)\n",
    "\n",
    "    def query_documents(self, embedding, top_k):\n",
    "        documents_with_scores = [(doc, self._cosine_similarity(embedding, doc.embedding)) for doc in self.collection]\n",
    "        documents_with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, score in documents_with_scores[:top_k]]\n",
    "\n",
    "    def clear(self):\n",
    "        super().clear()\n",
    "        self.client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJU4AdHrdXu8"
   },
   "source": [
    "### Класс Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "hqk-o5RA-97P"
   },
   "outputs": [],
   "source": [
    "# Базовый класс для работы с коллекцией документов, поддерживающий добавление, поиск и очистку данных\n",
    "class Collector:\n",
    "    def __init__(self, splitter: Splitter, embedder: Embedder):\n",
    "        self.splitter = splitter\n",
    "        self.embedder = embedder\n",
    "        self.loader = Loader()\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        # Метод для добавления текстов и связанных с ними метаданных в коллекцию\n",
    "        embeddings = self.embedder.encode(texts)\n",
    "        return [{\"embedding\": embedding, \"metadata\": metadata} for embedding, metadata in zip(embeddings, metadatas)]\n",
    "\n",
    "    def add_from_directory(self, dir_path: str):\n",
    "        # Метод для добавления документов в коллекцию из указанной директории\n",
    "        documents = self.loader.load_documents(dir_path)\n",
    "        fragments = self.splitter.split_documents(documents)\n",
    "\n",
    "        texts = [fragment[\"text\"] for fragment in fragments]\n",
    "        metadatas = [fragment[\"metadata\"] for fragment in fragments]\n",
    "        self.add(texts, metadatas)\n",
    "\n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "        norm1 = sum(a ** 2 for a in vec1) ** 0.5\n",
    "        norm2 = sum(b ** 2 for b in vec2) ** 0.5\n",
    "        return dot_product / (norm1 * norm2)\n",
    "\n",
    "    def query_documents(self, embedding, top_k):\n",
    "        pass\n",
    "\n",
    "    def get(self, search_strings: list[str], n_results: int) -> list[Document]:\n",
    "        # Метод для поиска документов по строкам запроса с ограничением на количество результатов\n",
    "        search_embeddings = self.embedder.encode(search_strings)\n",
    "        results = []\n",
    "        for search_embedding in search_embeddings:\n",
    "            result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "            results.extend(result_docs)\n",
    "        return results\n",
    "\n",
    "    def get_documents(self, search_string: str, n_results: int, score_threshold: float) -> list[Document]:\n",
    "        # Метод для поиска документов с учётом порога релевантности и количества возвращаемых результатов\n",
    "        search_embedding = self.embedder.encode([search_string])[0]\n",
    "        result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "        return [doc for doc in result_docs if doc.score >= score_threshold]\n",
    "\n",
    "\n",
    "class ChromaCollector(Collector):\n",
    "    def __init__(self, splitter: Splitter, embedder: HuggingFaceEmbedder):\n",
    "        super().__init__(splitter, embedder)\n",
    "        self.client = Client()\n",
    "        self.collection = self.client.get_or_create_collection(COLLECTION_NAME)\n",
    "        self.doc_id_counter = 0\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        # Добавляем документы с их эмбеддингами и метаданными в коллекцию\n",
    "        added_documents = super().add(texts, metadatas)\n",
    "        embeddings = np.array([doc[\"embedding\"] for doc in added_documents]).astype(\"float32\")\n",
    "\n",
    "        ids = [f\"id_{self.doc_id_counter + i}\" for i in range(len(added_documents))]\n",
    "        self.doc_id_counter += len(added_documents)\n",
    "\n",
    "        self.collection.add(\n",
    "            documents=texts,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=[doc[\"metadata\"] for doc in added_documents],\n",
    "            ids=ids\n",
    "        )\n",
    "\n",
    "    def query_documents(self, query_embedding, top_k: int):\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "\n",
    "        ids = results['ids'][0]\n",
    "        distances = results['distances'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        documents = results['documents'][0]\n",
    "\n",
    "        results_list = []\n",
    "        for i in range(len(ids)):\n",
    "            results_list.append({\n",
    "                \"id\": ids[i],\n",
    "                \"distance\": distances[i],\n",
    "                \"metadata\": metadatas[i],\n",
    "                \"document\": documents[i]\n",
    "            })\n",
    "\n",
    "        return results_list\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XXhGdIuDmUU"
   },
   "source": [
    "###Implementation vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "h8xU0gGbERSk"
   },
   "outputs": [],
   "source": [
    "# path_to_index = '/content/VDB' #@param {type:\"string\"}\n",
    "# path_to_documents = '/content/tmp' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "v631_WnyDMUw"
   },
   "outputs": [],
   "source": [
    "#Нужно написать реализацию векторной базы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP4n4OAZ_VuG"
   },
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E6s-niuuIlqB"
   },
   "outputs": [],
   "source": [
    "query = 'How can I clean a suede jacket?' #@param {type:\"string\"}\n",
    "n_results = 5 #@param {type:\"integer\"}\n",
    "score_threshold = 0.5 # @param {type:\"slider\", min:0, max:1, step:0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7YvW8XXaL-H",
    "outputId": "e0786226-6da4-456f-fa13-03382ba4a2af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'id_0',\n",
       "  'distance': 8.915149688720703,\n",
       "  'metadata': {'file_path': 'dir_1'},\n",
       "  'document': 'The sun is an average star.'},\n",
       " {'id': 'id_3',\n",
       "  'distance': 14.08548355102539,\n",
       "  'metadata': {'file_path': 'dir_4'},\n",
       "  'document': 'The galaxy is vast and full of stars.'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Нужно реализовать эксперимент по поиску в векторном индексе\n",
    "example_splitter = Splitter(SIZE, OVERLAP)\n",
    "example_embedder = HuggingFaceEmbedder()\n",
    "exampple_collector = ChromaCollector(splitter, embedder)\n",
    "\n",
    "exampple_collector.clear()\n",
    "exampple_collector = ChromaCollector(example_splitter, example_embedder)\n",
    "\n",
    "exaple_documents = [\n",
    "        \"The sun is an average star.\",\n",
    "        \"The moon orbits the Earth.\",\n",
    "        \"I enjoy cooking and baking.\",\n",
    "        \"The galaxy is vast and full of stars.\",\n",
    "        \"Artificial intelligence is transforming industries.\"\n",
    "    ]\n",
    "\n",
    "example_metadatas = [\n",
    "    {'file_path': 'dir_1'},\n",
    "    {'file_path': 'dir_2'},\n",
    "    {'file_path': 'dir_3'},\n",
    "    {'file_path': 'dir_4'},\n",
    "    {'file_path': 'dir_5'},\n",
    "    ]\n",
    "\n",
    "\n",
    "exampple_collector.add(exaple_documents, example_metadatas)\n",
    "exampple_collector.collection.peek()\n",
    "\n",
    "example_query = \"What is sun?\"\n",
    "example_query_embedding = embedder.encode([example_query])[0]\n",
    "exampple_collector.query_documents(example_query_embedding, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "EYWiLay4cqBR"
   },
   "outputs": [],
   "source": [
    "splitter = Splitter(SIZE, OVERLAP)\n",
    "embedder = HuggingFaceEmbedder()\n",
    "collector = ChromaCollector(splitter, embedder)\n",
    "\n",
    "collector.clear()\n",
    "collector = ChromaCollector(splitter, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "iBsTDaKFgS6v"
   },
   "outputs": [],
   "source": [
    "path_to_documents = '../../dataset/20news-bydate-train/comp.graphics'\n",
    "\n",
    "collector.add_from_directory(path_to_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YARkyirkv3wO",
    "outputId": "a4b56270-16f4-4a56-d726-d18d7e07d358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id_0',\n",
       "  'id_1',\n",
       "  'id_2',\n",
       "  'id_3',\n",
       "  'id_4',\n",
       "  'id_5',\n",
       "  'id_6',\n",
       "  'id_7',\n",
       "  'id_8',\n",
       "  'id_9',\n",
       "  'id_10',\n",
       "  'id_11',\n",
       "  'id_12',\n",
       "  'id_13',\n",
       "  'id_14',\n",
       "  'id_15',\n",
       "  'id_16',\n",
       "  'id_17',\n",
       "  'id_18',\n",
       "  'id_19',\n",
       "  'id_20',\n",
       "  'id_21',\n",
       "  'id_22',\n",
       "  'id_23',\n",
       "  'id_24',\n",
       "  'id_25',\n",
       "  'id_26',\n",
       "  'id_27',\n",
       "  'id_28',\n",
       "  'id_29',\n",
       "  'id_30',\n",
       "  'id_31',\n",
       "  'id_32',\n",
       "  'id_33',\n",
       "  'id_34',\n",
       "  'id_35',\n",
       "  'id_36',\n",
       "  'id_37',\n",
       "  'id_38',\n",
       "  'id_39',\n",
       "  'id_40',\n",
       "  'id_41',\n",
       "  'id_42',\n",
       "  'id_43',\n",
       "  'id_44',\n",
       "  'id_45',\n",
       "  'id_46',\n",
       "  'id_47',\n",
       "  'id_48',\n",
       "  'id_49',\n",
       "  'id_50',\n",
       "  'id_51',\n",
       "  'id_52',\n",
       "  'id_53',\n",
       "  'id_54',\n",
       "  'id_55',\n",
       "  'id_56',\n",
       "  'id_57',\n",
       "  'id_58',\n",
       "  'id_59',\n",
       "  'id_60',\n",
       "  'id_61',\n",
       "  'id_62',\n",
       "  'id_63',\n",
       "  'id_64',\n",
       "  'id_65',\n",
       "  'id_66',\n",
       "  'id_67',\n",
       "  'id_68',\n",
       "  'id_69',\n",
       "  'id_70',\n",
       "  'id_71',\n",
       "  'id_72',\n",
       "  'id_73',\n",
       "  'id_74',\n",
       "  'id_75',\n",
       "  'id_76',\n",
       "  'id_77',\n",
       "  'id_78',\n",
       "  'id_79',\n",
       "  'id_80',\n",
       "  'id_81',\n",
       "  'id_82',\n",
       "  'id_83',\n",
       "  'id_84',\n",
       "  'id_85',\n",
       "  'id_86',\n",
       "  'id_87',\n",
       "  'id_88',\n",
       "  'id_89',\n",
       "  'id_90',\n",
       "  'id_91',\n",
       "  'id_92',\n",
       "  'id_93',\n",
       "  'id_94',\n",
       "  'id_95',\n",
       "  'id_96',\n",
       "  'id_97',\n",
       "  'id_98',\n",
       "  'id_99',\n",
       "  'id_100',\n",
       "  'id_101',\n",
       "  'id_102',\n",
       "  'id_103',\n",
       "  'id_104',\n",
       "  'id_105',\n",
       "  'id_106',\n",
       "  'id_107',\n",
       "  'id_108',\n",
       "  'id_109',\n",
       "  'id_110',\n",
       "  'id_111',\n",
       "  'id_112',\n",
       "  'id_113',\n",
       "  'id_114',\n",
       "  'id_115',\n",
       "  'id_116',\n",
       "  'id_117',\n",
       "  'id_118',\n",
       "  'id_119',\n",
       "  'id_120',\n",
       "  'id_121',\n",
       "  'id_122',\n",
       "  'id_123',\n",
       "  'id_124',\n",
       "  'id_125',\n",
       "  'id_126',\n",
       "  'id_127',\n",
       "  'id_128',\n",
       "  'id_129',\n",
       "  'id_130',\n",
       "  'id_131',\n",
       "  'id_132',\n",
       "  'id_133',\n",
       "  'id_134',\n",
       "  'id_135',\n",
       "  'id_136',\n",
       "  'id_137',\n",
       "  'id_138',\n",
       "  'id_139',\n",
       "  'id_140',\n",
       "  'id_141',\n",
       "  'id_142',\n",
       "  'id_143',\n",
       "  'id_144',\n",
       "  'id_145',\n",
       "  'id_146',\n",
       "  'id_147',\n",
       "  'id_148',\n",
       "  'id_149',\n",
       "  'id_150',\n",
       "  'id_151',\n",
       "  'id_152',\n",
       "  'id_153',\n",
       "  'id_154',\n",
       "  'id_155',\n",
       "  'id_156',\n",
       "  'id_157',\n",
       "  'id_158',\n",
       "  'id_159',\n",
       "  'id_160',\n",
       "  'id_161',\n",
       "  'id_162',\n",
       "  'id_163',\n",
       "  'id_164',\n",
       "  'id_165',\n",
       "  'id_166',\n",
       "  'id_167',\n",
       "  'id_168',\n",
       "  'id_169',\n",
       "  'id_170',\n",
       "  'id_171',\n",
       "  'id_172',\n",
       "  'id_173',\n",
       "  'id_174',\n",
       "  'id_175',\n",
       "  'id_176',\n",
       "  'id_177',\n",
       "  'id_178',\n",
       "  'id_179',\n",
       "  'id_180',\n",
       "  'id_181',\n",
       "  'id_182',\n",
       "  'id_183',\n",
       "  'id_184',\n",
       "  'id_185',\n",
       "  'id_186',\n",
       "  'id_187',\n",
       "  'id_188',\n",
       "  'id_189',\n",
       "  'id_190',\n",
       "  'id_191',\n",
       "  'id_192',\n",
       "  'id_193',\n",
       "  'id_194',\n",
       "  'id_195',\n",
       "  'id_196',\n",
       "  'id_197',\n",
       "  'id_198',\n",
       "  'id_199',\n",
       "  'id_200',\n",
       "  'id_201',\n",
       "  'id_202',\n",
       "  'id_203',\n",
       "  'id_204',\n",
       "  'id_205',\n",
       "  'id_206',\n",
       "  'id_207',\n",
       "  'id_208',\n",
       "  'id_209',\n",
       "  'id_210',\n",
       "  'id_211',\n",
       "  'id_212',\n",
       "  'id_213',\n",
       "  'id_214',\n",
       "  'id_215',\n",
       "  'id_216',\n",
       "  'id_217',\n",
       "  'id_218',\n",
       "  'id_219',\n",
       "  'id_220',\n",
       "  'id_221',\n",
       "  'id_222',\n",
       "  'id_223',\n",
       "  'id_224',\n",
       "  'id_225',\n",
       "  'id_226',\n",
       "  'id_227',\n",
       "  'id_228',\n",
       "  'id_229',\n",
       "  'id_230',\n",
       "  'id_231',\n",
       "  'id_232',\n",
       "  'id_233',\n",
       "  'id_234',\n",
       "  'id_235',\n",
       "  'id_236',\n",
       "  'id_237',\n",
       "  'id_238',\n",
       "  'id_239',\n",
       "  'id_240',\n",
       "  'id_241',\n",
       "  'id_242',\n",
       "  'id_243',\n",
       "  'id_244',\n",
       "  'id_245',\n",
       "  'id_246',\n",
       "  'id_247',\n",
       "  'id_248',\n",
       "  'id_249',\n",
       "  'id_250',\n",
       "  'id_251',\n",
       "  'id_252',\n",
       "  'id_253',\n",
       "  'id_254',\n",
       "  'id_255',\n",
       "  'id_256',\n",
       "  'id_257',\n",
       "  'id_258',\n",
       "  'id_259',\n",
       "  'id_260',\n",
       "  'id_261',\n",
       "  'id_262',\n",
       "  'id_263',\n",
       "  'id_264',\n",
       "  'id_265',\n",
       "  'id_266',\n",
       "  'id_267',\n",
       "  'id_268',\n",
       "  'id_269',\n",
       "  'id_270',\n",
       "  'id_271',\n",
       "  'id_272',\n",
       "  'id_273',\n",
       "  'id_274',\n",
       "  'id_275',\n",
       "  'id_276',\n",
       "  'id_277',\n",
       "  'id_278',\n",
       "  'id_279',\n",
       "  'id_280',\n",
       "  'id_281',\n",
       "  'id_282',\n",
       "  'id_283',\n",
       "  'id_284',\n",
       "  'id_285',\n",
       "  'id_286',\n",
       "  'id_287',\n",
       "  'id_288',\n",
       "  'id_289',\n",
       "  'id_290',\n",
       "  'id_291',\n",
       "  'id_292',\n",
       "  'id_293',\n",
       "  'id_294',\n",
       "  'id_295',\n",
       "  'id_296',\n",
       "  'id_297',\n",
       "  'id_298',\n",
       "  'id_299',\n",
       "  'id_300',\n",
       "  'id_301',\n",
       "  'id_302',\n",
       "  'id_303',\n",
       "  'id_304',\n",
       "  'id_305',\n",
       "  'id_306',\n",
       "  'id_307',\n",
       "  'id_308',\n",
       "  'id_309',\n",
       "  'id_310',\n",
       "  'id_311',\n",
       "  'id_312',\n",
       "  'id_313',\n",
       "  'id_314',\n",
       "  'id_315',\n",
       "  'id_316',\n",
       "  'id_317',\n",
       "  'id_318',\n",
       "  'id_319',\n",
       "  'id_320',\n",
       "  'id_321',\n",
       "  'id_322',\n",
       "  'id_323',\n",
       "  'id_324',\n",
       "  'id_325',\n",
       "  'id_326',\n",
       "  'id_327',\n",
       "  'id_328',\n",
       "  'id_329',\n",
       "  'id_330',\n",
       "  'id_331',\n",
       "  'id_332',\n",
       "  'id_333',\n",
       "  'id_334',\n",
       "  'id_335',\n",
       "  'id_336',\n",
       "  'id_337',\n",
       "  'id_338',\n",
       "  'id_339',\n",
       "  'id_340',\n",
       "  'id_341',\n",
       "  'id_342',\n",
       "  'id_343',\n",
       "  'id_344',\n",
       "  'id_345',\n",
       "  'id_346',\n",
       "  'id_347',\n",
       "  'id_348',\n",
       "  'id_349',\n",
       "  'id_350',\n",
       "  'id_351',\n",
       "  'id_352',\n",
       "  'id_353',\n",
       "  'id_354',\n",
       "  'id_355',\n",
       "  'id_356',\n",
       "  'id_357',\n",
       "  'id_358',\n",
       "  'id_359',\n",
       "  'id_360',\n",
       "  'id_361',\n",
       "  'id_362',\n",
       "  'id_363',\n",
       "  'id_364',\n",
       "  'id_365',\n",
       "  'id_366',\n",
       "  'id_367',\n",
       "  'id_368',\n",
       "  'id_369',\n",
       "  'id_370',\n",
       "  'id_371',\n",
       "  'id_372',\n",
       "  'id_373',\n",
       "  'id_374',\n",
       "  'id_375',\n",
       "  'id_376',\n",
       "  'id_377',\n",
       "  'id_378',\n",
       "  'id_379',\n",
       "  'id_380',\n",
       "  'id_381',\n",
       "  'id_382',\n",
       "  'id_383',\n",
       "  'id_384',\n",
       "  'id_385',\n",
       "  'id_386',\n",
       "  'id_387',\n",
       "  'id_388',\n",
       "  'id_389',\n",
       "  'id_390',\n",
       "  'id_391',\n",
       "  'id_392',\n",
       "  'id_393',\n",
       "  'id_394',\n",
       "  'id_395',\n",
       "  'id_396',\n",
       "  'id_397',\n",
       "  'id_398',\n",
       "  'id_399',\n",
       "  'id_400',\n",
       "  'id_401',\n",
       "  'id_402',\n",
       "  'id_403',\n",
       "  'id_404',\n",
       "  'id_405',\n",
       "  'id_406',\n",
       "  'id_407',\n",
       "  'id_408',\n",
       "  'id_409',\n",
       "  'id_410',\n",
       "  'id_411',\n",
       "  'id_412',\n",
       "  'id_413',\n",
       "  'id_414',\n",
       "  'id_415',\n",
       "  'id_416',\n",
       "  'id_417',\n",
       "  'id_418',\n",
       "  'id_419',\n",
       "  'id_420',\n",
       "  'id_421',\n",
       "  'id_422',\n",
       "  'id_423',\n",
       "  'id_424',\n",
       "  'id_425',\n",
       "  'id_426',\n",
       "  'id_427',\n",
       "  'id_428',\n",
       "  'id_429',\n",
       "  'id_430',\n",
       "  'id_431',\n",
       "  'id_432',\n",
       "  'id_433',\n",
       "  'id_434',\n",
       "  'id_435',\n",
       "  'id_436',\n",
       "  'id_437',\n",
       "  'id_438',\n",
       "  'id_439',\n",
       "  'id_440',\n",
       "  'id_441',\n",
       "  'id_442',\n",
       "  'id_443',\n",
       "  'id_444',\n",
       "  'id_445',\n",
       "  'id_446',\n",
       "  'id_447',\n",
       "  'id_448',\n",
       "  'id_449',\n",
       "  'id_450',\n",
       "  'id_451',\n",
       "  'id_452',\n",
       "  'id_453',\n",
       "  'id_454',\n",
       "  'id_455',\n",
       "  'id_456',\n",
       "  'id_457',\n",
       "  'id_458',\n",
       "  'id_459',\n",
       "  'id_460',\n",
       "  'id_461',\n",
       "  'id_462',\n",
       "  'id_463',\n",
       "  'id_464',\n",
       "  'id_465',\n",
       "  'id_466',\n",
       "  'id_467',\n",
       "  'id_468',\n",
       "  'id_469',\n",
       "  'id_470',\n",
       "  'id_471',\n",
       "  'id_472',\n",
       "  'id_473',\n",
       "  'id_474',\n",
       "  'id_475',\n",
       "  'id_476',\n",
       "  'id_477',\n",
       "  'id_478',\n",
       "  'id_479',\n",
       "  'id_480',\n",
       "  'id_481',\n",
       "  'id_482',\n",
       "  'id_483',\n",
       "  'id_484',\n",
       "  'id_485',\n",
       "  'id_486',\n",
       "  'id_487',\n",
       "  'id_488',\n",
       "  'id_489',\n",
       "  'id_490',\n",
       "  'id_491',\n",
       "  'id_492',\n",
       "  'id_493',\n",
       "  'id_494',\n",
       "  'id_495',\n",
       "  'id_496',\n",
       "  'id_497',\n",
       "  'id_498',\n",
       "  'id_499'],\n",
       " 'embeddings': array([[-0.01149617,  0.13666891, -0.00736219, ...,  0.07257432,\n",
       "          0.00251686, -0.07353766],\n",
       "        [-0.05519525,  0.18154635, -0.00701501, ...,  0.05791618,\n",
       "         -0.01641907, -0.07594189],\n",
       "        [-0.06808887,  0.18346055, -0.00509683, ...,  0.08209143,\n",
       "         -0.02802497, -0.07115914],\n",
       "        ...,\n",
       "        [-0.11704443,  0.00651415, -0.00097091, ...,  0.06881984,\n",
       "          0.02436668, -0.08789244],\n",
       "        [-0.03479959,  0.12134106, -0.00505865, ..., -0.03756469,\n",
       "         -0.13497823, -0.13300574],\n",
       "        [ 0.04876032, -0.01347778, -0.0035294 , ..., -0.02978631,\n",
       "         -0.16223983, -0.16186196]]),\n",
       " 'metadatas': [{'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37261.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37913.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37913.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37913.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37913.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37914.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37915.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37916.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37916.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37916.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37916.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37917.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37918.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37918.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37918.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37921.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37921.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37921.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37921.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37921.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37923.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37923.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37923.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37923.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37923.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37924.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37924.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37924.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37924.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37924.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37925.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37925.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37925.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37925.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37926.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37926.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37926.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37926.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37927.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37928.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37929.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37929.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37929.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37929.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37930.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37930.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37930.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37930.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37930.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37932.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37932.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37932.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37932.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37932.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37933.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37933.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37933.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37934.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37934.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37934.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37934.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37936.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37936.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37937.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37938.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37938.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37938.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37939.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37939.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37939.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37940.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37940.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37941.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37941.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37941.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37942.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37942.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37942.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37943.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37944.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37945.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37945.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37945.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37945.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37946.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37946.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37946.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37946.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37947.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37947.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37948.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37950.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37951.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37951.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37951.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37951.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37951.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37952.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37952.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37952.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37952.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37953.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37953.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37953.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37953.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37953.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37954.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37954.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37954.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37955.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37956.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37956.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37956.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37957.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37957.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37957.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37957.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37957.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37958.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37958.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37958.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37959.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37959.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37959.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37959.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37959.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37960.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37960.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37960.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37960.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37960.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37961.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37962.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37962.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37962.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37963.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37963.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37963.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37963.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38099.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38099.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38099.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38099.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38099.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38214.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38214.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38214.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38215.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38215.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38215.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38215.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38216.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38216.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38216.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38216.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38216.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38217.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38217.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38217.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38217.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38218.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38219.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38219.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38219.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38219.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38220.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38220.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38220.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38221.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38221.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38222.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38222.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38222.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38222.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38223.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38224.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38225.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38226.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38227.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38228.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38228.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38228.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38228.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38230.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38231.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38231.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38232.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38233.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38234.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38235.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38235.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38235.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38237.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38238.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38238.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38238.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38239.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38239.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38239.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38239.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38239.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38240.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38240.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38240.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38240.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38241.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38241.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38241.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38241.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38241.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38242.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38242.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38242.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38242.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38242.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38243.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38243.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38243.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38244.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38245.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38245.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38245.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38245.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38246.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38246.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38246.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38246.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38246.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38247.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38247.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38247.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38247.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'},\n",
       "  {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'}],\n",
       " 'documents': ['From: lipman@oasys.dt.navy.mil (Robert Lipman)\\nSubject: CALL FOR PRESENTATIONS: Navy SciViz/VR Seminar\\nArticle-I.D.: oasys.32850\\nExpires: 30 Apr 93 04:00:00 GMT\\nReply-To: lipman@oasys.dt.navy.mil (Robert Lipman)\\nDistribution: usa\\nOrganization: Carder',\n",
       "  'ert Lipman)\\nDistribution: usa\\nOrganization: Carderock Division, NSWC, Bethesda, MD\\nLines: 65\\n\\n\\n\\t\\t\\tCALL FOR PRESENTATIONS\\n\\t\\n      NAVY SCIENTIFIC VISUALIZATION AND VIRTUAL REALITY SEMINAR\\n\\n\\t\\t\\tTuesday, June 22, 1993\\n\\n\\t    Carderock Division, Naval Surf',\n",
       "  'June 22, 1993\\n\\n\\t    Carderock Division, Naval Surface Warfare Center\\n\\t      (formerly the David Taylor Research Center)\\n\\t\\t\\t  Bethesda, Maryland\\n\\nSPONSOR: NESS (Navy Engineering Software System) is sponsoring a \\none-day Navy Scientific Visualization a',\n",
       "  'nsoring a \\none-day Navy Scientific Visualization and Virtual Reality Seminar.  \\nThe purpose of the seminar is to present and exchange information for\\nNavy-related scientific visualization and virtual reality programs, \\nresearch, developments, and app',\n",
       "  'reality programs, \\nresearch, developments, and applications.\\n\\nPRESENTATIONS: Presentations are solicited on all aspects of \\nNavy-related scientific visualization and virtual reality.  All \\ncurrent work, works-in-progress, and proposed work by Navy \\no',\n",
       "  'k, works-in-progress, and proposed work by Navy \\norganizations will be considered.  Four types of presentations are \\navailable.\\n\\n     1. Regular presentation: 20-30 minutes in length\\n     2. Short presentation: 10 minutes in length\\n     3. Video pres',\n",
       "  'sentation: 10 minutes in length\\n     3. Video presentation: a stand-alone videotape (author need not \\n\\tattend the seminar)\\n     4. Scientific visualization or virtual reality demonstration (BYOH)\\n\\nAccepted presentations will not be published in any p',\n",
       "  'epted presentations will not be published in any proceedings, \\nhowever, viewgraphs and other materials will be reproduced for \\nseminar attendees.\\n\\nABSTRACTS: Authors should submit a one page abstract and/or videotape to:\\n\\n     Robert Lipman\\n     Nava',\n",
       "  'and/or videotape to:\\n\\n     Robert Lipman\\n     Naval Surface Warfare Center, Carderock Division\\n     Code 2042\\n     Bethesda, Maryland  20084-5000\\n\\n     VOICE (301) 227-3618;  FAX (301) 227-5753  \\n     E-MAIL  lipman@oasys.dt.navy.mil\\n\\nAuthors should ',\n",
       "  ' E-MAIL  lipman@oasys.dt.navy.mil\\n\\nAuthors should include the type of presentation, their affiliations, \\naddresses, telephone and FAX numbers, and addresses.  Multi-author \\npapers should designate one point of contact.\\n\\nDEADLINES: The abstact submiss',\n",
       "  ' point of contact.\\n\\nDEADLINES: The abstact submission deadline is April 30, 1993.  \\nNotification of acceptance will be sent by May 14, 1993.  \\nMaterials for reproduction must be received by June 1, 1993.\\n\\nFor further information, contact Robert Lipma',\n",
       "  '93.\\n\\nFor further information, contact Robert Lipman at the above address.\\n\\n\\t  PLEASE DISTRIBUTE AS WIDELY AS POSSIBLE, THANKS.\\n\\n\\n\\n\\nRobert Lipman                     | Internet: lipman@oasys.dt.navy.mil\\nDavid Taylor Model Basin - CDNSWC |       or: li',\n",
       "  'l\\nDavid Taylor Model Basin - CDNSWC |       or: lip@ocean.dt.navy.mil\\nComputational Signatures and      | Voicenet: (301) 227-3618\\n   Structures Group, Code 2042    | Factsnet: (301) 227-5753\\nBethesda, Maryland  20084-5000    | Phishnet: stockings@lo',\n",
       "  \", Maryland  20084-5000    | Phishnet: stockings@long.legs\\n\\t\\t\\t\\t   \\nThe sixth sick shiek's sixth sheep's sick.\\n\",\n",
       "  'From: weston@ucssun1.sdsu.edu (weston t)\\nSubject: graphical representation of vector-valued functions\\nOrganization: SDSU Computing Services\\nLines: 13\\nNNTP-Posting-Host: ucssun1.sdsu.edu\\n\\ngnuplot, etc. make it easy to plot real valued functions of 2 v',\n",
       "  ' make it easy to plot real valued functions of 2 variables\\nbut I want to plot functions whose values are 2-vectors. I have been \\ndoing this by plotting arrays of arrows (complete with arrowheads) but\\nbefore going further, I thought I would ask whethe',\n",
       "  'before going further, I thought I would ask whether someone has already\\ndone the work. Any pointers??\\n\\nthanx in advance\\n\\n\\nTom Weston                    | USENET: weston@ucssun1.sdsu.edu\\nDepartment of Philosophy      | (619) 594-6218 (office)\\nSan Dieg',\n",
       "  'Philosophy      | (619) 594-6218 (office)\\nSan Diego State Univ.         | (619) 575-7477 (home)\\nSan Diego, CA 92182-0303      | \\n',\n",
       "  'From: rap@coconut.cis.ufl.edu (Ryan Porter)\\nSubject: Re: DMORPH\\nArticle-I.D.: snoopy.1pqlhnINN8k1\\nOrganization: Univ. of Florida CIS Dept.\\nLines: 34\\nNNTP-Posting-Host: coconut.cis.ufl.edu\\n\\nIn article <1993Apr3.183303.6442@usl.edu> jna8182@ucs.usl.edu',\n",
       "  \"<1993Apr3.183303.6442@usl.edu> jna8182@ucs.usl.edu (Armstrong Jay N) writes:\\n>Can someone please tell me where I can ftp DTA or DMORPH?\\n\\nDMorf (Dave's Morph, I think is what it means) and DTax (Dave's \\nTGA Assembler) are available in the MSDOS_UPLOAD\",\n",
       "  ' \\nTGA Assembler) are available in the MSDOS_UPLOADS directory\\non the wuarchive.\\n\\nThey are arjed and bundled with their respective xmemory versions,\\ndmorfx.exe and dtax.exe, you can also find a version of aaplay.exe\\nthere, with which you can view file',\n",
       "  ' of aaplay.exe\\nthere, with which you can view files you create with dta.exe or\\ndtax.exe.\\n\\nI downloaded the whole bunch last week and have been morphing \\naway the afternoons since.  The programmes are all a bit buggy and\\ndefinitely not-ready-to-spread',\n",
       "  'all a bit buggy and\\ndefinitely not-ready-to-spread-to-the-masses, but they are very\\nwell written. \\n\\nThe interface is frustrating at first, but it gets easy once you\\nfigure out the tricks.\\n\\nI have noticed that dmorfx will crash horribly if you try to ',\n",
       "  \"ced that dmorfx will crash horribly if you try to morph\\nwithout using the splines option.  Not sure why, since I don't have\\nthe source.  I think it was written for TP 6.0.\\n\\nIf anyone else comes up with any other hints on getting the thing \\nto work ri\",\n",
       "  'h any other hints on getting the thing \\nto work right, tell me; it took me several hours the first time\\njust to figure out that if I just used the durned splines then \\nit would work...\\n\\n>JNA\\n>jna8182@usl.edu\\n\\n-Ryan\\nrap@cis.ufl.edu\\n',\n",
       "  'usl.edu\\n\\n-Ryan\\nrap@cis.ufl.edu\\n',\n",
       "  'From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinckley)\\nSubject:   VOICE INPUT -- vendor information needed\\nReply-To: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinckley)\\nOrganization: University of Virginia\\nLines: 27\\n\\n\\nHello,\\n     I am looking to add voice inp',\n",
       "  'es: 27\\n\\n\\nHello,\\n     I am looking to add voice input capability to a user interface I am\\ndeveloping on an HP730 (UNIX) workstation.  I would greatly appreciate \\ninformation anyone would care to offer about voice input systems that are \\neasily accessi',\n",
       "  'about voice input systems that are \\neasily accessible from the UNIX environment. \\n\\n     The names or adresses of applicable vendors, as well as any \\nexperiences you have had with specific systems, would be very helpful.\\n\\n     Please respond via email',\n",
       "  \"ld be very helpful.\\n\\n     Please respond via email; I will post a summary if there is \\nsufficient interest.\\n\\n\\nThanks,\\nKen\\n\\n\\nP.S.  I have found several impressive systems for IBM PC's, but I would \\nlike to avoid the hassle of purchasing and maintainin\",\n",
       "  'e to avoid the hassle of purchasing and maintaining a separate PC if \\nat all possible.\\n\\n-------------------------------------------------------------------------------\\nKen Hinckley (kph2q@virginia.edu)\\nUniversity of Virginia \\nNeurosurgical Visualizat',\n",
       "  ')\\nUniversity of Virginia \\nNeurosurgical Visualization Laboratory\\n-------------------------------------------------------------------------------\\n',\n",
       "  'From: joth@ersys.edmonton.ab.ca (Joe Tham)\\nSubject: Where can I find SIPP?\\nOrganization: Edmonton Remote Systems #2, Edmonton, AB, Canada\\nLines: 11\\n\\n        I recently got a file describing a library of rendering routines \\ncalled SIPP (SImple Polygon',\n",
       "  \"of rendering routines \\ncalled SIPP (SImple Polygon Processor).  Could anyone tell me where I can \\nFTP the source code and which is the newest version around?\\n        Also, I've never used Renderman so I was wondering if Renderman \\nis like SIPP?  ie. \",\n",
       "  ' I was wondering if Renderman \\nis like SIPP?  ie. a library of rendering routines which one uses to make \\na program that creates the image...\\n\\n                                        Thanks,  Joe Tham\\n\\n--\\nJoe Tham              joth@ersys.edmonton.ab.',\n",
       "  '\\n\\n--\\nJoe Tham              joth@ersys.edmonton.ab.ca \\n',\n",
       "  'From: andrey@cco.caltech.edu (Andre T. Yew)\\nSubject: Re: 16 million vs 65 thousand colors\\nOrganization: California Institute of Technology, Pasadena\\nLines: 28\\nNNTP-Posting-Host: punisher.caltech.edu\\n\\nd9hh@dtek.chalmers.se (Henrik Harmsen) writes:\\n\\n>1',\n",
       "  'd9hh@dtek.chalmers.se (Henrik Harmsen) writes:\\n\\n>1-4 bits per R/G/B gives horrible machbanding visible in almost any picture.\\n\\n>5 bits per R/G/B (32768, 65000 colors) gives visible machbanding\\n\\n>color-gradient picture has _almost_ no machbanding. Thi',\n",
       "  '-gradient picture has _almost_ no machbanding. This color-resolution is \\n\\n>see some small machbanding on the smooth color-gradient picture, but all in all,\\n>There _ARE_ situiations where you get visible mach-banding even in\\n>a 24 bit card. If\\n>you cr',\n",
       "  \"le mach-banding even in\\n>a 24 bit card. If\\n>you create a very smooth color gradient of dark-green-white-yellow\\n>or something and turn\\n>up the contrast on the monitor, you will probably see some mach-banding.\\n\\n    While I don't mean to damn Henrik's a\",\n",
       "  \"anding.\\n\\n    While I don't mean to damn Henrik's attempt to be helpful here,\\nhe's using a common misconception that should be corrected.\\n\\n    Mach banding will occur for any image.  It is not the color\\nquantization you see when you don't have enough \",\n",
       "  \"r\\nquantization you see when you don't have enough bits.  It is the\\nhuman eye's response to transitions or edges between intensities.\\nThe result is that colors near the transistion look brighter on\\nthe brighter side and darker on the darker side.\\n\\n--A\",\n",
       "  ' brighter side and darker on the darker side.\\n\\n--Andre\\n\\n-- \\n             Andre Yew andrey@cco.caltech.edu (131.215.139.2)\\n',\n",
       "  'From: oehler@picard.cs.wisc.edu (Eric Oehler)\\nSubject: Translating TTTDDD to DXF or Swiv3D.\\nArticle-I.D.: cs.1993Apr6.020751.13389\\nDistribution: usa\\nOrganization: University of Wisconsin, Madison -- Computer Sciences Dept.\\nLines: 8\\n\\nI am a Mac-user w',\n",
       "  \"omputer Sciences Dept.\\nLines: 8\\n\\nI am a Mac-user when it comes to graphics (that's what I own software and hardware for) and\\nI've recently come across a large number of TTTDDD format modeling databases.  Is there any\\nsoftware, mac or unix, for transl\",\n",
       "  's.  Is there any\\nsoftware, mac or unix, for translating those to something I could use, like DXF?  Please\\nreply via email.\\n\\nThanx.\\nEric Oehler\\noehler@picard.cs.wisc.edu\\n',\n",
       "  \"From: alex@talus.msk.su (Alex Kolesov)\\nSubject: Help on RenderMan language wanted!\\nReply-To: alex@talus.msk.su\\nOrganization: unknown\\nLines: 17\\n\\nHello everybody !\\n\\nIf you are using PIXAR'S RenderMan 3D scene description language for creating 3D worlds\",\n",
       "  \" scene description language for creating 3D worlds, please, help me. \\n\\nI'm using RenderMan library on my NeXT but there is no documentation about NeXTSTEP version of RenderMan available. I can create very complicated scenes and render them using surf\",\n",
       "  'very complicated scenes and render them using surface shaders, \\nbut I can not bring them to life by applying shadows and reflections.\\n\\nAs far as I understand I have to define environmental and shadows maps to produce reflections and shadows, but I do',\n",
       "  ' maps to produce reflections and shadows, but I do not know how to use them.\\n\\nAny advises or simple RIB or C examples will be appreciated.\\nThanks in advance...\\n\\n---\\nAlex Kolesov                             Moscow, Russia.\\nTalus Imaging & Communicatio',\n",
       "  '      Moscow, Russia.\\nTalus Imaging & Communications Corporation\\ne-mail: <alex@talus.msk.su> \\t\\t(NeXT mail accepted)  \\t\\t\\t   \\n.   \\n',\n",
       "  'From: rowlands@pocomoco.NoSubdomain.NoDomain (Jon Rowlands)\\nSubject: Re: More gray levels out of the screen\\nNntp-Posting-Host: pocomoco.hc.ti.com\\nReply-To: rowlands@hc.ti.com (Jon Rowlands)\\nOrganization: Texas Instruments, SPDC, DSP Technology Branch',\n",
       "  'on: Texas Instruments, SPDC, DSP Technology Branch, Dallas\\nLines: 51\\n\\nIn article <1pp991$t63@cc.tut.fi>, jk87377@lehtori.cc.tut.fi (Kouhia Juhana)\\nwrites:\\n>In article <1993Apr5.040819.14943@kpc.com> hollasch@kpc.com (Steve\\n>Hollasch) writes:\\n>>\\n>>   ',\n",
       "  \"ollasch@kpc.com (Steve\\n>Hollasch) writes:\\n>>\\n>>    I think you're proposal would work to get an extra one, maybe two extra\\n>>bits of color resolution.  However, if you had a display that chould do only\\n>>zero or full intensity for each primary, I don\",\n",
       "  \"y\\n>>zero or full intensity for each primary, I don't think you'd get great\\n>>equivalent 24-bit photographs.\\n>\\n>I have not suggested to do so; I wrote about problems, and the problem\\n>were clearly visible with 7 bit b&w images; not to mention 24 bit i\",\n",
       "  'ble with 7 bit b&w images; not to mention 24 bit images.\\n\\n[ description of experiment deleted ]\\n\\n>If the 1 bit images are viewed quickly and in sync with screen,\\n>then 100 intensities could be better than we have -- I dunno.\\n\\n[ more deleted ]\\n\\n>In an',\n",
       "  \"than we have -- I dunno.\\n\\n[ more deleted ]\\n\\n>In any case, getting black color with slow machines is problem.\\n>I could try it on our 8 bit screens but I don't know how to\\n>render pixels with X in constant time. I recall our double buffer\\n>has other im\",\n",
       "  \"ant time. I recall our double buffer\\n>has other image color and one b&w -- that doesn't help either.\\n>Maybe I should dump photos to screen with low level code; how?\\n\\nA few years ago a friend and I took some 256 grey-level photos from\\na 1 bit Mac Plus\",\n",
       "  'k some 256 grey-level photos from\\na 1 bit Mac Plus screen using this method. Displaying all 256 levels\\nsynchronized to the 60Hz display took about 10 seconds. After\\nexperimenting with different aperture settings and screen\\nbrightnesses we found a ran',\n",
       "  're settings and screen\\nbrightnesses we found a range that worked well, giving respectable\\ncontrast. The quality of the images was pretty good. There were no\\nvisible contrast bands.\\n\\nTo minimize the exposure time the display program built 255\\ndifferen',\n",
       "  'posure time the display program built 255\\ndifferent 1 bit frames. The first contained a dot only for pixels\\nthat had value 255, the second only for pixels that had value 254,\\netc. These frames were stored using a sparse data structure that was\\nvery f',\n",
       "  \"ored using a sparse data structure that was\\nvery fast to 'or' onto the screen in sequence. Creating these\\nframes sometimes took 5-10 minutes on that old Mac, but the camera\\nshutter was closed during that time anyway. And yes, we wrote\\ndirectly to the\",\n",
       "  'hat time anyway. And yes, we wrote\\ndirectly to the screen memory. Mea culpa.\\n\\nOur biggest problem was that small images were displayed in the\\ntop left corner of the screen instead of the center. It took\\nan extra week to have the film developed and pr',\n",
       "  \"ok\\nan extra week to have the film developed and printed, because the\\nprocessors took the trouble to manually move the all images into\\nthe center of the print. Who'd have guessed?\\n\\nregards,\\nJon Rowlands\\n\",\n",
       "  's\\n',\n",
       "  'From: sloan@cis.uab.edu (Kenneth Sloan)\\nSubject: Re: More gray levels out of the screen\\nOrganization: CIS, University of Alabama at Birmingham\\nLines: 22\\n\\nIn article <C51C4r.BtG@csc.ti.com> rowlands@hc.ti.com (Jon Rowlands) writes:\\n>\\n>A few years ago ',\n",
       "  \".ti.com (Jon Rowlands) writes:\\n>\\n>A few years ago a friend and I took some 256 grey-level photos from\\n>a 1 bit Mac Plus screen using this method. Displaying all 256 levels\\n>synchronized to the 60Hz display took about 10 seconds.\\n\\nWhy didn't you creat\",\n",
       "  \"splay took about 10 seconds.\\n\\nWhy didn't you create 8 grey-level images, and display them for\\n1,2,4,8,16,32,64,128... time slices?\\n\\nThis requires the same total exposure time, and the same precision in\\ntiming, but drastically reduces the image-prepar\",\n",
       "  'n\\ntiming, but drastically reduces the image-preparation time, no?\\n\\n\\n\\n\\n\\n\\n-- \\nKenneth Sloan                   Computer and Information Sciences\\nsloan@cis.uab.edu               University of Alabama at Birmingham\\n(205) 934-2213                  115A Cam',\n",
       "  'irmingham\\n(205) 934-2213                  115A Campbell Hall, UAB Station \\n(205) 934-5473 FAX              Birmingham, AL 35294-1170\\n',\n",
       "  'From: lex@optimla.aimla.com (Lex van Sonderen)\\nSubject: Re: Rumours about 3DO ???\\nNntp-Posting-Host: emerald\\nOrganization: Philips Interactive Media of America\\nLines: 20\\n\\nIn article <h1p4s4g@zola.esd.sgi.com> erik@westworld.esd.sgi.com (Erik Fortune)',\n",
       "  \"sgi.com> erik@westworld.esd.sgi.com (Erik Fortune) writes:\\n>> better than CDI\\n>*Much* better than CDI.\\nOf course, I do not agree.  It does have more horsepower.  Horsepower is not\\nthe only measurement for 'better'.  It does not have full motion, full\",\n",
       "  ' for \\'better\\'.  It does not have full motion, full screen\\nvideo yet.  Does it have CD-ROM XA?\\n\\n>> starting in the 4 quarter of 1993\\n>The first 3DO \"multiplayer\" will be manufactured by panasonic and will be \\n>available late this year.   A number of o',\n",
       "  'ill be \\n>available late this year.   A number of other manufacturers are reported to \\n>have 3DO compatible boxes in the works.\\nWhich other manufacturers?\\nWe shall see about the date.\\n\\n>All this information is third hand or so and worth what you paid ',\n",
       "  'ation is third hand or so and worth what you paid for it:-).\\nThis is second hand, but it still hard to look to the future ;-).\\n\\nLex van Sonderen\\nlex@aimla.com\\nPhilips Interactive Media\\n',\n",
       "  'From: teckjoo@iti.gov.sg (Chua Teck Joo)\\nSubject: Visuallib (3D graphics for Windows)\\nOrganization: Information Technology Institute, National Computer Board, Singapore.\\nLines: 17\\n\\n\\nI am currently looking for a 3D graphics library that runs on MS\\nWin',\n",
       "  'king for a 3D graphics library that runs on MS\\nWindows 3.1.  Are there any such libraries out there other than\\nVisuallib?  (It must run on VGA and should not require any other\\nadd-on graphics cards).\\n\\nFor Visuallib, will it run with Metaware High C c',\n",
       "  '\\nFor Visuallib, will it run with Metaware High C compiler v3.0?  Any\\nemail contact for the author of Visuallib?\\n\\nAny help would be much appreciated.  Thanks.\\n\\n\\n-- \\n* Chua, Teck Joo\\t    | Information Technology Institute *\\n* Email: teckjoo@iti.gov.sg ',\n",
       "  'echnology Institute *\\n* Email: teckjoo@iti.gov.sg | 71 Science Park Drive\\t       *\\n* Phone: (65) 772-0237 \\t    | Singapore (0511)\\t\\t       *\\n* Fax:   (65) 779-1827      |\\t\\t\\t   \\t       *\\n',\n",
       "  'From: cst@garfield.catt.ncsu.edu (Caroline Tsang)\\nSubject: Graphics Library Package\\nArticle-I.D.: ncsu.1993Apr6.051201.9535\\nOrganization: Computer and Technologies Theme Program, NCSU, Raleigh\\nLines: 15\\n\\nHi all,\\n\\n  I am looking for a recommandation o',\n",
       "  '15\\n\\nHi all,\\n\\n  I am looking for a recommandation on a good royalty free graphics\\nlibrary package for C and C++ program.  This is mainly use to write\\nchildren games and education software.  I heard someone mentioned Genus\\nand also GFX ?  Are they any ',\n",
       "  'eone mentioned Genus\\nand also GFX ?  Are they any good?\\n\\nPlease pardon me if my question sounds a little strange, I am asking\\nthis question for a friend.\\n\\nThanks in advance!\\n\\nCaroline Tsang\\n<cst@garfield.catt.ncsu.edu>\\n  \\n',\n",
       "  'eld.catt.ncsu.edu>\\n  \\n',\n",
       "  'From: bprofane@netcom.com (Gert Niewahr)\\nSubject: Re: Rumours about 3DO ???\\nArticle-I.D.: netcom.bprofaneC51wHz.HIo\\nOrganization: Netcom Online Communications Services (408-241-9760 login: guest)\\nLines: 39\\n\\nIn article <C51Eyz.4Ix@optimla.aimla.com> l',\n",
       "  's: 39\\n\\nIn article <C51Eyz.4Ix@optimla.aimla.com> lex@optimla.aimla.com (Lex van Sonderen) writes:\\n>In article <h1p4s4g@zola.esd.sgi.com> erik@westworld.esd.sgi.com (Erik Fortune) writes:\\n>>> better than CDI\\n>>*Much* better than CDI.\\n>Of course, I do ',\n",
       "  \"an CDI\\n>>*Much* better than CDI.\\n>Of course, I do not agree.  It does have more horsepower.  Horsepower is not\\n>the only measurement for 'better'.  It does not have full motion, full screen\\n>video yet.  Does it have CD-ROM XA?\\n>\\n>>> starting in the 4\",\n",
       "  '.  Does it have CD-ROM XA?\\n>\\n>>> starting in the 4 quarter of 1993\\n>>The first 3DO \"multiplayer\" will be manufactured by panasonic and will be \\n>>available late this year.   A number of other manufacturers are reported to \\n>>have 3DO compatible boxes',\n",
       "  'urers are reported to \\n>>have 3DO compatible boxes in the works.\\n>Which other manufacturers?\\n>We shall see about the date.\\n\\nA 3DO marketing rep. recently offered a Phillips marketing rep. a $100\\nbet that 3DO would have boxes on the market on schedule',\n",
       "  'hat 3DO would have boxes on the market on schedule.  The Phillips\\nrep. declined the bet, probably because he knew that 3DO players are\\nalready in pre-production manufacturing runs, 6 months before the\\ncommercial release date.\\n\\nBy the time of commerci',\n",
       "  '\\ncommercial release date.\\n\\nBy the time of commercial release, there will be other manufacturers of\\n3DO players announced and possibly already tooling up production.  Chip\\nsets will be in full production.  The number of software companies\\ndesigning ti',\n",
       "  'on.  The number of software companies\\ndesigning titles for the box will be over 300.\\n\\nHow do I know this?  I was at a bar down the road from 3DO headquarters\\nlast week.  Some folks were bullshitting a little too loudly about\\ncompany business.\\n\\n>>All ',\n",
       "  ' little too loudly about\\ncompany business.\\n\\n>>All this information is third hand or so and worth what you paid for it:-).\\n>This is second hand, but it still hard to look to the future ;-).\\n>\\n>Lex van Sonderen\\n>lex@aimla.com\\n>Philips Interactive Media',\n",
       "  'Sonderen\\n>lex@aimla.com\\n>Philips Interactive Media\\n ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n What an impartial source!\\n',\n",
       "  'From: hl7204@eehp22 (H L)\\nSubject: Re: Graphics Library Package\\nOrganization: University of Illinois at Urbana\\nLines: 2\\n\\n  \\n\\n',\n",
       "  'From: steveq@DIALix.oz.au (Steve Quartly)\\nSubject: WANTED: SIRD Alogorythmn\\nSummary: WANTED: A Sird Alogorythmn\\nKeywords: Sird\\nArticle-I.D.: DIALix.1praaa$pqv\\nOrganization: DIALix Services, Perth, Western Australia\\nLines: 12\\nNNTP-Posting-Host: localh',\n",
       "  \"tern Australia\\nLines: 12\\nNNTP-Posting-Host: localhost.dialix.oz.au\\nX-Newsreader: NN version 6.4.19 #1\\n\\nHi,\\n\\nI'm interested in writing a program to generate a SIRD picture, you know\\nthe stereogram where you cross your eyes and the picture becomes 3D.\\n\",\n",
       "  'e you cross your eyes and the picture becomes 3D.\\n\\nDoes anyone have one or know where I can get one?\\n\\nPlease e-mail to steveq@sndcrft.DIALix.oz.au with any replies.\\n\\nMany thanks for your help.\\n\\nSteve Q.\\n',\n",
       "  'Q.\\n',\n",
       "  'From: ari@tahko.lpr.carel.fi (Ari Suutari)\\nSubject: Any graphics packages available for AIX ?\\nOrganization: Carelcomp Oy\\nLines: 24\\nNNTP-Posting-Host: tahko.lpr.carel.fi\\nKeywords: gks graphics\\n\\n\\n\\tDoes anybody know if there are any good 2d-graphics pac',\n",
       "  \"anybody know if there are any good 2d-graphics packages\\n\\tavailable for IBM RS/6000 & AIX ? I'm looking for something\\n\\tlike DEC's GKS or Hewlett-Packards Starbase, both of which\\n\\thave reasonably good support for different output devices\\n\\tlike plotters\",\n",
       "  \"upport for different output devices\\n\\tlike plotters, terminals, X etc.\\n\\n\\tI have tried also xgks from X11 distribution and IBM's implementation\\n\\tof Phigs. Both of them work but we require more output devices\\n\\tthan just X-windows.\\n\\n\\tOur salesman at IBM \",\n",
       "  'vices\\n\\tthan just X-windows.\\n\\n\\tOur salesman at IBM was not very familiar with graphics and\\n\\tI am not expecting for any good solutions from there.\\n\\n\\n\\t\\tAri\\n\\n---\\n\\n\\tAri Suutari\\t\\t\\tari@carel.fi\\n\\tCarelcomp Oy\\n\\tLappeenranta\\n\\tFINLAND\\n\\n',\n",
       "  '\\n\\tLappeenranta\\n\\tFINLAND\\n\\n',\n",
       "  'From: wijkstra@fwi.uva.nl (Marcel Wijkstra (AIO))\\nSubject: Re: BW hardcopy of colored window?\\nKeywords: color hardcopy print\\nNntp-Posting-Host: ic.fwi.uva.nl\\nOrganization: FWI, University of Amsterdam\\nLines: 38\\n\\nmars@ixos.de (Martin Stein) writes:\\n\\n#',\n",
       "  \"\\nLines: 38\\n\\nmars@ixos.de (Martin Stein) writes:\\n\\n#I use xwd/xpr (from the X11R5 dist.) and various programs of the\\n#ppm-tools to print hardcopies of colored X windows. My problem is,\\n\\nI don't like xpr. It gives (at least, the X11R4 version does) louz\",\n",
       "  '. It gives (at least, the X11R4 version does) louzy\\noutput: the hardcopy looks very grainy to me.\\nInstead, I use pnmtops. This takes full advantage PostScript, and\\nlets the printer do the dirty job of dithering a (graylevel)\\nimage to black and white ',\n",
       "  ' dithering a (graylevel)\\nimage to black and white dots.\\n\\nSo: if you have a PostScript printer, try:\\n\\txwdtopnm <xwdfile> |\\t# convert to PPM\\n\\t[ppmtopgm |]\\t\\t# .. to graylevel for smaller file to print\\n\\tpnmtops -noturn |\\t# .. to PostScript\\n\\tlpr\\t\\t\\t# print',\n",
       "  'nmtops -noturn |\\t# .. to PostScript\\n\\tlpr\\t\\t\\t# print\\n\\npnmtops Has several neat options, but use them with care:\\nIf you want your image to be 4\" wide, use:\\n\\tpnmtops -noturn -scale 100 -width 4\\n-noturn Prevents the image from being rotated (if it is wide',\n",
       "  'events the image from being rotated (if it is wider than it\\n\\tis high)\\n-width 4 Specifies the PAPER width (not the image width - see below)\\n-scale 100 Is used because if the image is small, it may fit within a\\n\\twidth less than 4\", and will thus be pri',\n",
       "  'within a\\n\\twidth less than 4\", and will thus be printed smaller than 4\" wide.\\n\\tIf you first scale it up a lot, it will certainly not fit in 4\", and\\n\\twill be scaled down by pnmtops automatically to fit the specified\\n\\tpaper width. \\n\\tIn short: pnmtops wi',\n",
       "  'the specified\\n\\tpaper width. \\n\\tIn short: pnmtops will scale an image down to fit the paper size,\\n\\tbut it will not blow it up automatically.\\n\\nHope this helps.\\nMarcel.\\n-- \\n X\\t   Marcel Wijkstra   AIO   (wijkstra@fwi.uva.nl)\\n|X|\\t     Faculty of Mathemati',\n",
       "  \"wijkstra@fwi.uva.nl)\\n|X|\\t     Faculty of Mathematics and Computer Science\\t\\n X\\t       University of Amsterdam   The Netherlands\\n======Life stinks. Fortunately, I've got a cold.========\\n\",\n",
       "  'From: jk87377@lehtori.cc.tut.fi (Kouhia Juhana)\\nSubject: Re: More gray levels out of the screen\\nOrganization: Tampere University of Technology\\nLines: 21\\nDistribution: inet\\nNNTP-Posting-Host: cc.tut.fi\\n\\nIn article <1993Apr6.011605.909@cis.uab.edu> slo',\n",
       "  \"\\n\\nIn article <1993Apr6.011605.909@cis.uab.edu> sloan@cis.uab.edu\\n(Kenneth Sloan) writes:\\n>\\n>Why didn't you create 8 grey-level images, and display them for\\n>1,2,4,8,16,32,64,128... time slices?\\n\\nBy '8 grey level images' you mean 8 items of 1bit image\",\n",
       "  \" grey level images' you mean 8 items of 1bit images?\\nIt does work(!), but it doesn't work if you have more than 1bit\\nin your screen and if the screen intensity is non-linear.\\n\\nWith 2 bit per pixel; there could be 1*c_1 + 4*c_2 timing,\\nthis gives 16 l\",\n",
       "  \"ere could be 1*c_1 + 4*c_2 timing,\\nthis gives 16 levels, but they are linear if screen intensity is\\nlinear.\\nWith 1*c_1 + 2*c_2 it works, but we have to find the best\\ncompinations -- there's 10 levels, but 16 choises; best 10 must be\\nchosen. Different\",\n",
       "  ' but 16 choises; best 10 must be\\nchosen. Different compinations for the same level, varies a bit, but\\nthe levels keeps their order.\\n\\nReaders should verify what I wrote... :-)\\n\\nJuhana Kouhia\\n',\n",
       "  \"From: renouar@amertume.ufr-info-p7.ibp.fr (Renouard Olivier)\\nSubject: LOOKING for CTDS !\\nKeywords: CTDS\\nNntp-Posting-Host: amertume.ufr-info-p7.ibp.fr\\nOrganization: Universite PARIS 7 - UFR d'Informatique\\nLines: 5\\n\\nI can't find CTDS (Connect The Dots\",\n",
       "  \"ique\\nLines: 5\\n\\nI can't find CTDS (Connect The Dots Smoother) in France. If it is a commercial\\nprogram I'll happily pay whatever it may cost (do not take it litterally).\\nPlease help!\\nI have *LOTS* of PoV sources, texture images and animations though, \",\n",
       "  'oV sources, texture images and animations though, if you\\nare looking for something, just tell.\\n',\n",
       "  \"From: renouar@amertume.ufr-info-p7.ibp.fr (Renouard Olivier)\\nSubject: Re: POV previewer\\nNntp-Posting-Host: amertume.ufr-info-p7.ibp.fr\\nOrganization: Universite PARIS 7 - UFR d'Informatique\\nLines: 10\\n\\nActually I am trying to write something like this \",\n",
       "  'Actually I am trying to write something like this but I encounter some\\nproblems, amongst them:\\n\\n- drawing a 3d wireframe view of a quadric/quartic requires that you have\\nthe explicit equation of the quadric/quartic (x, y, z functions of some\\nparamete',\n",
       "  \"uadric/quartic (x, y, z functions of some\\nparameters). How to convert the implicit equation used by PoV to an\\nexplicit one? Is it mathematically always possible?\\n\\nI don't have enough math to find out by myself, has anybody heard about\\nuseful books on\",\n",
       "  'by myself, has anybody heard about\\nuseful books on the subject?\\n',\n",
       "  'From: dsnyder@falcon.aamrl.wpafb.af.mil\\nSubject: Re: Real Time Graphics??\\nDistribution: na\\nOrganization: USAF AL/CFH, WPAFB, Dayton, OH\\nLines: 30\\n\\nIn article <C4vA9r.KK7@taurus.cs.nps.navy.mil>, stockel@oahu.oc.nps.navy.mil (Jim Stockel) writes:\\n> Hi',\n",
       "  \"el@oahu.oc.nps.navy.mil (Jim Stockel) writes:\\n> Hi,\\n> \\n> I will be writing a data acquisition program to collect data from a\\n> variety of sources including RS232, and external A/D's, and I would\\n> like to be able to display the data in near realtime.\",\n",
       "  \"e to be able to display the data in near realtime.  I've done this\\n> type of thing on PC's and other machines, but I am unaware of any graphics\\n> package that could help me with this on a UNIX machine.\\n> \\n> .......\\n> \\n> Does anyone have any ideas on \",\n",
       "  '.\\n> \\n> .......\\n> \\n> Does anyone have any ideas on commercial or \"free\" packages that might\\n> suit my needs?  I would really appreciate any input.  I\\'m sure this has\\n> been done many times before.\\n> \\n\\n  For a commerical package try WAVE from  Precisio',\n",
       "  '  For a commerical package try WAVE from  Precision Visuals\\n                                           505-530-6563\\n\\n  For a free package try KHOROS from University of New Mexico\\n                                      508-277-6563\\n                    ',\n",
       "  '                 508-277-6563\\n                                   ftp from\\n                              ptrg.eece.unm.edu\\n\\n    Login in anonyomus or ftp  with a valid email address as the password\\n               cd /pub/khoros/release\\n\\n   That will g',\n",
       "  '            cd /pub/khoros/release\\n\\n   That will get you to the right place.\\n\\n                                                         David\\n',\n",
       "  'From: scrowe@hemel.bull.co.uk (Simon Crowe)\\nSubject: BGI Drivers for SVGA\\nSummary: Ftp site for SVGA Driver\\nKeywords: BGI, SVGA\\nNntp-Posting-Host: bogart\\nOrganization: Bull HN UK\\nLines: 11\\n\\nI require BGI drivers for Super VGA Displays and Super XVGA ',\n",
       "  'BGI drivers for Super VGA Displays and Super XVGA Displays. Does \\nanyone know where I could obtain the relevant drivers ? (FTP sites ??)\\n\\n\\tRegards\\n\\n\\n\\t\\tSimon Crowe\\n\\n\\n\\n\\n',\n",
       "  'From: d91-fad@tekn.hj.se (DANIEL FALK)\\nSubject: RE: VESA on the Speedstar 24\\nOrganization: H|gskolan i J|nk|ping\\nLines: 39\\nNntp-Posting-Host: pc5_b109.et.hj.se\\n\\n>>>kjb/MGL/uvesa32.zip\\n>>>\\n>>>This is a universal VESA driver.  It supports most video\\n>>',\n",
       "  \" universal VESA driver.  It supports most video\\n>>>boards/chipsets (include the Speedstar-24 and -24X) up to\\n>>>24 bit color.\\n>>>\\n>>>Terry\\n>>>\\n>>>P.S.  I've tried it on a Speedstar-24 and -24X and it works. :)\\n\\n>>Not with all software. :( For instanc\",\n",
       "  \"works. :)\\n\\n>>Not with all software. :( For instance it doesn't work at all with\\n>>Animator Pro from Autodesk. It can't detect ANY SVGA modes when \\n>>running UniVESA. This is really a problem as we need a VESA driver\\n>>for both AA Pro and some hi-colo\",\n",
       "  'd a VESA driver\\n>>for both AA Pro and some hi-color stuff. :(\\n\\n>Just out of curiosity... Are you using the latest version (3.2)?  Versions\\n>previous to this did not fill in all of the capabilities bits and other\\n>information correctly.  I had problem',\n",
       "  \"s and other\\n>information correctly.  I had problems with a lot of software until I got\\n>this version.  (I don't think the author got around to posting an \\n>announcementof it (or at least I missed it), but 3.2 was available in the \\n>directory indicate\",\n",
       "  ' but 3.2 was available in the \\n>directory indicated as of 3/29.)\\n\\nI sure did use version 3.2. It works fine with most software but NOT\\nwith Animator Pro and that one is quite important to me. Pretty\\nuseless program without that thing working IMHO.\\nSo',\n",
       "  'seless program without that thing working IMHO.\\nSo I hope the author can fix that.\\n\\n/Daniel...\\n\\n\\n\\n\\n=============================================================================\\n!!      Daniel Falk          \\\\\\\\  \" Don\\'t quote me! No comments! \"        ',\n",
       "  '      \\\\\\\\  \" Don\\'t quote me! No comments! \"          !! \\n!!      ^^^^^^ ^^^^           \\\\\\\\               Ebenezum the Great Wizard   !! \\n!!      d91-fad@tekn.hj.se     \\\\\\\\                                          !!\\n!!      d91fad@hjds90.hj.se    //  Al',\n",
       "  '          !!\\n!!      d91fad@hjds90.hj.se    //  Also known as the mega-famous musician  !!\\n!!      Jkpg, Sweeeeeden...    \\\\\\\\         Leinad of The Yellow Ones        !!\\n=============================================================================\\n',\n",
       "  '==============================================\\n',\n",
       "  'From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: (None set)\\nOrganization: The University of Birmingham, United Kingdom\\nLines: 5\\nNNTP-Posting-Host: ibm3090.bham.ac.uk\\n\\n==============================================================================\\nBear with ',\n",
       "  \"=======================================\\nBear with me i'm new at this game, but could anyone explain exactly what DMORF\\ndoes, does it simply fade one bitmap into another or does it re shape one bitma\\np into another. Please excuse my ignorance, i' not \",\n",
       "  \" into another. Please excuse my ignorance, i' not even sure if i've posted thi\\ns message correctly.\\n\",\n",
       "  'From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: HELP WANTED FOR DMORF.......!\\nOrganization: The University of Birmingham, United Kingdom\\nLines: 6\\nNNTP-Posting-Host: ibm3090.bham.ac.uk\\n\\n======================================================================',\n",
       "  '==========================================================\\nPlease bear with me as i am new at this game, i apologize unreservedly if i hav\\ne posted another message earlier by mistake. but i digress, could anyone out th\\nere please explain exactly what',\n",
       "  'ould anyone out th\\nere please explain exactly what DMORF does (dtax.exe). Does it simply fade one\\nbitmap into another or does it reshape one bitmap into another. Excuse my ignor\\nance.....\\n',\n",
       "  'From: SITUNAYA@IBM3090.BHAM.AC.UK\\nSubject: test....(sorry)\\nOrganization: The University of Birmingham, United Kingdom\\nLines: 1\\nNNTP-Posting-Host: ibm3090.bham.ac.uk\\n\\n==============================================================================\\n',\n",
       "  '============================================\\n',\n",
       "  'From: stgprao@st.unocal.COM (Richard Ottolini)\\nSubject: Re: Rumours about 3DO ???\\nOrganization: Unocal Corporation\\nLines: 5\\n\\nThey need a hit software product to encourage software sales of the product,\\ni.e. the Pong, Pacman, VisiCalc, dBase, or Pagem',\n",
       "  \",\\ni.e. the Pong, Pacman, VisiCalc, dBase, or Pagemaker of multi-media.\\nThere are some multi-media and digital television products out there already,\\nalbeit, not as capable as 3DO's.  But are there compelling reasons to buy\\nsuch yet?  Perhaps someone \",\n",
       "  'pelling reasons to buy\\nsuch yet?  Perhaps someone in this news group will write that hit software :-)\\n',\n",
       "  'Subject: Technical Help Sought\\nFrom: jiu1@husc11.harvard.edu (Haibin Jiu)\\nOrganization: Harvard University Science Center\\nNntp-Posting-Host: husc11.harvard.edu\\nLines: 9\\n\\nHi!  I am in immediate need for details of various graphics compression\\ntechniqu',\n",
       "  'r details of various graphics compression\\ntechniques.  So if you know where I could obtain descriptions of algo-\\nrithms or public-domain source codes for such formats as JPEG, GIF, and\\nfractals, I would be immensely grateful if you could share the in',\n",
       "  'ld be immensely grateful if you could share the info with\\nme.  This is for a project I am contemplating of doing.\\n\\nThanks in advance.  Please reply via e-mail if possible.\\n\\n--hBJ\\n',\n",
       "  'From: srp@travis.csd.harris.com (Stephen Pietrowicz)\\nSubject: Surface normal orientations\\nArticle-I.D.: travis.1pscti$aqe\\nOrganization: Harris CSD, Ft. Lauderdale, FL\\nLines: 20\\nNNTP-Posting-Host: travis.csd.harris.com\\n\\nSome rendering programs require',\n",
       "  'is.csd.harris.com\\n\\nSome rendering programs require that all surface normals point in the same\\ndirection.  (ie: On a closed cube, all normals point outwards).  You can use\\nthe points on the faces to determine the direction of the normal, by making\\nsur',\n",
       "  'termine the direction of the normal, by making\\nsure that all points are either in clockwise or counter-clockwise order.\\n\\nHow do you go about orienting all normals in the same direction, given a \\nset of points, edges and faces?   Say that you had a cu',\n",
       "  'f points, edges and faces?   Say that you had a cube with all faces that \\nhave their normals facing outwards, except for one face.  What\\'s the\\nbest way to realize that face is \"flipped\", and should have it\\'s points\\nre-ordered?   I thought I had a goo',\n",
       "  \"ve it's points\\nre-ordered?   I thought I had a good way of telling this, but then realized\\nthat the algorithm I had would only tell you if you had points in clockwise\\norder for a 2d polygon.  I'd like something for 3d data.\\n\\nAny hints, tips, referenc\",\n",
       "  ' something for 3d data.\\n\\nAny hints, tips, references would be appreciated.\\n\\nSteve\\n-- \\nWhere humor is concerned there are no standards -- no one can say what is good \\nor bad, although you can be sure that everyone will.  -- John Kenneth Galbraith\\n----',\n",
       "  'hat everyone will.  -- John Kenneth Galbraith\\n------- These opinions are my own.\\n',\n",
       "  'From: egerter@gaul.csd.uwo.ca (Barry Egerter)\\nSubject: Re: Graphics Library Package\\nOrganization: Computer Science Dept., Univ. of Western Ontario, London, Canada\\nNntp-Posting-Host: obelix.gaul.csd.uwo.ca\\nLines: 43\\n\\n\\n\\tWGT is the WordUp Graphics Toolk',\n",
       "  'o.ca\\nLines: 43\\n\\n\\n\\tWGT is the WordUp Graphics Toolkit, designed by yours truly and my\\nco-programmer (and brother) Chris Egerter. It is a Turbo/Borland C++ graphics\\nlibrary for programming in 320*200*256 VGA. We are currently producing it as\\nshareware,',\n",
       "  \"6 VGA. We are currently producing it as\\nshareware, but in a few years it may be a commercial product (excuse typos,\\nthere's no backspace on this terminal). Features include:\\n\\n- loading and saving bit-images (called blocks from herein)\\n- flipping, res\",\n",
       "  'images (called blocks from herein)\\n- flipping, resizing and warping blocks\\n- loading and saving palette, fading, several in memory at once\\n- graphics primitives such as line, circle, bar, rectangle\\n- region fill (not the usually useless floodfill)\\n- ',\n",
       "  'region fill (not the usually useless floodfill)\\n- sprites (animated bitmaps), up to 200 onscreen at once\\n- joystick/mouse support\\n- SB support (VOC and CMF)\\n- tile-based game creation using 16*16 pixel tiles to create\\n  a 320*200 tile map (or game wo',\n",
       "  \"l tiles to create\\n  a 320*200 tile map (or game world) like in Duke Nuke 'Em\\n- number of sprites increased to 1000\\n- Professional Sprite Creator utility and Map Maker\\n-  routines to simplify scrolling games using maps, etc\\n- FLI playing routines, spr\",\n",
       "  ' games using maps, etc\\n- FLI playing routines, sprites can be animated over the FLI while playing\\n- PCX support, soon GIF\\n- EMS/XMS coming soon as well\\n\\nLeave E-mail to Barry Egerter at    egerter@obelix.gaul.csd.uwo.ca\\n\\nFiles available on:      (use',\n",
       "  'lix.gaul.csd.uwo.ca\\n\\nFiles available on:      (use  mget wgt*.zip)\\n\\nSIMTEL20 and mirrors                pd1:<msdos.turbo-c>\\n\\nnic.funet.fi                        pub/msdos/games/programming\\n\\nSome sites may not have recent files, contact me for info re',\n",
       "  ' may not have recent files, contact me for info regarding the up-to-\\ndate information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       "  'From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging Club\")\\nSubject: Re: Signature Image Database\\nOrganization: Mail to News Gateway at Wang Labs\\nLines: 21\\n\\nContact Signaware Corp\\n800-4583820\\n800 6376564\\n\\n-------------------------------- Original Memo ------',\n",
       "  '----------------------------- Original Memo --------------------------------\\nBCC:     Vincent Wall                   From:      Imaging Club\\nSubject: Signature verification  ?      Date Sent: 05/04/93\\n\\nsci.image.processing\\nFrom: yyqi@ece.arizona.edu ',\n",
       "  '\\n\\nsci.image.processing\\nFrom: yyqi@ece.arizona.edu (Yingyong Qi)\\nSubject: Signature Image Database\\nOrganization: U of Arizona Electrical and Computer Engineering\\n\\nHi, All:\\n\\nCould someone tell me if there is a database of handwriting signature\\nimages a',\n",
       "  're is a database of handwriting signature\\nimages available for evaluating signature verification systems.\\n\\nThanks.\\n\\nYY\\n',\n",
       "  'From: sloan@cis.uab.edu (Kenneth Sloan)\\nSubject: Re: Surface normal orientations\\nArticle-I.D.: cis.1993Apr6.181509.1973\\nOrganization: CIS, University of Alabama at Birmingham\\nLines: 16\\n\\nIn article <1993Apr6.175117.1848@cis.uab.edu> sloan@cis.uab.edu ',\n",
       "  \"93Apr6.175117.1848@cis.uab.edu> sloan@cis.uab.edu (Kenneth Sloan) writes:\\n\\nA brilliant algorithm.  *NOT*\\n\\nSeriously - it's correct, up to a sign change.  The flaw is obvious, and\\nwill therefore not be shown.\\n\\nsorry about that.\\n\\n\\n\\n-- \\nKenneth Sloan   \",\n",
       "  ' shown.\\n\\nsorry about that.\\n\\n\\n\\n-- \\nKenneth Sloan                   Computer and Information Sciences\\nsloan@cis.uab.edu               University of Alabama at Birmingham\\n(205) 934-2213                  115A Campbell Hall, UAB Station \\n(205) 934-5473 FA',\n",
       "  '115A Campbell Hall, UAB Station \\n(205) 934-5473 FAX              Birmingham, AL 35294-1170\\n',\n",
       "  \"From: pallis@server.uwindsor.ca (PALLIS  DIMITRIOS        )\\nSubject: Re: Genoa Blitz 24 hits 1600x1200x256 NI !\\nLines: 3\\n\\ni am sorry, but this genoa card does nothing that the ATI ultra plus 2mb\\ncan't do, PLUS the ATI costs 330$US street price ....\\n\\n\",\n",
       "  ' do, PLUS the ATI costs 330$US street price ....\\n\\n',\n",
       "  'From: sloan@cis.uab.edu (Kenneth Sloan)\\nSubject: Re: Surface normal orientations\\nOrganization: CIS, University of Alabama at Birmingham\\nLines: 42\\n\\nIn article <1pscti$aqe@travis.csd.harris.com> srp@travis.csd.harris.com (Stephen Pietrowicz) writes:\\n>.',\n",
       "  'vis.csd.harris.com (Stephen Pietrowicz) writes:\\n>...\\n>How do you go about orienting all normals in the same direction, given a \\n>set of points, edges and faces? \\n\\nLook for edge inconsistencies.  Consider two vertices, p and q, which\\nare connected by ',\n",
       "  'der two vertices, p and q, which\\nare connected by at least one edge.\\n\\nIf (p,q) is an edge, then (q,p) should *not* appear.  \\n\\nIf *both* (p,q) and (q,p) appear as edges, then the surface \"flips\" when\\nyou travel across that edge.  This is bad.  \\n\\nAssum',\n",
       "  'ou travel across that edge.  This is bad.  \\n\\nAssuming (warning...warning...warning) that you have an otherwise\\nacceptable surface - you can pick an edge, any edge, and traverse the\\nsurface enforcing consistency with that edge.  \\n\\n    0) pick an edge ',\n",
       "  'onsistency with that edge.  \\n\\n    0) pick an edge (p,q), and mark it as \"OK\"\\n    1) for each face, F, containing this edge (if more than 2, oops)\\n       make sure that all edges in F are consistent (i.e., the Face\\n       should be [(p,q),(q,r),(r,s),',\n",
       "  '.e., the Face\\n       should be [(p,q),(q,r),(r,s),(s,t),(t,p)]).  Flip those which\\n       are wrong. Mark all of the edges in F as \"OK\",\\n       and add them to a queue (check for duplicates, and especially\\n       inconsistencies - don\\'t let the queue',\n",
       "  \"ially\\n       inconsistencies - don't let the queue have both (p,q) and (q,p)). \\n    2) remove an edge from the queue, and go to 1).\\n\\nIf a *marked* edge is discovered to be inconsistent, then you lose.\\n\\nIf step 1) finds more than one face sharing a pa\",\n",
       "  '\\n\\nIf step 1) finds more than one face sharing a particular edge, then you\\nlose. \\n    \\nOtherwise, when done, all of the edges will be consistent.  Which means\\nthat all of the surface normals will either point IN or OUT.  Deciding\\nwhich way is OUT is l',\n",
       "  'r point IN or OUT.  Deciding\\nwhich way is OUT is left as an exercise...\\n\\n\\n\\n-- \\nKenneth Sloan                   Computer and Information Sciences\\nsloan@cis.uab.edu               University of Alabama at Birmingham\\n(205) 934-2213                  115A ',\n",
       "  't Birmingham\\n(205) 934-2213                  115A Campbell Hall, UAB Station \\n(205) 934-5473 FAX              Birmingham, AL 35294-1170\\n',\n",
       "  'From: gavin@krypton.asd.sgi.com (Gavin Bell)\\nSubject: Re: Surface normal orientations\\nOrganization: Silicon Graphics, Inc.  Mountain View, CA\\nLines: 38\\nNNTP-Posting-Host: krypton.asd.sgi.com\\n\\nIn <1pscti$aqe@travis.csd.harris.com> srp@travis.csd.harri',\n",
       "  'ti$aqe@travis.csd.harris.com> srp@travis.csd.harris.com (Stephen Pietrowicz) writes:\\n>How do you go about orienting all normals in the same direction, given a \\n>set of points, edges and faces?\\n\\nThis algorithm works well for me:\\n\\nAlgorithm to attempt ',\n",
       "  'lgorithm works well for me:\\n\\nAlgorithm to attempt to find outward-facing normals:\\n---------------------------------------------------\\nFirst, mark all faces as UNKNOWN.\\n\\nThen create an edge dictionary that allows you to find all of the\\nfaces sharing a',\n",
       "  'that allows you to find all of the\\nfaces sharing a given edge (where an edge is two integers representing\\nthe two shared vertices).\\n\\nPick an arbitrary face and mark it COUNTER_CLOCKWISE.  Using the edge\\ndictionary, orient all surrounding faces based ',\n",
       "  'ge\\ndictionary, orient all surrounding faces based on the orientation of\\nthis face.  And recurse for all surrounding faces, consistently\\norienting the entire surface.\\n\\nFind the average of the vertices in this surface.  Using that point,\\ncalculate a vo',\n",
       "  \"in this surface.  Using that point,\\ncalculate a volume measurement, taking into account the face's\\norientation.  If the volume turns out to be positive, assume the faces\\nare oriented correctly.  If it is negative, reverse their orientations\\n(mark the\",\n",
       "  ' is negative, reverse their orientations\\n(mark them CLOCKWISE).\\n\\nIf any faces are still UNKNOWN after this, choose another face\\nand go through the algorithm again.\\n\\nAt the end, faces marked CLOCKWISE must have their indices reversed\\nbefore facet norm',\n",
       "  'must have their indices reversed\\nbefore facet normals are found.\\n\\n(Note: if you are running on Silicon Graphics machines and buy the\\nIRIS Inventor 3D toolkit developers package you have the source to\\nthis algorithm-- see /usr/src/Inventor/tools/ivnor',\n",
       "  \"this algorithm-- see /usr/src/Inventor/tools/ivnorm/.  If you're\\nnot... sorry, I can't give out the source, and even if I could it\\nrelies heavily on Inventor).\\n--\\n--gavin     (gavin@sgi.com,  (415)390-1024)\\n\",\n",
       "  '-1024)\\n',\n",
       "  'From: d9hh@dtek.chalmers.se (Henrik Harmsen)\\nSubject: Re: 16 million vs 65 thousand colors\\nNntp-Posting-Host: hacke11.dtek.chalmers.se\\nOrganization: Chalmers University of Technology, Gothenburg Sweden\\nLines: 37\\n\\nandrey@cco.caltech.edu (Andre T. Yew)',\n",
       "  'n\\nLines: 37\\n\\nandrey@cco.caltech.edu (Andre T. Yew) writes:\\n\\n>d9hh@dtek.chalmers.se (Henrik Harmsen) writes:\\n\\n>>1-4 bits per R/G/B gives horrible machbanding visible in almost any picture.\\n\\n>>5 bits per R/G/B (32768, 65000 colors) gives visible machba',\n",
       "  'r R/G/B (32768, 65000 colors) gives visible machbanding\\n\\n>>color-gradient picture has _almost_ no machbanding. This color-resolution is \\n\\n>>see some small machbanding on the smooth color-gradient picture, but all in all,\\n>>There _ARE_ situiations whe',\n",
       "  'ure, but all in all,\\n>>There _ARE_ situiations where you get visible mach-banding even in\\n>>a 24 bit card. If\\n>>you create a very smooth color gradient of dark-green-white-yellow\\n>>or something and turn\\n>>up the contrast on the monitor, you will prob',\n",
       "  \"rn\\n>>up the contrast on the monitor, you will probably see some mach-banding.\\n\\n>    While I don't mean to damn Henrik's attempt to be helpful here,\\n>he's using a common misconception that should be corrected.\\n\\n>    Mach banding will occur for any ima\",\n",
       "  \"rrected.\\n\\n>    Mach banding will occur for any image.  It is not the color\\n>quantization you see when you don't have enough bits.  It is the\\n>human eye's response to transitions or edges between intensities.\\n>The result is that colors near the transi\",\n",
       "  \"sities.\\n>The result is that colors near the transistion look brighter on\\n>the brighter side and darker on the darker side.\\n\\n>--Andre\\n\\nYeah, of course... The term 'mach banding' was not the correct one, it should've\\nbeen 'color quantization effect'. A\",\n",
       "  \", it should've\\nbeen 'color quantization effect'. Although a bad color quantization effect could\\nresult in some visible mach-bands on a picture that was smooth before it was\\nquantizised.\\n\\n--\\nHenrik Harmsen     Internet:  d9hh@dtek.chalmers.se\\n        \",\n",
       "  'msen     Internet:  d9hh@dtek.chalmers.se\\n               Chalmers University of Technology, Sweden. \\n      \"I haven\\'t lost my mind -- it\\'s backed up on tape somewhere.\"\\n',\n",
       "  'From: dsnyder@falcon.aamrl.wpafb.af.mil\\nSubject: Re: Real Time Graphics??\\nDistribution: na\\nOrganization: USAF AL/CFH, WPAFB, Dayton, OH\\nLines: 27\\n\\nIn article <1993Apr5.114428.2061@falcon.aamrl.wpafb.af.mil>, dsnyder@falcon.aamrl.wpafb.af.mil writes:\\n',\n",
       "  'f.mil>, dsnyder@falcon.aamrl.wpafb.af.mil writes:\\n> In article <C4vA9r.KK7@taurus.cs.nps.navy.mil>, stockel@oahu.oc.nps.navy.mil (Jim Stockel) writes:\\n>> Hi,\\n>> \\n>> \\n\\n\\n Opps!  typed in the phone numbers wrong.  Here are the correct numbers.\\n\\n> \\n>   F',\n",
       "  'rs wrong.  Here are the correct numbers.\\n\\n> \\n>   For a commerical package try WAVE from  Precision Visuals\\n\\n\\n                                            303-530-9000\\n\\n> \\n>   For a free package try KHOROS from University of New Mexico\\n\\n\\n              ',\n",
       "  'ROS from University of New Mexico\\n\\n\\n                                       505-277-6563\\n\\n\\n>                                    ftp from\\n>                               ptrg.eece.unm.edu\\n> \\n>     Login in anonyomus or ftp  with a valid email address a',\n",
       "  ' in anonyomus or ftp  with a valid email address as the password\\n>                cd /pub/khoros/release\\n',\n",
       "  'From: bsaffo01@cad.gmeds.com (Brian H. Safford)\\nSubject: IGES Viewer for DOS/Windows\\nOrganization: EDS/Cadillac\\nLines: 10\\nNNTP-Posting-Host: ccadmn1.cad.gmeds.com\\n\\nAnybody know of an IGES Viewer for DOS/Windows? I need to be able to display \\nComputer',\n",
       "  'OS/Windows? I need to be able to display \\nComputerVision IGES files on a PC running Windows 3.1. Thanks in advance.\\n\\n+-----------------------------------------------------------+\\n| Brian H. Safford           EMAIL: bsaffo01@cad.gmeds.com  |\\n| Electro',\n",
       "  '        EMAIL: bsaffo01@cad.gmeds.com  |\\n| Electronic Data Systems    PHONE: (313) 696-6302          |\\n+-----------------------------------------------------------+\\n| NOTE: The views and opinions expressed herein are mine,   |\\n| and DO NOT reflect th',\n",
       "  'essed herein are mine,   |\\n| and DO NOT reflect those of Electronic Data Systems Corp. |\\n+-----------------------------------------------------------+\\n',\n",
       "  'From: brr1@ns1.cc.lehigh.edu (BRANT RICHARD RITTER)\\nSubject: computer graphics to vcr?\\nOrganization: Lehigh University\\nLines: 15\\n\\n\\n    HELP   MY FRIEND AND I HAVE A CLASS PROJECT IN WHICH WE ARE TRYING TO MAKE\\n    A COMPUTER ANIMATED MOVIE OF SORTS W',\n",
       "  'G TO MAKE\\n    A COMPUTER ANIMATED MOVIE OF SORTS WITH THE DISNEY ANIMATION AND WOULD\\n    LIKE TO PUT WHAT WE HAVE ON A VCR IS THIS POSSIBLE?  IS IT EASY AND\\n    RELATIVELY CHEAP? IF SO HOW? WE BOTH HAVE 386 IBM COMPATIBLES BUT ARE\\n    RELATIVELY CLUE',\n",
       "  'VE 386 IBM COMPATIBLES BUT ARE\\n    RELATIVELY CLUELESS WITH COMPUTERS IF YOU COULD HELP PLEASE DO.\\n\\n                                THANX.\\n-- \\nBRANT RITTER\\n-----------------------------------------------------\\nmoshing--   \"a cosmic cesspool of physic',\n",
       "  '---------\\nmoshing--   \"a cosmic cesspool of physical delight.\"\\n                                  -A. Kiedas\\n                                     RHCP\\n-----------------------------------------------------\\n',\n",
       "  '---\\n',\n",
       "  'From: mbh2@engr.engr.uark.edu (M. Barton Hodges)\\nSubject: Stereoscopic imaging\\nSummary: Stereoscopic imaging\\nKeywords: stereoscopic\\nNntp-Posting-Host: engr.engr.uark.edu\\nOrganization: University of Arkansas\\nLines: 8\\n\\nI am interested in any informatio',\n",
       "  'kansas\\nLines: 8\\n\\nI am interested in any information on stereoscopic imaging on a sun\\nworkstation.  For the most part, I need to know if there is any hardware\\navailable to interface the system and whether the refresh rates are\\nsufficient to produce qu',\n",
       "  'her the refresh rates are\\nsufficient to produce quality image representations.  Any information\\nabout the subject would be greatly appreciated.\\n\\n    Thanks!\\n\\n',\n",
       "  'From: ab@nova.cc.purdue.edu (Allen B)\\nSubject: Re: Fractals? what good are they?\\nOrganization: Purdue University\\nLines: 51\\n\\nIn article <7155@pdxgate.UUCP> idr@rigel.cs.pdx.edu (Ian D Romanick) writes:\\n> One thing:  a small change in initial condition',\n",
       "  '\\n> One thing:  a small change in initial conditions can cause a huge\\n> change in final conditions.  There are certain things about the way\\n> the plate tektoniks and volcanic activity effect a land scape that\\n> is, while not entirely random, unpredict',\n",
       "  \"pe that\\n> is, while not entirely random, unpredictable.  This is also true with\\n> fractals, so one could also conclude that you could model this\\n> fractally. \\n\\nYeah, and it's also true most long complicated sequences of events,\\ncalculations, or big c\",\n",
       "  \"icated sequences of events,\\ncalculations, or big computer programs in general.  I don't argue\\nthat you can get similar and maybe useful results from fractals, I\\njust question whether you >should<.\\n\\nThe fractal fiends seem to be saying that any part o\",\n",
       "  \"e fractal fiends seem to be saying that any part of a system that we\\ncan't model should be replaced with a random number generator.  That\\nhas been useful, for instance, in making data more palatable to human\\nperception or for torture testing the rest\",\n",
       "  \"o human\\nperception or for torture testing the rest of the system, but I don't\\nthink it has much to do with fractals, and I certainly would rather\\nthat the model be improved in a more explicable manner.\\n\\nI guess I just haven't seen all these earth-sha\",\n",
       "  \".\\n\\nI guess I just haven't seen all these earth-shaking fractal models\\nthat explain and correlate to the universe as it actually exists.  I\\nreally hope I do, but I'm not holding my self-similar breath.\\n\\n> There is one other thing that fractals are goo\",\n",
       "  \"\\n\\n> There is one other thing that fractals are good for:  fractal\\n> image compression.\\n\\nUh huh.  I'll believe it when I see it.  I've been chasing fractal\\ncompression for a few years, and I still don't believe in it.  If it's so\\ngreat, how come we do\",\n",
       "  \"t believe in it.  If it's so\\ngreat, how come we don't see it competing with JPEG?  'Cause it can't,\\nI'll wager.\\n\\nActually, I have wagered, I quit trying to make fractal compression\\nwork- and I was trying- because I don't think it's a reasonable\\nalter\",\n",
       "  \"ing- because I don't think it's a reasonable\\nalternative to other techniques.  It is neat, though. :-)\\n\\nI'll reiterate my disbelief that everything is fractal.  That's why I\\ndon't think fractal compression as it is widely explained is\\npractical.  I k\",\n",
       "  \"ssion as it is widely explained is\\npractical.  I know Barnsley and Sloan have some tricks up their\\nsleeves that make their demos work, but I don't see anyone using it in a\\nreal product.  It's been six years since Iterated Systems was formed,\\nright?\\n\\n\",\n",
       "  ' years since Iterated Systems was formed,\\nright?\\n\\n\\t\"There are always going to be questions until there\\'s a product\\n\\tout there,\" Sloan replies.  The company plans to ship its first\\n\\tencoding devices in the summer, he says.  In March, Iterated\\n\\tSystems',\n",
       "  \" the summer, he says.  In March, Iterated\\n\\tSystems will have the other half of the system: the decoders.\\n\\n\\t\\t- Scientific American, March 1990, page 77\\n\\nAllen B (Don't even get me started :-) )\\n\",\n",
       "  'From: ranjan@cs.ubc.ca (Vishwa Ranjan)\\nSubject: Complex (i.e. with real and imaginary parts) bio-medical images..\\nOrganization: Computer Science, University of B.C., Vancouver, B.C., Canada\\nLines: 7\\nDistribution: world\\nNNTP-Posting-Host: ironduke.cs.',\n",
       "  'istribution: world\\nNNTP-Posting-Host: ironduke.cs.ubc.ca\\n\\nAre  complex  bio-medical  images  available  anywhere on the net for \\nexperimentation?  By complex I mean that every sampled data point has \\na magnitude and phase information both. \\n\\nThanks f',\n",
       "  'a magnitude and phase information both. \\n\\nThanks for any pointers,\\n--Vishwa\\n\\n',\n",
       "  'From: sas58295@uxa.cso.uiuc.edu (Lord Soth       )\\nSubject: MPEG for MS-DOS\\nOrganization: University of Illinois at Urbana\\nLines: 13\\n\\nDoes anyone know where I can FTP MPEG for DOS from?  Thanks for any\\nhelp in advance.  Email is preferred but posting',\n",
       "  'y\\nhelp in advance.  Email is preferred but posting is fine.\\n\\n\\t\\t\\t\\tScott\\n\\n\\n---------------------------------------------------------------------------\\n| Lord Soth, Knight |||| email to --> LordSoth@uiuc                ||||||||\\n| of the Black Rose |||| ',\n",
       "  \"                ||||||||\\n| of the Black Rose |||| NeXT to ---> sas58295@sumter.cso.uiuc.edu ||||||||\\n|   @}--'-,--}--    |||||||||||||||||||||||||||||||||||||||||||||||||||||||\\n|------------------------------------------------------------------------\",\n",
       "  \"---------------------------------------------------|\\n|    I have no clue what I want to say in here so I won't say anything.   |\\n---------------------------------------------------------------------------\\n\",\n",
       "  '----\\n',\n",
       "  \"From: jack@shograf.com (Jack Ritter)\\nSubject: Help!!\\nArticle-I.D.: shograf.C531E6.7uo\\nDistribution: usa\\nOrganization: SHOgraphics, Sunnyvale\\nLines: 9\\n\\nI need a complete list of all the polygons\\nthat there are, in order.\\n\\nI'll summarize to the net.\\n\\n\\n\",\n",
       "  'here are, in order.\\n\\nI\\'ll summarize to the net.\\n\\n\\n--------------------------------------------------------\\n   \"If only I had been compiled with the \\'-g\\' option.\"\\n---------------------------------------------------------\\n',\n",
       "  '-------------------\\n',\n",
       "  'From: geoffrey@cosc.canterbury.ac.nz (Geoff Thomas)\\nSubject: Re: Help! 256 colors display in C.\\nKeywords: graphics\\nArticle-I.D.: cantua.C533EM.Cv7\\nOrganization: University of Canterbury, Christchurch, New Zealand\\nLines: 21\\nNntp-Posting-Host: huia.can',\n",
       "  \" New Zealand\\nLines: 21\\nNntp-Posting-Host: huia.canterbury.ac.nz\\n\\n\\nYou'll probably have to set the palette up before you try drawing\\nin the new colours.\\n\\nUse the bios interrupt calls to set the r g & b values (in the range\\nfrom 0-63 for most cards) fo\",\n",
       "  ' values (in the range\\nfrom 0-63 for most cards) for a particular palette colour (in the\\nrange from 0-255 for 256 colour modes).\\n\\nThen you should be able to draw pixels in those palette values and\\nthe result should be ok.\\n\\nYou might have to do a bit o',\n",
       "  'result should be ok.\\n\\nYou might have to do a bit of colourmap compressing if you have\\nmore than 256 unique rgb triplets, for a 256 colour mode.\\n\\n\\nGeoff Thomas\\t\\t\\tgeoffrey@cosc.canterbury.ac.nz\\nComputer Science Dept.\\nUniversity of Canterbury\\nPrivate Ba',\n",
       "  ' Science Dept.\\nUniversity of Canterbury\\nPrivate Bag\\t\\t\\t\\t+-------+\\nChristchurch\\t\\t\\t\\t| Oook! |\\nNew Zealand\\t\\t\\t\\t+-------+\\n',\n",
       "  'From: tessmann@cs.ubc.ca (Markus Tessmann)\\nSubject: Re: Rumours about 3DO ???\\nOrganization: Computer Science, University of B.C., Vancouver, B.C., Canada\\nLines: 16\\nNNTP-Posting-Host: larry.cs.ubc.ca\\n\\nstgprao@st.unocal.COM (Richard Ottolini) writes:\\n\\n',\n",
       "  'stgprao@st.unocal.COM (Richard Ottolini) writes:\\n\\n>They need a hit software product to encourage software sales of the product,\\n>i.e. the Pong, Pacman, VisiCalc, dBase, or Pagemaker of multi-media.\\n>There are some multi-media and digital television p',\n",
       "  \"here are some multi-media and digital television products out there already,\\n>albeit, not as capable as 3DO's.  But are there compelling reasons to buy\\n>such yet?  Perhaps someone in this news group will write that hit software :-)\\n\\nI've just had the\",\n",
       "  \"ill write that hit software :-)\\n\\nI've just had the good fortune to be hired by Electronic Arts as Senior\\nComputer Graphics Artist at the Vancouver, Canada office.  :^)\\n\\nThe timing has a lot to do with the 3DO which EA is putting a lot of resources\\nin\",\n",
       "  ' the 3DO which EA is putting a lot of resources\\ninto.  I do not know of any titles to be developed as yet but will be happy to\\npost as things develop.  I start there May 3.\\n\\n\\tMarkus Tessmann\\n',\n",
       "  'From: johnsh@rpi.edu (Hugh Johnson)\\nSubject: Re: QuickTime movie available\\nArticle-I.D.: mustang.johnsh-060493161931\\nOrganization: Rensselaer Polytechnic Institute\\nLines: 31\\nNntp-Posting-Host: mustang.stu.rpi.edu\\n\\nIn article <johnsh-040493161915@must',\n",
       "  '.stu.rpi.edu\\n\\nIn article <johnsh-040493161915@mustang.stu.rpi.edu>, I wrote:\\n> \\n> I\\'ve used the recently-released Macintosh application MPEG to QuickTime to\\n> convert the excellent MPEG \"canyon.mpg\" into a QuickTime movie.  While\\n> anyone who would w',\n",
       "  \"nto a QuickTime movie.  While\\n> anyone who would want this movie is perfectly able to convert it\\n> themselves, I thought I'd let the net know that I'd be glad to mail copies\\n> of mine out.  The movie conversion took close to SIX HOURS on my poor\\n> li\",\n",
       "  \"conversion took close to SIX HOURS on my poor\\n> little IIcx; in other words, unless you've got a Quadra, you might not want\\n> to tie up your machine in converting this file.\\n> \\n> The movie is a fast fly-through of a fractal-generated canyon landscape\",\n",
       "  'ly-through of a fractal-generated canyon landscape. \\n> The movie is 58 seconds long, and uses the compact video compressor (i.e.,\\n> QuickTime v1.5).  The movie looks okay on 8-bit displays, and looks\\n> absolutely awesome on 16- and 24-bit displays.\\n>',\n",
       "  \"> absolutely awesome on 16- and 24-bit displays.\\n> \\n> I'd be happy to mail this movie to the first 20 or so people who ask for\\n> it.  The only caveat is you need to be able to receive a nine-megabyte mail\\n> message (the movie was stuff-it'ed down to \",\n",
       "  \"mail\\n> message (the movie was stuff-it'ed down to seven megs, but binhex ruined\\n> that party).  If more then 20 people want this movie, then it's just more\\n> evidence that the net needs a dedicated QuickTime FTP archive site.  C'mon,\\n> someone's gott\",\n",
       "  \"ickTime FTP archive site.  C'mon,\\n> someone's gotta have a spare 1.2GB drive out there...\\n\\nOkay, I've received a whole lot of requests for the movie, so for\\nsimplicity's sake I can't mail out any more than I've already received (as\\nof 16:30 EDT, Tues\",\n",
       "  \" than I've already received (as\\nof 16:30 EDT, Tuesday).  Maybe it'll pop up on a site sooner or later.\\n\\n==============================================================================\\nHugh Johnson (johnsh@rpi.edu)    | \\nRensselaer Polytechnic Institut\",\n",
       "  'nsh@rpi.edu)    | \\nRensselaer Polytechnic Institute |            Welcome to Macintosh.\\nTroy, New York, USA              |\\n==============================================================================\\n',\n",
       "  '\\n',\n",
       "  'From: george@ccmail.larc.nasa.gov (George M. Brown)\\nSubject: QC/MSC code to view/save images\\nOrganization: Client Specific Systems, Inc.\\nLines: 12\\nNNTP-Posting-Host: thrasher.larc.nasa.gov\\n\\nDear Binary Newsers,\\n\\nI am looking for Quick C or Microsoft ',\n",
       "  'y Newsers,\\n\\nI am looking for Quick C or Microsoft C code for image decoding from file for\\nVGA viewing and saving images from/to GIF, TIFF, PCX, or JPEG format. I have\\nscoured the Internet, but its like trying to find a Dr. Seuss spell checker \\nTSR. I',\n",
       "  \"e trying to find a Dr. Seuss spell checker \\nTSR. It must be out there, and there's no need to reinvent the wheel.\\n\\nThanx in advance.\\n\\n//////////////\\n\\n The Internet is like a Black Hole....\\n\",\n",
       "  'Subject: AutoCAD -> TIFF Can it be done????\\nFrom: cvadrmaz@vmsb.is.csupomona.edu\\nOrganization: California State Polytechnic University, Pomona\\nNntp-Posting-Host: acvax2\\nNntp-Posting-User: cvadrmaz\\nLines: 9\\n\\nHello, I realize that this might be a FAQ b',\n",
       "  \"es: 9\\n\\nHello, I realize that this might be a FAQ but I have to ask since I don't get a\\nchange to read this newsgroup very often.  Anyways for my senior project I need\\nto convert an AutoCad file to a TIFF file.  Please I don't need anyone telling\\nme t\",\n",
       "  \"IFF file.  Please I don't need anyone telling\\nme that the AutoCAD file is a vector file and the TIFF is a bit map since I\\nhave heard that about 100 times already I would just like to know if anyone\\nknows how to do this or at least point me to the rig\",\n",
       "  'ows how to do this or at least point me to the right direction.\\n\\nAny help greatly appreciated,\\nMatt Georgy\\n',\n",
       "  'From: amjad@eng.umd.edu (Amjad A Soomro)\\nSubject: Gamma-Law Correction\\nOrganization: Project GLUE, University of Maryland, College Park\\nLines: 22\\nDistribution: USA\\nExpires: 05/15/93\\nNNTP-Posting-Host: filter.eng.umd.edu\\n\\nHi:\\n\\nI am digitizing a NTSC s',\n",
       "  ' filter.eng.umd.edu\\n\\nHi:\\n\\nI am digitizing a NTSC signal and displaying on a PC video monitor.\\nIt is known that the display response of tubes is non-linear and is\\nsometimes said to follow Gamma-Law. I am not certain if these\\nnon-linearities are \"Gamma',\n",
       "  'am not certain if these\\nnon-linearities are \"Gamma-corrected\" before encoding NTSC signals\\nor if the TV display is supposed to correct this.\\n \\nAlso, if  256 grey levels, for example, are coded in a C program do\\nthese intensity levels appear with line',\n",
       "  'program do\\nthese intensity levels appear with linear brightness on a PC\\nmonitor? In other words does PC monitor display circuitry\\ncorrect for \"gamma errrors\"?\\n \\nYour response is much appreciated.\\n \\nAmjad.\\n\\nAmjad Soomro\\nCCS, Computer Science Center\\nU.',\n",
       "  'jad.\\n\\nAmjad Soomro\\nCCS, Computer Science Center\\nU. of Maryland at College Park\\nemail: amjad@wam.umd.edu\\n\\n',\n",
       "  'From: mlee@eng.sdsu.edu (Mike Lee)\\nSubject: MPEG for x-windows MONO needed.\\nOrganization: San Diego State University Computing Services\\nLines: 4\\nNNTP-Posting-Host: eng.sdsu.edu\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nHello, and thank you for reading thi',\n",
       "  'ion 1.1 PL9]\\n\\nHello, and thank you for reading this request.  I have a Mpeg viewer for x-windows and it did not run because I was running it on a monochrome monitor.  I need the mono-driver for mpeg_play.   \\n\\nPlease post the location of the file or b',\n",
       "  'lay.   \\n\\nPlease post the location of the file or better yet, e-mail me at mlee@eng.sdsu.edu.\\n\\n',\n",
       "  'From: ab@nova.cc.purdue.edu (Allen B)\\nSubject: Re: thining algorithm\\nOrganization: Purdue University\\nLines: 15\\n\\nIn article <1q7615INNmi@shelley.u.washington.edu> kshin@stein.u.washington.edu  \\n(Kevin Shin) writes:\\n> I am trying obtain program to prep',\n",
       "  'Shin) writes:\\n> I am trying obtain program to preprocess handwriting characters.\\n> Like thining algorithm, graph alogrithm.\\n> Do anyone know where I can obtain those?\\n\\nI usually use \"Algorithms for graphics and image processing\" by\\nTheodosios Pavlidi',\n",
       "  'aphics and image processing\" by\\nTheodosios Pavlidis, but other people here got them same idea and now\\n3 of 4 copies in the libraries have been stolen!\\n\\nAnother reference is \"Digital Image Processing\" by Gonzalez and\\nWintz/Wood, which is widely availa',\n",
       "  'by Gonzalez and\\nWintz/Wood, which is widely available but a little expensive ($55\\nhere- I just checked today).\\n\\nab\\n',\n",
       "  'From: ab@nova.cc.purdue.edu (Allen B)\\nSubject: Re: TIFF: philosophical significance of 42\\nOrganization: Purdue University\\nLines: 20\\n\\nIn article <1993Apr10.160929.696@galki.toppoint.de> ulrich@galki.toppoint.de  \\nwrites:\\n> According to the TIFF 5.0 Sp',\n",
       "  'ppoint.de  \\nwrites:\\n> According to the TIFF 5.0 Specification, the TIFF \"version number\"\\n> (bytes 2-3) 42 has been chosen for its \"deep philosophical \\n> significance\".\\n> Last week, I read the Hitchhikers Guide To The Galaxy,\\n> Is this actually how th',\n",
       "  \"ers Guide To The Galaxy,\\n> Is this actually how they picked the number 42?\\n\\nI'm sure it is, and I am not amused.  Every time I read that part of the\\nTIFF spec, it infuriates me- and I'm none too happy about the\\ncomplexity of the spec anyway- because \",\n",
       "  ' about the\\ncomplexity of the spec anyway- because I think their \"arbitrary but\\ncarefully chosen number\" is neither.  Additionally, I find their\\nchoice of 4 bytes to begin a file with meaningless of themselves- why\\nnot just use the letters \"TIFF\"?\\n\\n(A',\n",
       "  'emselves- why\\nnot just use the letters \"TIFF\"?\\n\\n(And no, I don\\'t think they should have bothered to support both word\\norders either- and I\\'ve found that many TIFF readers actually\\ndon\\'t.)\\n\\nab\\n',\n",
       "  'From: rob@rjck.UUCP (Robert J.C. Kyanko)\\nSubject: Re: VGA 640x400 graphics mode\\nDistribution: world\\nOrganization: Neptune Software Inc\\nLines: 15\\n\\ngchen@essex.ecn.uoknor.edu writes in article <C55DoH.2AI@constellation.ecn.uoknor.edu>:\\n> \\n> Greetings!\\n',\n",
       "  \"AI@constellation.ecn.uoknor.edu>:\\n> \\n> Greetings!\\n> \\n> Does anybody know if it is possible to set VGA graphics mode to 640x400\\n> instead of 640x480?  Any info is appreciated!\\n\\nSome VESA bios's support this mode (0x100).  And *any* VGA should be able \",\n",
       "  \" this mode (0x100).  And *any* VGA should be able to\\nsupport this (640x480 by 256 colors) since it only requires 256,000 bytes.\\nMy 8514/a VESA TSR supports this; it's the only VESA mode by card can support\\ndue to 8514/a restrictions. (A WD/Paradise)\\n\",\n",
       "  \"pport\\ndue to 8514/a restrictions. (A WD/Paradise)\\n\\n--\\nI am not responsible for anything I do or say -- I'm just an opinion.\\n             Robert J.C. Kyanko (rob@rjck.UUCP)\\n\",\n",
       "  'From: rob@rjck.UUCP (Robert J.C. Kyanko)\\nSubject: Re: Weitek P9000 ?\\nDistribution: world\\nOrganization: Neptune Software Inc\\nLines: 23\\n\\nabraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> \\n> Anyone know about the Weitek P90',\n",
       "  \"astate.edu>:\\n> \\n> Anyone know about the Weitek P9000 graphics chip?\\n> Micron is selling it with their systems They rank them at 50 winmarks...\\n> Any info would help...\\n> thanks.\\n\\nIt's supposedly a high-performance chip based upon workstation graphics\",\n",
       "  \"h-performance chip based upon workstation graphics\\naccelerators.  It's quite fast (I have 7), but as usual with new boards/chips\\nthe drivers are buggy for Windows.  As far as Winmarks go, it depends upon\\nthe version.  I think I got 42M winmarks with \",\n",
       "  \"pon\\nthe version.  I think I got 42M winmarks with version 3.11.  2.5 yielded the\\n50+ number.  I've also benchmarked this with Wintach at over 65 (from memory\\nas well).\\n\\nAs far as the low-level stuff goes, it looks pretty nice.  It's got this\\nquadrila\",\n",
       "  \"oes, it looks pretty nice.  It's got this\\nquadrilateral fill command that requires just the four points.\\n\\nIt's very fast, but beware of buggy drivers, and otherwise no non-windows\\nsupport.\\n\\n--\\nI am not responsible for anything I do or say -- I'm just\",\n",
       "  \"t responsible for anything I do or say -- I'm just an opinion.\\n             Robert J.C. Kyanko (rob@rjck.UUCP)\\n\",\n",
       "  'From: lewism@aix.rpi.edu (Michael C. Lewis)\\nSubject: Re: Delaunay Triangulation\\nNntp-Posting-Host: aix.rpi.edu\\nOrganization: Rensselaer Polytechnic Institute, Troy, NY\\nLines: 16\\n\\nIn article <lsk1v9INN93c@caspian.usc.edu> zyeh@caspian.usc.edu (zhengha',\n",
       "  \"93c@caspian.usc.edu> zyeh@caspian.usc.edu (zhenghao yeh) writes:\\n>\\n>Does anybody know what Delaunay Triangulation is?\\n>Is there any reference to it? \\n>Is it useful for creating 3-D objects? If yes, what's the advantage?\\n\\nIt is used to create a TIN (t\",\n",
       "  \"at's the advantage?\\n\\nIt is used to create a TIN (triangulated irregular network), which is\\nbasically a bunch of triangles which form a surface over a group of\\npoints.  What is special about it is that the triangles formed are the \\nmost equalateral po\",\n",
       "  ' the triangles formed are the \\nmost equalateral possible.  Check out \"Proceedings of AutoCarto N\" where\\nN is 8..10.  Sorry, I don\\'t have a specific reference describing the\\nprocess.\\n-Michael\\n\\n\\n\\n',\n",
       "  'From: rubery@saturn.aitc.rest.tasc.com. (Dan Rubery)\\nSubject: Graphic Formats\\nOrganization: TASC\\nLines: 7\\nNNTP-Posting-Host: saturn.aitc.rest.tasc.com\\n\\nI am writing some utilies to convert Regis and Tektonic esacpe sequences  \\ninto some useful format',\n",
       "  'ektonic esacpe sequences  \\ninto some useful formats. I would rather not have to goto a bitmap format.  \\nI can convert them to Window Meta FIles easily enough, but I would rather  \\nconvert them to Corel Draw, .CDR, or MS Power Point, .PPT, files.  \\nMi',\n",
       "  'l Draw, .CDR, or MS Power Point, .PPT, files.  \\nMicrosoft would not give me the format. I was wondering if anybody out  \\nthere knows the formats for these two applications.\\n\\n',\n",
       "  'From: aad@scr.siemens.com (Anthony A. Datri)\\nSubject: Re: Nice gif code\\nNntp-Posting-Host: lovecraft.siemens.com\\nOrganization: Siemens Weyland-Yutani\\nLines: 7\\n\\n>There is a thing called xgif\\n\\nxgif is the grandfather of XV.\\n\\n-- \\n\\n======================',\n",
       "  'he grandfather of XV.\\n\\n-- \\n\\n======================================================================8--<\\n',\n",
       "  \"From: fischer@iesd.auc.dk (Lars Peter Fischer)\\nSubject: Re: Rumours about 3DO ???\\nIn-Reply-To: archer@elysium.esd.sgi.com's message of 6 Apr 93 18:18:30 GMT\\nOrganization: Mathematics and Computer Science, Aalborg University\\n\\t<C51Eyz.4Ix@optimla.aimla\",\n",
       "  'nce, Aalborg University\\n\\t<C51Eyz.4Ix@optimla.aimla.com> <1993Apr6.144520.2190@unocal.com>\\n\\t<h48vtis@zola.esd.sgi.com>\\nLines: 11\\n\\n\\n>>>>> \"Archer\" == Archer (Bad Cop) Surly (archer@elysium.esd.sgi.com)\\n\\nArcher> How about \"Interactive Sex with Madonna\"?',\n",
       "  '\\nArcher> How about \"Interactive Sex with Madonna\"?\\n\\nor \"Sexium\" for short.\\n\\n/Lars\\n--\\nLars Fischer, fischer@iesd.auc.dk | It takes an uncommon mind to think of\\nCS Dept., Aalborg Univ., DENMARK. | these things.  -- Calvin\\n',\n",
       "  ' things.  -- Calvin\\n',\n",
       "  'From: crash@ckctpa.UUCP (Frank \"Crash\" Edwards)\\nSubject: Re: forms for curses\\nReply-To: crash%ckctpa@myrddin.sybus.com (Frank \"Crash\" Edwards)\\nOrganization: Edwards & Edwards Consulting\\nLines: 40\\n\\nNote the Followup-To: header ...\\n\\nsteelem@rintintin.C',\n",
       "  \"e the Followup-To: header ...\\n\\nsteelem@rintintin.Colorado.EDU (STEELE MARK A) writes:\\n>Is there a collection of forms routines that can be used with curses?\\n>If so where is it located?\\n\\nOn my SVR4 Amiga Unix box, I've got -lform, -lmenu, and -lpanel \",\n",
       "  \"ga Unix box, I've got -lform, -lmenu, and -lpanel for\\nuse with the curses library.  Guess what they provide? :-)\\n\\nUnix Press, ie. Prentice-Hall, has a programmer's guide for these\\ntools, referred to as the FMLI (Forms Mgmt Language Interface) and\\nETI\",\n",
       "  \"s the FMLI (Forms Mgmt Language Interface) and\\nETI (Extended Terminal Interface), now in it's 2nd edition.  It is\\nISBN 0-13-020637-7.\\n\\nParaphrased from the outside back cover:\\n\\n    FMLI is a high-level programming tool for creating menus, forms,\\n    \",\n",
       "  'l programming tool for creating menus, forms,\\n    and text frames.  ETI is a set of screen management library\\n    subroutines that promote fast development of application programs\\n    for window, panel, menu, and form manipulation.\\n\\nThe FMLI is a she',\n",
       "  'l, menu, and form manipulation.\\n\\nThe FMLI is a shell package which reads ascii text files and produces\\nscreen displays for data entry and presentation.  It consists of a\\n\"shell-like\" environment of the \"fmli\" program and it\\'s database\\nfiles.  It is s',\n",
       "  'e \"fmli\" program and it\\'s database\\nfiles.  It is section 1F in the Unix Press manual.\\n\\nThe ETI are subroutines, part of the 3X manual section, provide\\nsupport for a multi-window capability on an ordinary ascii terminal\\nwith controls built on top of t',\n",
       "  'ary ascii terminal\\nwith controls built on top of the curses library.\\n\\n>Thanks\\n>-Mark Steele\\n>steelem@rintintin.colorado.edu\\n\\n-- \\nFrank \"Crash\" Edwards          Edwards & Edwards Consulting\\nVoice: 813/786-3675            crash%ckctpa@myrddin.sybus.com',\n",
       "  \"786-3675            crash%ckctpa@myrddin.sybus.com, but please\\nData:  813/787-3675            don't ask UUNET to route it -- it's sloooow.\\n    There will be times in life when everyone you meet smiles and pats you on\\n    the back and tells you how gr\",\n",
       "  ' and pats you on\\n    the back and tells you how great you are ... so hold on to your wallet.\\n',\n",
       "  'From: millernw@craft.camp.clarkson.edu (Neal Miller)\\nSubject: Re: Trying to view POV files.....\\nNntp-Posting-Host: craft.clarkson.edu\\nOrganization: Clarkson University\\nLines: 31\\n\\nmerkelbd@sage.cc.purdue.edu (Brian Merkel) writes:\\n\\n>In article <1993Ap',\n",
       "  \"ue.edu (Brian Merkel) writes:\\n\\n>In article <1993Apr11.132604.13400@ornl.gov> ednobles@sacam.OREN.ORTN.EDU (Edward d Nobles) writes:\\n>>\\n>>I've been trying to view .tga files created in POVRAY.  I have the Diamond\\n>>SpeedStar 24 Video board (not the _2\",\n",
       "  \"the Diamond\\n>>SpeedStar 24 Video board (not the _24X_).  So far I can convert them to\\n>>jpeg using cjpeg and view them with CVIEW but that only displays 8 bit color.\\n>>\\n>>I'm looking for some way to convert and/or view them in 24 bit.\\n>>\\n>>I have UNI\",\n",
       "  \"onvert and/or view them in 24 bit.\\n>>\\n>>I have UNIVESA (uvesa31.zip) and the DVPEG viewer but I don't get anything.\\n>>Perhaps I am not setting up UNIVESA properly?  If anyone has ideas about this\\n>>please feel free to enlighten me...\\n>>\\n>>Just want t\",\n",
       "  'ease feel free to enlighten me...\\n>>\\n>>Just want to see the darn things in real color...\\n\\n>Image Alchemy (aka alchemy) will view the TGA files that POV outputs\\n> and just about any other format you can think of. It will also convert\\n> between all the',\n",
       "  \"n think of. It will also convert\\n> between all these. It's shareware, so it's probably available by FTP\\n> somwhere out there in netland...\\n\\n        Yep... Alchemy works fine on my Tseng400+DAC, but I think I remember\\nreading that it only displays in \",\n",
       "  \"think I remember\\nreading that it only displays in 15-bit or so.  Of course, that's still 32K\\ncolors which is nothing to sneeze at.  Use the --v flag.\\n\\n\\n--\\n-----------------------------------------------------------------------------\\n Neal Miller     \",\n",
       "  '--------------------------------\\n Neal Miller         | \"Why not go mad?\"  | millernw@craft.camp.clarkson.edu\\n Clarkson University |     - Ford Prefect |     dark@craft.camp.clarkson.edu\\n---------------------------------------------------------------',\n",
       "  '----------------------------------------------------------------\\n',\n",
       "  \"From: trb3@Ra.MsState.Edu (Tony R. Boutwell)\\nSubject: HOT NEW 3D Software\\nKeywords: Imagine,3d\\nNntp-Posting-Host: ra.msstate.edu\\nOrganization: Mississippi State University\\nLines: 20\\n\\nThere is a new product for the (IBM'ers) out there... it is called\\n\",\n",
       "  \"oduct for the (IBM'ers) out there... it is called\\nIMAGINE and it just started shipping yesterday... I can personally attest that it will blow the doors off of 3D-Studio.  It is made by IMPUlSE, and is in its\\n3rd version....(1st) for the IBM.... it ca\",\n",
       "  ' in its\\n3rd version....(1st) for the IBM.... it can do morphing, your standard key-framming animation, it is a raytracer (reflections & shadows), and can do/apply special FX to objects... (like ripple, explode, bounce) things of that nature.  Also it',\n",
       "  ', explode, bounce) things of that nature.  Also it has algorithmic texture maps....and your standard brushmapping also...\\n\\nyou can have animated brushmaps...(ie. live video mapped on the objs)...\\nalso animated backdrops (ie. live video backgrounds)\\na',\n",
       "  ' animated backdrops (ie. live video backgrounds)\\nalso animted reflections maps....\\n\\nyou get the idea.... it will run for about 500$ retail (I think)...\\n\\ndont let the low price fool you.... this product can do it all when it\\ncomes to 3D-animation and ',\n",
       "  't can do it all when it\\ncomes to 3D-animation and Renderering...!\\n\\nalso....does anyone here know how to get in the Imagine mailing list??\\nplease e-mail me if you do or post up here....\\n\\noh...the number for IMPULSE is --->1 800 328 0184\\n\\ntrb3@ra.mssta',\n",
       "  'r for IMPULSE is --->1 800 328 0184\\n\\ntrb3@ra.msstate.edu\\n\\n',\n",
       "  'From: mbc@po.CWRU.Edu (Michael B. Comet)\\nSubject: Re: HOT NEW 3D Software\\nOrganization: Case Western Reserve University, Cleveland, OH (USA)\\nLines: 34\\nReply-To: mbc@po.CWRU.Edu (Michael B. Comet)\\nNNTP-Posting-Host: thor.ins.cwru.edu\\n\\n\\nIn a previous a',\n",
       "  \"-Posting-Host: thor.ins.cwru.edu\\n\\n\\nIn a previous article, trb3@Ra.MsState.Edu (Tony R. Boutwell) says:\\n\\n>There is a new product for the (IBM'ers) out there... it is called\\n>IMAGINE and it just started shipping yesterday... I can personally attest tha\",\n",
       "  \" shipping yesterday... I can personally attest that it will blow the doors off of 3D-Studio.  It is made by IMPUlSE, and is in its\\n>\\n\\tWell....I don't know about its competing with 3D studio, but\\nit's pretty powerful allright.\\n\\n>\\n>also....does anyone \",\n",
       "  'pretty powerful allright.\\n\\n>\\n>also....does anyone here know how to get in the Imagine mailing list??\\n>please e-mail me if you do or post up here....\\n>\\n\\n\\tYes, send e-mail to:\\n\\n\\timagine-request@email.sp.paramax.com\\n\\n\\tWith a header of something like sub',\n",
       "  '.paramax.com\\n\\n\\tWith a header of something like subscribe.\\n\\n\\n\\tI actually work on the FAQ (frequently asked questions).  We\\nshould have the new version out of it by next week, but if you want, I\\ncould e-mail you the previous one.  It details what the l',\n",
       "  '-mail you the previous one.  It details what the list is etc...\\nas well as answering basic questions about Imagine.\\n\\n\\tHope this helps!\\n\\n\\n-- \\n+======================================================================+\\n|  Michael B. Comet -   Software Eng',\n",
       "  '============+\\n|  Michael B. Comet -   Software Engineer / Graphics Artist  - CWRU    |\\n|  mbc@po.CWRU.Edu  - \"Silence those who oppose the freedom of speech\" |\\n+======================================================================+\\n',\n",
       "  '===============================+\\n',\n",
       "  'From: dutc0006@student.tc.umn.edu (David J Dutcher-1)\\nSubject: Re: VGA 640x400 graphics mode\\nNntp-Posting-Host: student.tc.umn.edu\\nOrganization: University of Minnesota\\nLines: 23\\n\\nIn article <734553308snx@rjck.UUCP> rob@rjck.UUCP (Robert J.C. Kyanko)',\n",
       "  '8snx@rjck.UUCP> rob@rjck.UUCP (Robert J.C. Kyanko) writes:\\n>gchen@essex.ecn.uoknor.edu writes in article <C55DoH.2AI@constellation.ecn.uoknor.edu>:\\n>> \\n>> Greetings!\\n>> \\n>> Does anybody know if it is possible to set VGA graphics mode to 640x400\\n>> in',\n",
       "  \"possible to set VGA graphics mode to 640x400\\n>> instead of 640x480?  Any info is appreciated!\\n>\\n>Some VESA bios's support this mode (0x100).  And *any* VGA should be able to\\n>support this (640x480 by 256 colors) since it only requires 256,000 bytes.\\n\",\n",
       "  \"256 colors) since it only requires 256,000 bytes.\\n>My 8514/a VESA TSR supports this; it's the only VESA mode by card can support\\n>due to 8514/a restrictions. (A WD/Paradise)\\n>\\n>--\\n>I am not responsible for anything I do or say -- I'm just an opinion.\",\n",
       "  \"e for anything I do or say -- I'm just an opinion.\\n>             Robert J.C. Kyanko (rob@rjck.UUCP)\\n\\n\\tAhh no.  Possibly you punched in the wrong numbers on your\\ncalculator.  256 color modes take a byte per pixel so 640 time 480 is\\n307,200 which is 30\",\n",
       "  \"e per pixel so 640 time 480 is\\n307,200 which is 300k to be exact.  640x400x256 only takes 250k but I\\ndon't think it is a BIOS mode.  I wouldn't bet that all VGA cards can do\\nthat either.  If a VGA card has 512k I bet it can do both 640x400 and\\n640x48\",\n",
       "  'd has 512k I bet it can do both 640x400 and\\n640x480.  That by definition is SVGA, though not very high SVGA.\\n',\n",
       "  'From: pvconway@cudnvr.denver.colorado.edu\\nSubject: TIN files & coutours\\nLines: 15\\n\\n\\nHi!\\n\\tI am working on a project that needs to create contour lines\\nfrom random data points.  The work that I have done so far tells me that I\\nneed to look into Triangu',\n",
       "  'e so far tells me that I\\nneed to look into Triangulated Irregular Networks (TIN), the Delauney\\ncriiterion, and the Krige method.  Does anyone have any suggestions for\\nreferences, programs and hopefully source code for creating contours.  Any\\nhelp wit',\n",
       "  'y source code for creating contours.  Any\\nhelp with this or any surface modeling would be greatly appreciated.\\nI can be reached at the addresses below:\\n\\n\\n\\t\\t\\t-- Paul Conway\\n\\nPVCONWAY@COPPER.DENVER.COLORADO.EDU\\nPVCONWAY@CUDNVR.DENVER.COLORADO.EDU\\n',\n",
       "  'RADO.EDU\\nPVCONWAY@CUDNVR.DENVER.COLORADO.EDU\\n',\n",
       "  \"From: mccool@dgp.toronto.edu (Michael McCool)\\nSubject: Apr 20 Toronto Siggraph Event\\nOrganization: University of Toronto Dynamic Graphics Project\\nDistribution: na\\nLines: 48\\n\\n\\nToronto Siggraph \\n================\\n\\nWhat: ``Chance's Art'': 2D Graphics and\",\n",
       "  \"=========\\n\\nWhat: ``Chance's Art'': 2D Graphics and Animation on the Indigo.\\n\\nBy:    Ken Evans, Imagicians Artware, Inc. \\n\\nWhen:  Tuesday 20 April 1993 7:00pm-9:00pm \\n\\nWhere: The McLuhan Centre for Culture and Technology\\n       University of Toronto\\n \",\n",
       "  \"ture and Technology\\n       University of Toronto\\n       39A Queen's Park Crescent\\n       Toronto\\n\\nWho:   Members and non-members alike \\n       (non-members encouraged to become members...)\\n\\nAbstract:\\n\\nImagicians Artware, Inc. is entering into early b\",\n",
       "  \"\\nImagicians Artware, Inc. is entering into early beta site testing on Silicon \\nGraphics workstations of a new 2D abstract artwork and animation package called \\nChance's Art.  The package will be described and demonstrated, and some of the \\ntechnical \",\n",
       "  'ibed and demonstrated, and some of the \\ntechnical issues will be discussed.  Marketing plans will be outlined.  The \\ntalk will also present some of the technical and business problems increasingly \\nconfronting small startup software companies today, ',\n",
       "  'nfronting small startup software companies today, and some of the \\nopportunities this situation presents.\\n\\nTime after the event will be allocated for hands-on demonstrations to \\ninterested parties.  Silicon Graphics is graciously providing an Indigo ',\n",
       "  'ilicon Graphics is graciously providing an Indigo for \\nthis event.  Myck Kupka will also be demonstrating his computerized interactive \\nreflective stereoscope, which is installed upstairs in the McLuhan Centre, so \\nfeel free to drop by for a demonstr',\n",
       "  'an Centre, so \\nfeel free to drop by for a demonstration before or after the event. BTW, be \\nsure to sing \"Happy Birthday, Myck\"...\\n\\nThe names of nominees for our Siggraph executive offices will be announced at \\nthis meeting.  Nominations will still b',\n",
       "  \"ounced at \\nthis meeting.  Nominations will still be open until the election at our \\nMay 18th event; call Myck Kupka at 465-0943 or fax to 465-0729.  \\n\\nDirections: The McLuhan Coachhouse is on the east side of Queen's Park \\nCrescent, just NORTH of Wel\",\n",
       "  \" side of Queen's Park \\nCrescent, just NORTH of Wellesley, SOUTH of St. Joseph St., BEHIND (EAST of) \\n39 Queen's Park Crescent, which is the centre for Mediaeval Studies.  \\n\\nFor information on Toronto Siggraph membership, contact Michael McCool via:\\n\\t\",\n",
       "  'Siggraph membership, contact Michael McCool via:\\n\\tInternet: mccool@dgp.utoronto.ca; \\n\\tVoice: 652-8072/978-6619/978-6027; \\n\\tFax: 653-1654\\n\\n',\n",
       "  'From: Dave Watson <watson@maths.uwa.edu.au>\\nSubject: Re: Delaunay Triangulation\\nOrganization: The University of Western Australia\\nLines: 29\\nDistribution: world\\nReply-To: watson@maths.uwa.edu.au\\nNNTP-Posting-Host: madvax.maths.uwa.oz.au\\n\\nzyeh@caspian.',\n",
       "  'osting-Host: madvax.maths.uwa.oz.au\\n\\nzyeh@caspian.usc.edu (zhenghao yeh) writes:\\n\\n>Does anybody know what Delaunay Triangulation is?\\n>Is there any reference to it? \\n\\nThe Delaunay triangulation is the geometrical dual of the \\nVoronoi tessellation and ',\n",
       "  'geometrical dual of the \\nVoronoi tessellation and both constructions are derived from\\nnatural neighbor order.\\n\\nAurenhammer, F., 1991, Voronoi Diagrams - A Survey of a \\nFundamental Geometric Data Structure:\\nACM Computing Surveys, 23(3), p. 345-405. \\n\\n',\n",
       "  'ture:\\nACM Computing Surveys, 23(3), p. 345-405. \\n\\nOkabe, A., Boots, B., and Sugihara, K., 1992, Spatial \\ntessellations : concepts and applications of Voronoi diagrams: \\nWiley & Sons, New York, ISBN 0 471 93430 5, 532p.\\n\\nWatson, D.F., 1981, Computing ',\n",
       "  '471 93430 5, 532p.\\n\\nWatson, D.F., 1981, Computing the n-dimensional Delaunay \\ntessellation with application to Voronoi polytopes: \\nThe Computer J., 24(2), p. 167-172.}\\n\\nWatson, D.F., 1985, Natural neighbour sorting: The Australian \\nComputer J., 17(4)',\n",
       "  'ghbour sorting: The Australian \\nComputer J., 17(4), p. 189-193. \\n\\n--\\nDave Watson                          Internet: watson@maths.uwa.edu.au\\nDepartment of Mathematics            \\nThe University of Western Australia               Tel: (61 9) 380 3359\\nN',\n",
       "  'ern Australia               Tel: (61 9) 380 3359\\nNedlands, WA 6009  Australia.                     FAX: (61 9) 380 1028\\n',\n",
       "  'From: hrs1@cbnewsi.cb.att.com (herman.r.silbiger)\\nSubject: ANSI/AIIM MS-53 Standard Image File Format\\nOrganization: AT&T\\nKeywords: image, file format\\nLines: 6\\n\\n\\nwing the suggestion of Stu Lynne, I have posted the Image File Format executable and sour',\n",
       "  'e posted the Image File Format executable and source code to alt.sources.\\n\\nHerman Silbiger\\n.\\n\\n',\n",
       "  \"From: ccraig@nmt.edu (Catherine Craig)\\nSubject: Re: Trying to view POV files.....\\nOrganization: New Mexico Tech\\nLines: 23\\n\\nIn article <1993Apr11.132604.13400@ornl.gov> ednobles@sacam.OREN.ORTN.EDU (Edward d Nobles) writes:\\n>\\n>I've been trying to view\",\n",
       "  \"ward d Nobles) writes:\\n>\\n>I've been trying to view .tga files created in POVRAY.  I have the Diamond\\n>SpeedStar 24 Video board (not the _24X_).  So far I can convert them to\\n>jpeg using cjpeg and view them with CVIEW but that only displays 8 bit colo\",\n",
       "  \" them with CVIEW but that only displays 8 bit color.\\n>\\n>I'm looking for some way to convert and/or view them in 24 bit.\\n>\\n>\\n>Just want to see the darn things in real color...\\n>\\n>Thanks,\\n>\\n>Jim Nobles\\n>\\n\\nThe best program I've seen for viewing such fil\",\n",
       "  \">\\n\\nThe best program I've seen for viewing such files is VPIC.  You'll want version 5.9 or later.  (6.0x is current.)  It allows you to view in 15 and 24 bit modes.  It really is QUITE nice.\\n\\nNow, for a return question:  Do you run Windows?  If so, wh\",\n",
       "  \"a return question:  Do you run Windows?  If so, what are the dates on your drivers?  The newest ones *I* can find are from around 4-??-92!!  My problem is they conflict with Star Trek: After Dark, and other things as well.  I'm willing to bet that it\",\n",
       "  \" other things as well.  I'm willing to bet that it's the drivers, and NOT the programs.  Anyone out there have info on newer SS24 (NOT X) drivers for windows or OS/2?\\n\\nThanks,\\n\\tJustin\\n\\n\",\n",
       "  'From: graeme@labtam.labtam.oz.au (Graeme Gill)\\nSubject: Re: looking for circle algorithm faster than Bresenhams\\nOrganization: Labtam Australia Pty. Ltd., Melbourne, Australia\\nLines: 28\\n\\nIn article <1993Apr13.025240.8884@nwnexus.WA.COM>, mpdillon@halc',\n",
       "  '93Apr13.025240.8884@nwnexus.WA.COM>, mpdillon@halcyon.com (Michael Dillon) writes:\\n> I have an algorithm similar to Bresenhams line drawing algorithm, that\\n> draws a line by stepping along the minor axis and drawing slices like\\n> AAAA, BBBB, CCCC in ',\n",
       "  'xis and drawing slices like\\n> AAAA, BBBB, CCCC in the following diagram.\\n> \\n>      AAAA\\n>          BBBB\\n>              CCCC\\n> \\n\\n\\tYes, that\\'s known as \"Bresenhams Run Length Slice Algorithm for\\nIncremental lines\". See Fundamental Algorithms for Comput',\n",
       "  'ntal lines\". See Fundamental Algorithms for Computer Graphics,\\nSpringer-Verlag, Berlin Heidelberg 1985.\\n\\n> I have tried to extrapolate this to circles but I can\\'t figure out\\n> how to determine the length of the slices. Any ideas?\\n\\n\\tHmm. I don\\'t think',\n",
       "  'gth of the slices. Any ideas?\\n\\n\\tHmm. I don\\'t think I can help you with this, but you might\\ntake a look at the following:\\n\\n\\t\"Double-Step Incremental Generation of Lines and Circles\",\\nX. Wu and J. G. Rokne, Computer Graphics and Image processing,\\nVol 3',\n",
       "  'kne, Computer Graphics and Image processing,\\nVol 37, No. 4, Mar. 1987, pp. 331-334\\n\\n\\t\"Double-Step Generation of Ellipses\", X. Wu and J. G. Rokne,\\nIEEE Computer Graphics & Applications, May 1989, pp. 56-69\\n\\n\\tGraeme Gill.\\n',\n",
       "  '6-69\\n\\n\\tGraeme Gill.\\n',\n",
       "  'Subject: E-mail of Michael Abrash?\\nFrom: gmontem@eis.calstate.edu (George A. Montemayor)\\nOrganization: Calif State Univ/Electronic Information Services\\nLines: 0\\n\\n',\n",
       "  'From: g9134255@wampyr.cc.uow.edu.au (Coronado Emmanuel Abad)\\nSubject: Fonts in POV??\\nOrganization: University of Wollongong, NSW, Australia.\\nLines: 11\\nNNTP-Posting-Host: wampyr.cc.uow.edu.au\\nKeywords: fonts, raytrace\\n\\n\\n\\n\\tI have seen several ray-trace',\n",
       "  ' fonts, raytrace\\n\\n\\n\\n\\tI have seen several ray-traced scenes (from MTV or was it \\nRayShade??) with stroked fonts appearing as objects in the image.\\nThe fonts/chars had color, depth and even textures associated with\\nthem.  Now I was wondering, is it pos',\n",
       "  'ociated with\\nthem.  Now I was wondering, is it possible to do the same in POV??\\n\\n\\nThanks,\\n\\nNoel\\n',\n",
       "  'From: lm001@rrz.Uni-Koeln.DE (Erwin H. Keeve)\\nSubject: Polygon Reduction for Marching Cubes\\nOrganization: Regional Computing Center, University of Cologne\\nLines: 36\\nDistribution: world\\nNNTP-Posting-Host: rs1.rrz.uni-koeln.de\\nKeywords: Polygon Reducti',\n",
       "  \"st: rs1.rrz.uni-koeln.de\\nKeywords: Polygon Reduction, Marching Cubes, Surfaces, Midical Visualisation\\n\\n\\nDear Reader,\\n\\n\\nI'am searching for an implementation of a polygon reduction algorithm\\nfor marching cubes surfaces. I think the best one is the redu\",\n",
       "  \"g cubes surfaces. I think the best one is the reduction algorithm\\nfrom Schroeder et al., SIGGRAPH '92. So, is there any implementation of this \\nalgorithm, it would be very nice if you could leave it to me.\\n\\nAlso I'am looking for a fast !!! connectivi\",\n",
       "  \"o me.\\n\\nAlso I'am looking for a fast !!! connectivity\\ntest for marching cubes surfaces.\\n\\nAny help or hints will be very useful.\\nThanks a lot\\n\\n\\n                                                 ,,,\\n                                                (o o)\\n \",\n",
       "  '                                           (o o)\\n ___________________________________________oOO__(-)__OOo_____________\\n|___|___|___|___|___|___|___|___|___|___|___|___|___|___|___|___|___|_|\\n|_|___|___|___|___|___|___|___|___|___|___|___|___|___|___',\n",
       "  '__|___|___|___|___|___|___|___|___|___|___|___|___|___|___|___|\\n|                               |                                     |\\n| Erwin Keeve                   | adress:  Peter-Welter-Platz 2       |\\n|                               |         ',\n",
       "  '      |\\n|                               |          W-5000 Cologne 1, Germany  |\\n|                               |                                     |\\n| Dept. of Computergraphics &   | phone:   +49-221-20189-132 (-192)   |\\n|          Computeranimati',\n",
       "  '21-20189-132 (-192)   |\\n|          Computeranimation    | FAX:     +49-221-20189-17           |\\n|                               |                                     |\\n| Academy of Media Arts Cologne | Email:   keeve@khm.uni-koeln.de     |\\n|_________',\n",
       "  '| Email:   keeve@khm.uni-koeln.de     |\\n|_______________________________|_____________________________________|\\n\\n\\n\\n\\n\\n\\n',\n",
       "  'From: stefan@lis.e-technik.tu-muenchen.de (Stefan Eckart)\\nSubject: dmpeg10.zip info: Another DOS MPEG decoder/player posted\\nKeywords: MPEG, DOS\\nReply-To: stefan@lis.e-technik.tu-muenchen.de\\nOrganization: Technische Universitaet Muenchen, Germany\\nLine',\n",
       "  'on: Technische Universitaet Muenchen, Germany\\nLines: 74\\n\\n\\nI have posted a DOS MPEG decoder/player to alt.binaries.pictures.utilities.\\n\\nHere is a short description and some technical information, taken from the\\naccompanying documentation:\\n\\n\\n          ',\n",
       "  ' from the\\naccompanying documentation:\\n\\n\\n                              DMPEG V1.0\\n\\n                       Public Domain MPEG decoder\\n\\n                           by Stefan Eckart\\n\\n\\n0. Features\\n===========\\n\\nDMPEG/DMPLAY is another MPEG decoder/player fo',\n",
       "  '==\\n\\nDMPEG/DMPLAY is another MPEG decoder/player for the PC:\\n\\n\\n - decodes (nearly) the full MPEG video standard\\n   (I,P,B frames, frame size up to at least 352x240 supported)\\n\\n - saves decoded sequence in 8 or 24bit raw file for later display\\n\\n - opti',\n",
       "  ' in 8 or 24bit raw file for later display\\n\\n - optional on-screen display during decoding (requires VGA)\\n\\n - several dithering options: ordered dither, Floyd-Steinberg, grayscale\\n\\n - color-space selection\\n\\n - runs under DOS, 640KB RAM, no MS-Windows r',\n",
       "  'ion\\n\\n - runs under DOS, 640KB RAM, no MS-Windows required\\n\\n - very compact (small code / small data models, 16 bit arithmetic)\\n\\n - real time display of the raw file by a separate player for\\n   VGA and many Super-VGAs\\n\\n...\\n\\n4. Technical information\\n==',\n",
       "  ' many Super-VGAs\\n\\n...\\n\\n4. Technical information\\n========================\\n\\nThe player is a rather straightforward implementation of the MPEG spec [1].\\nThe IDCT is based on the Chen-Wang 13 multiplication algorithm [2]\\n(not quite the optimum, I know). ',\n",
       "  \"on algorithm [2]\\n(not quite the optimum, I know). Blocks with not more than eight non-zero\\ncoefficients use a non-separated direct multiply-accumulate 2D-IDCT\\n(sounds great, doesn't it?), which turned out to be faster than a 'fast'\\nalgorithm in this \",\n",
       "  \" out to be faster than a 'fast'\\nalgorithm in this (quite common) case. Dithering is pretty standard. Main\\ndifference to the Berkeley decoder (except for the fewer number of supported\\nalgorithms) is the use of 256 instead of 128 colors, the (default) \",\n",
       "  'e use of 256 instead of 128 colors, the (default) option to\\nuse a restricted color-space and the implementation of a color saturation\\ndominant ordered dither. This leads to a significantly superior quality of\\nthe dithered image (I claim, judge yourse',\n",
       "  'ality of\\nthe dithered image (I claim, judge yourself).\\n\\nRestricted color-space means that the U and V components are clipped to\\n+/-0.25 (instead of +/-0.5) and the display color-space points are distributed\\nover this restricted space. Since the dista',\n",
       "  'ibuted\\nover this restricted space. Since the distance between color-space points\\nis thus reduced by a factor of two, the color resolution is doubled at the\\nexpense of not being able to represent fully saturated colors.\\n\\nSaturation dominant ordered di',\n",
       "  ' saturated colors.\\n\\nSaturation dominant ordered dither is a method by which a color, lying\\nsomewhere between the points of the display color space, is approximated\\nby primarily alternating between two points of constant hue instead of\\nconstant satura',\n",
       "  ' points of constant hue instead of\\nconstant saturation. This yields subjectivly better quality due to the\\nlower sensitivity of the human viewing system to saturation changes than\\nto hue changes (the same reasoning as used by the PAL TV standard to im',\n",
       "  'ame reasoning as used by the PAL TV standard to improve\\non NTSC). The improvement is particularly visible in dark brown or redish\\nareas.\\n\\n...\\n\\n--\\nStefan Eckart, stefan@lis.e-technik.tu-muenchen.de\\n',\n",
       "  'From: scrowe@hemel.bull.co.uk (Simon Crowe)\\nSubject: Point within a polygon\\nSummary: Algorithm to find if a point is bound by a polygon\\nKeywords: point, polygon\\nNntp-Posting-Host: bogart\\nOrganization: Bull HN UK\\nLines: 7\\n\\nI am looking for an algorith',\n",
       "  ' Bull HN UK\\nLines: 7\\n\\nI am looking for an algorithm to determine if a given point is bound by a \\npolygon. Does anyone have any such code or a reference to book containing\\ninformation on the subject ?\\n\\n\\t\\tRegards\\n\\n\\t\\t\\tSimon\\n',\n",
       "  '\\n\\t\\tRegards\\n\\n\\t\\t\\tSimon\\n',\n",
       "  'From: john@goshawk.mcc.ac.uk (John Heaton)\\nSubject: POV reboots PC after memory upgrade\\nReply-To: john@nessie.mcc.ac.uk\\nOrganization: MCC Network Unit\\nLines: 13\\n\\nUp until last week, I have been running POVray v1.0 on my 486/33 under DOS5\\nwithout any ',\n",
       "  'g POVray v1.0 on my 486/33 under DOS5\\nwithout any major problems.  Over Easter I increased the memory from 4Meg to\\n8Meg, and found that POVray reboots the system every time under DOS5.  I had\\na go at running POVray in a DOS window when running Win3.1',\n",
       "  'running POVray in a DOS window when running Win3.1 on the same system\\nand it now works fine, even if a lot slower.  I would like to go back to \\nusing POVray directly under DOS, anyone any ideas???\\n\\nJohn\\n-- \\n                 John Heaton   -   NRS Cent',\n",
       "  'hn\\n-- \\n                 John Heaton   -   NRS Central Administrator\\n      MCC Network Unit, The University, Oxford Road, Manchester,  M13-9PL\\n            Phone: (+44) 61 275 6011   -   FAX: (+44) 61 275 6040\\n                   Packet: G1YYH @ G1YYH.G',\n",
       "  '75 6040\\n                   Packet: G1YYH @ G1YYH.GB7PWY.#16.GBR.EU\\n',\n",
       "  'From: af774@cleveland.Freenet.Edu (Chad Cipiti)\\nSubject: Good shareware paint and/or animation software for SGI?\\nOrganization: Case Western Reserve University, Cleveland, OH (USA)\\nLines: 15\\nReply-To: af774@cleveland.Freenet.Edu (Chad Cipiti)\\nNNTP-Pos',\n",
       "  \"af774@cleveland.Freenet.Edu (Chad Cipiti)\\nNNTP-Posting-Host: hela.ins.cwru.edu\\n\\n\\nDoes anyone know of any good shareware animation or paint software for an SGI\\n machine?  I've exhausted everyplace on the net I can find and still don't hava\\n a nice pie\",\n",
       "  \"he net I can find and still don't hava\\n a nice piece of software.\\n\\nThanks alot!\\n\\nChad\\n\\n\\n-- \\nKnock, knock.                                         Chad Cipiti\\nWho's there?                                    af774@cleveland.freenet.edu\\n                \",\n",
       "  '      af774@cleveland.freenet.edu\\n                                               cipiti@bobcat.ent.ohiou.edu\\nIt might be Heisenberg.                          chad@voxel.zool.ohiou.edu\\n',\n",
       "  \"From: hendrix@oasys.dt.navy.mil (Dane Hendrix)\\nSubject: Processing of stereo images\\nReply-To: hendrix@oasys.dt.navy.mil (Dane Hendrix)\\nOrganization: Code 1542, DTMB, Bethesda, MD\\nLines: 16\\n\\nI'm interested in find out what is involved in processing pa\",\n",
       "  \"sted in find out what is involved in processing pairs of \\nstereo photographs.  I have black-and-white photos and would like \\nto obtain surface contours.\\n\\nI'd prefer to do the processing on an SGI, but would be interested\\nin hearing what software/hard\",\n",
       "  ' would be interested\\nin hearing what software/hardware is used for this type of\\nimage processing.\\n\\nPlease email and/or post to comp.sys.sgi.graphics your responses.\\n\\nThanks,\\n\\nDane Hendrix                              | email: dane@wizard.dt.navy.mil ',\n",
       "  '                 | email: dane@wizard.dt.navy.mil \\nDTMB (a.k.a. Headquarters, Carderock Div.,|  or hendrix@oasys.dt.navy.mil\\nNaval Surface Warfare Center)             |  or hendrix@nas.nasa.gov \\nCode 1542, Bethesda, MD 20084-5000        | phone: (301',\n",
       "  '1542, Bethesda, MD 20084-5000        | phone: (301)227-1340\\n',\n",
       "  'From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP',\n",
       "  'ersion 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nic',\n",
       "  \"r as the low-level stuff goes, it looks pretty nice.  It's got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek's address/phone number?  I'd like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarri\",\n",
       "  'nformation\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n',\n",
       "  'nathan Winters\\n',\n",
       "  'From: kreyling@lds.loral.com (Ed Kreyling 6966)\\nSubject: Sun-os and 8bit ASCII graphics\\nOrganization: Loral Data Systems\\nDistribution: comp.graphics\\nLines: 7\\n\\nI would like to know if anyone has had any luck using the upper 128 ASCII\\ncharacters on a S',\n",
       "  'y luck using the upper 128 ASCII\\ncharacters on a Sun station.  I am trying to convert a fortran program to run\\non a Sun.  When we write character buffers to the Sun which contain char(218)\\nor char(196) or char(197) etc.  We get characters on the scre',\n",
       "  ') or char(197) etc.  We get characters on the screen but they are\\nnot the characters in the standard ASCII tables.\\n\\nAny ideas or help will be appreciated.\\n',\n",
       "  'From: clipper@mccarthy.csd.uwo.ca (Khun Yee Fung)\\nSubject: Re: looking for circle algorithm faster than Bresenhams\\nOrganization: Department of Computer Science, The University of Western\\n\\tOntario, London, Ontario, Canada\\nIn-Reply-To: graeme@labtam.la',\n",
       "  \"don, Ontario, Canada\\nIn-Reply-To: graeme@labtam.labtam.oz.au's message of Wed, 14 Apr 1993 04:49:46 GMT\\n\\t<1993Apr13.025240.8884@nwnexus.WA.COM>\\n\\t<1993Apr14.044946.12144@labtam.labtam.oz.au>\\nNntp-Posting-Host: mccarthy.csd.uwo.ca\\nLines: 41\\n\\n>>>>> On W\",\n",
       "  'ng-Host: mccarthy.csd.uwo.ca\\nLines: 41\\n\\n>>>>> On Wed, 14 Apr 1993 04:49:46 GMT, graeme@labtam.labtam.oz.au (Graeme Gill) said:\\n\\nGraeme> \\tYes, that\\'s known as \"Bresenhams Run Length Slice Algorithm for\\nGraeme> Incremental lines\". See Fundamental Algor',\n",
       "  '\\nGraeme> Incremental lines\". See Fundamental Algorithms for Computer Graphics,\\nGraeme> Springer-Verlag, Berlin Heidelberg 1985.\\n\\n> I have tried to extrapolate this to circles but I can\\'t figure out\\n> how to determine the length of the slices. Any ide',\n",
       "  'how to determine the length of the slices. Any ideas?\\n\\nGraeme> \\tHmm. I don\\'t think I can help you with this, but you might\\nGraeme> take a look at the following:\\n\\nGraeme> \\t\"Double-Step Incremental Generation of Lines and Circles\",\\nGraeme> X. Wu and J.',\n",
       "  'ration of Lines and Circles\",\\nGraeme> X. Wu and J. G. Rokne, Computer Graphics and Image processing,\\nGraeme> Vol 37, No. 4, Mar. 1987, pp. 331-334\\n\\nGraeme> \\t\"Double-Step Generation of Ellipses\", X. Wu and J. G. Rokne,\\nGraeme> IEEE Computer Graphics &',\n",
       "  ' and J. G. Rokne,\\nGraeme> IEEE Computer Graphics & Applications, May 1989, pp. 56-69\\n\\nAnother paper you might want to consider is:\\n\\n@article{fungdraw,\\n  title=\"A Run-Length Slice Line Drawing Algorithm without Division Operations\",\\n  author=\"Khun Yee',\n",
       "  'm without Division Operations\",\\n  author=\"Khun Yee Fung and Tina M. Nicholl and A. K. Dewdney\",\\n  journal=\"Computer Graphics Forum\",\\n  year=1992,\\n  volume=11,\\n  number=3,\\n  pages=\"C-267--C-277\"\\n}\\n\\nKhun Yee\\n--\\nKhun Yee Fung    clipper@csd.uwo.ca\\nDepar',\n",
       "  'n Yee\\n--\\nKhun Yee Fung    clipper@csd.uwo.ca\\nDepartment of Computer Science\\nMiddlesex College\\nUniversity of Western Ontario\\nLondon, Ontario\\nCanada N6A 5B7\\nTel: (519) 661-6889\\nFax: (519) 661-3515\\n',\n",
       "  'From: msc_wdqn@jhunix.hcf.jhu.edu (Daniel Q Naiman)\\nSubject: Geometry package\\nOrganization: Homewood Academic Computing, Johns Hopkins University, Baltimore, Md, USA\\nLines: 11\\nDistribution: world\\nNNTP-Posting-Host: jhunix.hcf.jhu.edu\\n\\nI am looking fo',\n",
       "  '-Posting-Host: jhunix.hcf.jhu.edu\\n\\nI am looking for a package which takes as inputs a set\\nof geometric objects defined by unions of convex polytopes\\nspecified in some manner, say by inequalities and equalities,\\nand determines in some reasonable form ',\n",
       "  'qualities,\\nand determines in some reasonable form things like\\nintersections, unions, etc. etc..\\n\\nDoes anyone know where I can find such a thing?\\n\\nDan Naiman\\nDepartment of Mathematical Sciences\\nJohns Hopkins University\\n',\n",
       "  'opkins University\\n',\n",
       "  'From: spl@ivem.ucsd.edu (Steve Lamont)\\nSubject: Re: Point within a polygon\\nOrganization: University of Calif., San Diego/Microscopy and Imaging Resource\\nLines: 15\\nNNTP-Posting-Host: ivem.ucsd.edu\\nKeywords: point, polygon\\n\\nIn article <1993Apr14.102007',\n",
       "  'ords: point, polygon\\n\\nIn article <1993Apr14.102007.20664@uk03.bull.co.uk> scrowe@hemel.bull.co.uk (Simon Crowe) writes:\\n>I am looking for an algorithm to determine if a given point is bound by a \\n>polygon. Does anyone have any such code or a referenc',\n",
       "  'ygon. Does anyone have any such code or a reference to book containing\\n>information on the subject ?\\n\\nSee the article \"An Efficient Ray-Polygon Intersection,\" p. 390 in\\nGraphics Gems (ISBN 0-12-286165-5).  The second step, intersecting the\\npolygon, d',\n",
       "  '-5).  The second step, intersecting the\\npolygon, does what you want.  There is sample code in the book.\\n\\n\\t\\t\\t\\t\\t\\t\\tspl\\n-- \\nSteve Lamont, SciViGuy -- (619) 534-7968 -- spl@szechuan.ucsd.edu\\nSan Diego Microscopy and Imaging Resource/UC San Diego/La Jolla,',\n",
       "  'oscopy and Imaging Resource/UC San Diego/La Jolla, CA 92093-0608\\n\"They are not Bolsheviks,\\n        just bullshitviks.\"  - Yevgeny Yevtechenko, \"Again a meeting...\"\\n',\n",
       "  'From: ferdinan@oeinck.waterland.wlink.nl (Ferdinand Oeinck)\\nSubject: Re: Distance between two Bezier curves\\nOrganization: My own node in Groningen, NL.\\nLines: 14\\n\\npes@hutcs.cs.hut.fi (Pekka Siltanen) writes:\\n\\n> Suppose two cubic Bezier curves (contro',\n",
       "  'writes:\\n\\n> Suppose two cubic Bezier curves (control points V1,..,V4 and W1,..,W4)\\n> which have equal first and last control points (V1 = W1, V4 = W4). How do I \\n> get upper bound for distance between these curves. \\n\\nWhich distance? The distance betwe',\n",
       "  'these curves. \\n\\nWhich distance? The distance between one point (t = ti) on the first curve\\nand a point on the other curve with same parameter (u = ti)?\\n\\n> \\n> Any references appreciated. Thanks in anvance.\\n> \\n> Pekka Siltanen\\n\\n',\n",
       "  'nce.\\n> \\n> Pekka Siltanen\\n\\n',\n",
       "  'From: jonas-y@isy.liu.se (Jonas Yngvesson)\\nSubject: Re: Point within a polygon\\nKeywords: point, polygon\\nOrganization: Dept of EE, University of Linkoping\\nLines: 129\\n\\nscrowe@hemel.bull.co.uk (Simon Crowe) writes:\\n\\n>I am looking for an algorithm to det',\n",
       "  \"we) writes:\\n\\n>I am looking for an algorithm to determine if a given point is bound by a \\n>polygon. Does anyone have any such code or a reference to book containing\\n>information on the subject ?\\n\\nWell, it's been a while since this was discussed so i t\",\n",
       "  \" it's been a while since this was discussed so i take the liberty of\\nreprinting (without permission, so sue me) Eric Haines reprint of the very\\ninteresting discussion of this topic...\\n\\n                /Jonas\\n\\n                         O /         \\\\ O\\n\",\n",
       "  ' /Jonas\\n\\n                         O /         \\\\ O\\n------------------------- X snip snip X ------------------------------\\n                         O \\\\         / O\\n\\n\"Give a man a fish, and he\\'ll eat one day.\\nGive a man a fishing rod, and he\\'ll laze aro',\n",
       "  ' day.\\nGive a man a fishing rod, and he\\'ll laze around fishing and never do anything.\"\\n\\nWith that in mind, I reprint (without permission, so sue me) relevant\\ninformation posted some years ago on this very problem.  Note the early use of\\nPostScript tec',\n",
       "  \"ery problem.  Note the early use of\\nPostScript technology, predating many of this year's papers listed in the\\nApril 1st SIGGRAPH Program Announcement posted here a few days ago.\\n\\n-- Eric\\n\\n\\nIntersection Between a Line and a Polygon (UNDECIDABLE??),\\n\\tb\",\n",
       "  'n Between a Line and a Polygon (UNDECIDABLE??),\\n\\tby Dave Baraff, Tom Duff\\n\\n\\tFrom: deb@charisma.graphics.cornell.edu\\n\\tNewsgroups: comp.graphics\\n\\tKeywords: P, NP, Jordan curve separation, Ursyhon Metrization Theorem\\n\\tOrganization: Program of Computer G',\n",
       "  'ation Theorem\\n\\tOrganization: Program of Computer Graphics\\n\\nIn article [...] ncsmith@ndsuvax.UUCP (Timothy Lyle Smith) writes:\\n>\\n>  I need to find a formula/algorithm to determine if a line intersects\\n>  a polygon.  I would prefer a method that would ',\n",
       "  '>  a polygon.  I would prefer a method that would do this in as little\\n>  time as possible.  I need this for use in a forward raytracing\\n>  program.\\n\\nI think that this is a very difficult problem.  To start with, lines and\\npolygons are semi-algebraic',\n",
       "  ' start with, lines and\\npolygons are semi-algebraic sets which both contain uncountable number of\\npoints.  Here are a few off-the-cuff ideas.\\n\\nFirst, we need to check if the line and the polygon are separated.  Now, the\\nJordan curve separation theorem',\n",
       "  'parated.  Now, the\\nJordan curve separation theorem says that the polygon divides the plane into\\nexactly two open (and thus non-compact) regions.  Thus, the line lies\\ncompletely inside the polygon, the line lies completely outside the polygon,\\nor poss',\n",
       "  ' line lies completely outside the polygon,\\nor possibly (but this will rarely happen) the line intersects the polyon.\\n\\nNow, the phrasing of this question says \"if a line intersects a polygon\", so\\nthis is a decision problem.  One possibility (the decis',\n",
       "  'is a decision problem.  One possibility (the decision model approach) is\\nto reduce the question to some other (well known) problem Q, and then try to\\nsolve Q.  An answer to Q gives an answer to the original decision problem.\\n\\nIn recent years, many ge',\n",
       "  'iginal decision problem.\\n\\nIn recent years, many geometric problems have been successfully modeled in a\\nnew language called PostScript.  (See \"PostScript Language\", by Adobe Systems\\nIncorporated, ISBN # 0-201-10179-3, co. 1985).\\n\\nSo, given a line L an',\n",
       "  '# 0-201-10179-3, co. 1985).\\n\\nSo, given a line L and a polygon P, we can write a PostScript program that\\ndraws the line L and the polygon P, and then \"outputs\" the answer.  By\\n\"output\", we mean the program executes a command called \"showpage\", which\\na',\n",
       "  'gram executes a command called \"showpage\", which\\nactually prints a page of paper containing the line and the polygon.  A quick\\nexamination of the paper provides an answer to the reduced problem Q, and thus\\nthe original problem.\\n\\nThere are two small p',\n",
       "  \" thus\\nthe original problem.\\n\\nThere are two small problems with this approach. \\n\\n\\t(1) There is an infinite number of ways to encode L and P into the\\n\\treduced problem Q.  So, we will be forced to invoke the Axiom of\\n\\tChoice (or equivalently, Zorn's Lem\",\n",
       "  \" the Axiom of\\n\\tChoice (or equivalently, Zorn's Lemma).  But the use of the Axiom of\\n\\tChoice is not regarded in a very serious light these days.\\n\\n\\t(2) More importantly, the question arises as to whether or not the\\n\\tPostScript program Q will actually o\",\n",
       "  'r or not the\\n\\tPostScript program Q will actually output a piece of paper; or in\\n\\tother words, will it halt?\\n\\n\\tNow, PostScript is expressive enough to encode everything that a\\n\\tTuring Machine might do; thus the halting problem (for PostScript) is\\n\\tund',\n",
       "  \" thus the halting problem (for PostScript) is\\n\\tundecidable.  It is quite possible that the original problem will turn\\n\\tout to be undecidable.\\n\\n\\nI won't even begin to go into other difficulties, such as aliasing, finite\\nprecision and running out of in\",\n",
       "  \"s aliasing, finite\\nprecision and running out of ink, paper or both.\\n\\nA couple of references might be:\\n\\n1. Principia Mathematica.  Newton, I.  Cambridge University Press, Cambridge,\\n   England.  (Sorry, I don't have an ISBN# for this).\\n\\n2. An Introduc\",\n",
       "  \", I don't have an ISBN# for this).\\n\\n2. An Introduction to Automata Theory, Languages, and Computation.  Hopcroft, J\\n   and Ulman, J.\\n\\n3. The C Programming Language. Kernighan, B and Ritchie, D.\\n\\n4. A Tale of Two Cities. Dickens, C.\\n\\n--------\\n\\nFrom: t\",\n",
       "  \"Tale of Two Cities. Dickens, C.\\n\\n--------\\n\\nFrom: td@alice.UUCP (Tom Duff)\\nSummary: Overkill.\\nOrganization: AT&T Bell Laboratories, Murray Hill NJ\\n\\nThe situation is not nearly as bleak as Baraff suggests (he should know\\nbetter, he's hung around The La\",\n",
       "  \"ts (he should know\\nbetter, he's hung around The Labs for long enough).  By the well known\\nDobbin-Dullman reduction (see J. Dullman & D. Dobbin, J. Comp. Obfusc.\\n37,ii:  pp. 33-947, lemma 17(a)) line-polygon intersection can be reduced to\\nHamiltonian \",\n",
       "  'olygon intersection can be reduced to\\nHamiltonian Circuit, without(!) the use of Grobner bases, so LPI (to coin an\\nacronym) is probably only NP-complete.  Besides, Turing-completeness will no\\nlonger be a problem once our Cray-3 is delivered, since it',\n",
       "  \"e a problem once our Cray-3 is delivered, since it will be able to\\ncomplete an infinite loop in 4 milliseconds (with scatter-gather.)\\n\\n--------\\n\\nFrom: deb@svax.cs.cornell.edu (David Baraff)\\n\\nWell, sure its no worse than NP-complete, but that's ONLY i\"],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['embeddings', 'metadatas', 'documents']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector.collection.peek(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSiiVKiad0Rn",
    "outputId": "198570a1-34c9-4472-96c2-d7791a997f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search query: What tools does include ImageMagick?\n",
      "Result 1: {'id': 'id_2466', 'distance': 4.114987850189209, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'oftware for Amigas.  ImageMaster, from Black Belt Systems, is another\\nwell-regarded commercial graphics package with JPEG support.\\n\\nThe free IJG JPEG software is available compiled for Amigas from\\namiga.physik.unizh.ch (and mirror sites) in directory'}\n",
      "Result 2: {'id': 'id_2379', 'distance': 4.43457555770874, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': \"isty's free ImageMagick package,\\nalso available from export.lcs.mit.edu, file contrib/ImageMagick.tar.Z.\\nThis package handles many image processing and conversion tasks.  The\\nImageMagick viewer handles 24-bit displays correctly; for colormapped\\ndispl\"}\n",
      "Result 3: {'id': 'id_1650', 'distance': 4.7922492027282715, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': 'geMagick can read and write many\\n  of the more popular image formats.  ImageMagick is available as\\n  export.lcs.mit.edu: contrib/ImageMagick.tar.Z or at your nearest\\n  X11 archive.\\n\\n===================================================================='}\n",
      "Result 4: {'id': 'id_2471', 'distance': 4.980372428894043, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'atari/Graphics/jpeg4bin.zoo.\\nThese programs convert JPEG to/from PPM, GIF, Targa formats.\\n\\nI have not heard of any free or shareware JPEG-capable viewer for Ataris,\\nbut surely there must be one by now?  Pointers appreciated.\\n\\nAcorn Archimedes:\\n\\n!Chan'}\n",
      "Result 5: {'id': 'id_2465', 'distance': 5.133840560913086, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'press package that also includes CineMorph.  Both are\\ndistributed by Great Valley Products.  Art Department Professional (ADPro),\\nfrom ASDG Inc, is the most widely used commercial image manipulation\\nsoftware for Amigas.  ImageMaster, from Black Belt '}\n"
     ]
    }
   ],
   "source": [
    "search_queries = [\"What tools does include ImageMagick?\"]\n",
    "\n",
    "for query in search_queries:\n",
    "    print(f\"\\nSearch query: {query}\")\n",
    "    results = collector.get([query], n_results=n_results)\n",
    "\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6lzqXLZ_YtU"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WHZ6IMLIQq2-"
   },
   "outputs": [],
   "source": [
    "# Класс для оценки работы коллектора, предоставляющий функционал для поиска, оценки и расчета статистики по результатам\n",
    "class CollectorEvaluator:\n",
    "    def __init__(self, collector: Collector, n_top=5):\n",
    "        # Инициализация коллектора и параметра n_top для ограничения числа возвращаемых результатов\n",
    "        self.collector = collector\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def explore_collector(self, text: str):\n",
    "        # Метод для поиска документов в коллекторе на основе текста запроса\n",
    "        collector_results = self.collector.get([text], n_results=self.n_top)\n",
    "        return collector_results\n",
    "\n",
    "    def eval(self, query: str, answer: str):\n",
    "        # Метод для оценки корректности найденных документов на основе запроса и правильного ответа\n",
    "        collector_results = self.explore_collector(query)\n",
    "\n",
    "        print(f\"\\nSearch query: {query},\\nanswer: {answer}\")\n",
    "\n",
    "        for i, doc in enumerate(collector_results, start=1):\n",
    "            print(f\"Result {i}: {doc}\")\n",
    "\n",
    "        for i, doc in enumerate(collector_results, start=1):\n",
    "            if answer in doc[\"document\"]:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def calculate_statistics(self, data: list[int]):\n",
    "        # Метод для расчета статистических показателей (например, минимальное, максимальное, среднее значение)\n",
    "\n",
    "        filtered_data = [serial_number for serial_number in data if serial_number is not None]\n",
    "        not_found_queries = len([serial_number for serial_number in data if serial_number is None])\n",
    "\n",
    "        if not filtered_data:\n",
    "            return {\"min\": None, \"max\": None, \"mean\": None, \"not found\": None}\n",
    "\n",
    "        min_serial_number = min(filtered_data)\n",
    "        max_serial_number = max(filtered_data)\n",
    "        mean_serial_number = sum(filtered_data) / len(filtered_data)\n",
    "        return {\"min\": min_serial_number, \"max\": max_serial_number, \"mean\": mean_serial_number, \"not_found\": not_found_queries / len(data)}\n",
    "\n",
    "    def explore_and_calculate(self, data: list[tuple[str, str]]):\n",
    "        # Метод для проведения поиска по данным и расчета статистики на основе результатов\n",
    "        collector_results = []\n",
    "        for query, answer in data:\n",
    "            serial_number = self.eval(query, answer)\n",
    "            collector_results.append(serial_number)\n",
    "\n",
    "        stats = self.calculate_statistics(collector_results)\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "VFNalqWBkF-m"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = '/content/QA.csv' #@param {type:\"string\"}\n",
    "n_lines = 100 #@param {type:\"integer\"}\n",
    "n_top = 10 #@param {type:\"integer\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWlAHfzYjw4X",
    "outputId": "f737d7fe-bcd1-4335-f4a2-dc9a28aa7051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search query: What is the sun?,\n",
      "answer: The sun is an average star.\n",
      "Result 1: {'id': 'id_894', 'distance': 8.065171241760254, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38306.txt'}, 'document': '.Sun.COM\\n'}\n",
      "Result 2: {'id': 'id_3872', 'distance': 9.8038330078125, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38614.txt'}, 'document': 'ars\\n'}\n",
      "Result 3: {'id': 'id_1479', 'distance': 10.071670532226562, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 's on Sun 3/xxx, Sun 4/xxx (OS3.5, 4.0 and 4.0.3) under SunView.\\n  The expert system for image segmentation is written in Allegro Common Lisp.\\n  It was used on the following domains: computer science (image analysis), \\n  medicine, biology, physics. It'}\n",
      "Result 4: {'id': 'id_1468', 'distance': 10.396501541137695, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'lled user, and programmer.\\n\\nALV\\n---\\n  A Sun-specific image toolkit.  Version 2.0.6 posted to\\n  comp.sources.sun on 11dec89.  Also available via email to\\n  alv-users-request@cs.bris.ac.uk.\\n\\nAIPS\\n----\\n  Astronomical Image Processing System.  Contact: a'}\n",
      "Result 5: {'id': 'id_3318', 'distance': 10.65462875366211, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38525.txt'}, 'document': \"ibution: world\\nNNTP-Posting-Host: llullaillaco.engin.umich.edu\\nKeywords: sun ipx background picture\\nOriginator: tdawson@llullaillaco.engin.umich.edu\\n\\n\\nI'm not sure if you got the information you were looking for, so I'll\\npost it anyway for the genera\"}\n",
      "Result 6: {'id': 'id_2689', 'distance': 11.297584533691406, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38425.txt'}, 'document': '                 |\\n'}\n",
      "Result 7: {'id': 'id_1318', 'distance': 11.62136459350586, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': \",  pub/astrod.\\n\\nVG plotting library\\n-------------------\\n  This is a library of Fortran callable routines at sunspot.ceee.nist.gov\\n  [129.6.64.151]\\n\\nXgobi\\n-----\\n  It's being developed at Bellcore, and its speciality are\\n  multidimensional data sets an\"}\n",
      "Result 8: {'id': 'id_2730', 'distance': 11.664608001708984, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38429.txt'}, 'document': 'is.unomaha.edu, ed@sunsite.unc.edu\\n'}\n",
      "Result 9: {'id': 'id_3554', 'distance': 11.690579414367676, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38561.txt'}, 'document': 'ktische Informatik \\n'}\n",
      "Result 10: {'id': 'id_1317', 'distance': 11.977546691894531, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'ited 3-D. Based on XView 3, written\\n  in C / Fortran (so you need a Fortran compiler or the f2c translator).\\n  Mainly tested on Sun4, less on DECstations. Check at\\n  ftp.astro.psu.edu (128.118.147.28),  pub/astrod.\\n\\nVG plotting library\\n--------------'}\n",
      "\n",
      "Search query: What is the moon?,\n",
      "answer: The moon orbits the Earth.\n",
      "Result 1: {'id': 'id_3872', 'distance': 9.882584571838379, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38614.txt'}, 'document': 'ars\\n'}\n",
      "Result 2: {'id': 'id_2861', 'distance': 10.534574508666992, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38453.txt'}, 'document': 'ibm.com (Rick Turner) writes:\\n\\n>Look in the /pub/SPACE directory on ames.arc.nasa.gov - there are a number\\n>of earth images there. You may have to hunt around the subdirectories as\\n>things tend to be filed under the mission (ie, \"APOLLO\") rather than'}\n",
      "Result 3: {'id': 'id_2862', 'distance': 10.930655479431152, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38453.txt'}, 'document': 'filed under the mission (ie, \"APOLLO\") rather than under\\t\\n>the image subject.\\t\\n>\\nFor those of you who don\\'t need 24 bit, I got a 32 colour Amiga IFF\\nof a cloudless Earth (scanned). Looks okay when mapped on a sphere.\\nE-mail me and I\\'ll send it you...'}\n",
      "Result 4: {'id': 'id_1628', 'distance': 11.035639762878418, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': \"---\\n\\nTolis Lerios <tolis@nova.stanford.edu> has built a list of Space Shuttle\\ndatafiles. Here's a summary (From his sci.space list):\\n\\nmodel1:\\nA modified version of the newsgroup model (model2)\\n\\n406 vertices (296 useful, i.e. referred to in the polygo\"}\n",
      "Result 5: {'id': 'id_2761', 'distance': 11.055980682373047, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38433.txt'}, 'document': 'Organization: IBM UK Labs\\nLines: 6\\n\\nLook in the /pub/SPACE directory on ames.arc.nasa.gov - there are a number\\nof earth images there. You may have to hunt around the subdirectories as\\nthings tend to be filed under the mission (ie, \"APOLLO\") rather th'}\n",
      "Result 6: {'id': 'id_2689', 'distance': 11.086790084838867, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38425.txt'}, 'document': '                 |\\n'}\n",
      "Result 7: {'id': 'id_615', 'distance': 11.1411771774292, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38259.txt'}, 'document': '^^^^^^^^^^^^^^\\n'}\n",
      "Result 8: {'id': 'id_4845', 'distance': 11.23088550567627, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38816.txt'}, 'document': '=====================\\n'}\n",
      "Result 9: {'id': 'id_2987', 'distance': 11.261551856994629, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38465.txt'}, 'document': '. You may have to hunt around the subdirectories as\\n>>things tend to be filed under the mission (ie, \"APOLLO\") rather than under\\t\\n>>the image subject.\\t\\n>>\\n>For those of you who don\\'t need 24 bit, I got a 32 colour Amiga IFF\\n>of a cloudless Earth (sca'}\n",
      "Result 10: {'id': 'id_1989', 'distance': 11.549152374267578, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \")-354-7170\\n\\nspacelink.msfc.nasa.gov [128.158.13.250] (passwd:guest) : space graphics\\n        and GIF images from NASA's planetary probes and the Hubble Telescope.\\n        Main function is support for teachers (you can telnet also to this\\n        site\"}\n",
      "\n",
      "Search query: Cooking tips,\n",
      "answer: I enjoy cooking and baking.\n",
      "Result 1: {'id': 'id_3872', 'distance': 9.751921653747559, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38614.txt'}, 'document': 'ars\\n'}\n",
      "Result 2: {'id': 'id_1017', 'distance': 10.692583084106445, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38326.txt'}, 'document': \">\\n|> I ask this question periodically and haven't found anything.  This is\\n|> the last time.  If I don't find anything, I'm going to write some\\n|> myself.\\n|> \\n|> Post here or email me if you have any leads or suggestions, else just\\n|> sit back and wa\"}\n",
      "Result 3: {'id': 'id_947', 'distance': 11.012398719787598, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38311.txt'}, 'document': 'te.\\n'}\n",
      "Result 4: {'id': 'id_2689', 'distance': 11.220332145690918, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38425.txt'}, 'document': '                 |\\n'}\n",
      "Result 5: {'id': 'id_1205', 'distance': 11.236480712890625, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38358.txt'}, 'document': \" \\n> Can you please offer some recommendations?\\n\\nIt's really not that hard to do.  There are books out there which explain\\neverything, and the basic 3D functions, translation, rotation, shading, and\\nhidden line removal are pretty easy.  I wrote a prog\"}\n",
      "Result 6: {'id': 'id_3554', 'distance': 11.356351852416992, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38561.txt'}, 'document': 'ktische Informatik \\n'}\n",
      "Result 7: {'id': 'id_3101', 'distance': 11.364734649658203, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38485.txt'}, 'document': \"sun.tamu.edu (Brent) writes:\\n>tsa@cellar.org (The Silent Assassin) writes:\\n>>rgc3679@bcstec.ca.boeing.com (Robert G. Carpenter) writes:\\n>>\\n>>> Can you please offer some recommendations?\\n>>\\n>>It's really not that hard to do.  There are books out there\"}\n",
      "Result 8: {'id': 'id_1288', 'distance': 11.422880172729492, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38371.txt'}, 'document': \"lent Assassin) writes:\\n>rgc3679@bcstec.ca.boeing.com (Robert G. Carpenter) writes:\\n>\\n>> Can you please offer some recommendations?\\n>\\n>It's really not that hard to do.  There are books out there which explain\\n>everything, and the basic 3D functions, t\"}\n",
      "Result 9: {'id': 'id_3207', 'distance': 11.510653495788574, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38505.txt'}, 'document': ' sure, but I think I read this a long\\ntime ago.\\n\\n   Anyway, still with 15Mhz, you need sprites for a lot of tricks for\\nmaking cool awesome games (read psygnosis).\\n\\n--------------------------------------\\nRaist  New A1200 owner   320<->1280 in x, 200<-'}\n",
      "Result 10: {'id': 'id_4687', 'distance': 11.559393882751465, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38737.txt'}, 'document': 'oftware to run on my brand new Targa+ 16/32. If anyone knows\\nof any sites which have useful stuff, or if you have any yourself you want to\\ngive, let me know via mail. Thanks a LOT! Yayayay!\\n                                     jamie@ddsw1.mcs.com\\n\\n'}\n",
      "Статистика по позициям релевантных ответов: {'min': None, 'max': None, 'mean': None, 'not found': None}\n"
     ]
    }
   ],
   "source": [
    "#Нужно написать эксперимент для оценки полученной коллекции\n",
    "example_collector = ChromaCollector(example_splitter, example_embedder)\n",
    "example_evaluator = CollectorEvaluator(example_collector, n_top=n_top)\n",
    "\n",
    "example_data = [\n",
    "    (\"What is the sun?\", \"The sun is an average star.\"),\n",
    "    (\"What is the moon?\", \"The moon orbits the Earth.\"),\n",
    "    (\"Cooking tips\", \"I enjoy cooking and baking.\")\n",
    "]\n",
    "\n",
    "example_stats = example_evaluator.explore_and_calculate(example_data)\n",
    "print(\"Статистика по позициям релевантных ответов:\", example_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "IgRuY2XLxNVh"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('What are some examples of toolkits that can be used for image format conversion and basic image manipulations?', 'umber of toolkits for converting from one image format to\\nanother, doing simple image manipulations such as size scaling, plus\\nthe above-mentioned 24 -> 8, color -> gray, gray -> b&w conversions.\\nHere are pointers to some of them:\\n\\n    xv by John Bra'),\n",
    "    ('What techniques are discussed in the context of quantizing 24-bit images down to 8 bits, and where can one find a relevant reference on this topic?', 'for\\nshading, chapter 19 for clipping, and branch out from there.\\n\\n\\n3) Quantizing 24 bit images down to 8 bits.\\n\\nFind a copy of \"Color Image Quantization for Frame Buffer Display\" by\\nPaul Heckbert, SIGGRAPH \\'82 Proceedings, page 297.  There are other\\n'),\n",
    "    ('How to FTP by email', ' 9) Converting between vector formats.\\n    10) How to get Pixar films.\\n    11) How do I draw a circle as a Bezier (or B-spline) curve?\\n    12) How to order standards documents.\\n    13) How to FTP by email.\\n    14) How to tell whether a point is withi'),\n",
    "    ('What steps should you take to obtain information about using the mail handler and software distribution?', ' exercises.  To receive information describing\\nhow you can use the mail handler, simply mail graphtext@cs.brown.edu\\nand put the word \"Help\" in the Subject line.  Use the Subject line\\n\"Software-Distribution\" to receive information specifically concern'),\n",
    "    ('How to join ACM/SIGGRAPH\\n', 'trace height fields\\n    24) How to find the area of a 3D polygon\\n    25) How to join ACM/SIGGRAPH\\n    26) Where can I find MRI and CT scan volume data?\\n    27) Specific references on spatial data structures including quadtrees\\n\\tand octrees\\n    28) Wh'),\n",
    "    ('How to get general information about the\\nmail server?', '/news.answers/pictures-faq/part1\\nsend usenet/news.answers/pictures-faq/part2\\n\\nSend a message containing \"help\" to get general information about the\\nmail server.\\n\\nAlso, you could check out the resources described in sections 7, 8, and\\n20 above for mor'),\n",
    "    ('How many tool the kit contains on image manipulation, digital halftoning?', 'rting pixels of arbitrary channels,\\n    components, and bit precisions while allowing compression and machine\\n    byte-order independence.  The kit contains more than 50 tools with\\n    extensive support of image manipulation, digital halftoning and f'),\n",
    "    ('A Fast Algorithm for Raster\\nRotation', 'implementation is\\nalso present in PBMPLUS.  Reference: \"A Fast Algorithm for Raster\\nRotation\", by Alan Paeth (awpaeth@watcgl.waterloo.edu) Graphics\\nInterface \\'86 (Vancouver).  An article on the IM toolkit appears in\\nthe same journal.  An updated vers'),\n",
    "    ('What are some examples of formats that can be converted or rendered by commercial PostScript clones for PCs?', \" to Sun raster format, or HPGL to\\nX11 bitmap.  For example, some of the commercial PostScript clones for\\nPC's allow you to render to a disk file as well as a printer.  Also,\\nthe PostScript interpreters in the NeXT box and in Sun's X11/NeWs can\\nbe use\"),\n",
    "    ('Why is assembly language used for over 100 functions in the graphical interface?', \"short or floating point arithmetic to maintain the precision\\n  and accuracy of the pixel format. Over 100 functions are hand-coded in\\n  assembly language for maximum speed on the Intel hardware.  The entire\\n  graphical interface is also written in as\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hq4jqRAykA4",
    "outputId": "2131ccd0-7d9a-4e94-a6c4-6e515d2de691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search query: What are some examples of toolkits that can be used for image format conversion and basic image manipulations?,\n",
      "answer: umber of toolkits for converting from one image format to\n",
      "another, doing simple image manipulations such as size scaling, plus\n",
      "the above-mentioned 24 -> 8, color -> gray, gray -> b&w conversions.\n",
      "Here are pointers to some of them:\n",
      "\n",
      "    xv by John Bra\n",
      "Result 1: {'id': 'id_2471', 'distance': 4.962329387664795, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'atari/Graphics/jpeg4bin.zoo.\\nThese programs convert JPEG to/from PPM, GIF, Targa formats.\\n\\nI have not heard of any free or shareware JPEG-capable viewer for Ataris,\\nbut surely there must be one by now?  Pointers appreciated.\\n\\nAcorn Archimedes:\\n\\n!Chan'}\n",
      "Result 2: {'id': 'id_3166', 'distance': 5.410098075866699, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38497.txt'}, 'document': 'would like a hdftoppm type of utility, from\\nwhich I can then use the PBMplus stuff quite merrily. I can convert the cropped\\npart into another format for viewing/animation.\\n\\nOtherwise, can someone please explain how to set up the NCSA Visualisation S/'}\n",
      "Result 3: {'id': 'id_4264', 'distance': 5.501280307769775, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38682.txt'}, 'document': ':\\n  This program can let you READ, WRITE and DISPLAY images with different\\n  formats. It also let you do some special effects(ROTATION, DITHERING ....)\\n  on image. Its main purpose is to let you convert image among different\\n  formts.\\n  Include simpl'}\n",
      "Result 4: {'id': 'id_1505', 'distance': 5.677236080169678, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'sion  methods, noise generation, and image\\n  statistics computation. Over 150 such  image transformation programs\\n  have been developed.  As a result, almost any image processing  task\\n  can be performed quickly and conveniently. Additionally, HIPS a'}\n",
      "Result 5: {'id': 'id_2406', 'distance': 5.704128265380859, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'ble on non-PC platforms.\\n\\nHandmade Software also has a shareware image conversion and manipulation\\npackage, Image Alchemy.  This will translate JPEG files (both JFIF and HSI\\nformats) to and from many other image formats.  It can also display images.\\n'}\n",
      "Result 6: {'id': 'id_2539', 'distance': 5.774151802062988, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': \"ms are\\navailable to do it (see Mac portion of section 6A).  If you have an editor\\nthat handles binary files, you can strip a QuickTime JPEG PICT down to JFIF\\nby hand; see section 11 for details.\\n\\nAnother particular case is Handmade Software's program\"}\n",
      "Result 7: {'id': 'id_155', 'distance': 5.976705074310303, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37942.txt'}, 'document': 'r details of various graphics compression\\ntechniques.  So if you know where I could obtain descriptions of algo-\\nrithms or public-domain source codes for such formats as JPEG, GIF, and\\nfractals, I would be immensely grateful if you could share the in'}\n",
      "Result 8: {'id': 'id_1172', 'distance': 5.9971923828125, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38354.txt'}, 'document': 'ace to ask this question.  If not,\\nplease forgive me and point me in the right direction.\\n\\nDoes anybody know of a program that converts .GIF files to .BMP files\\nand if so, where can I ftp it from?  Any help would be greatly \\nappreciated.\\n\\nPlease resp'}\n",
      "Result 9: {'id': 'id_4832', 'distance': 6.01993989944458, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38795.txt'}, 'document': 's: 15\\n\\nTO: saz@hook.corp.mot.com\\n\\n\\nSZ>Does anybody know of a program that converts .GIF files to .BMP files\\nSZ>and if so, where can I ftp it from?  Any help would be greatly\\nSZ>appreciated.\\n\\n  Sure... A GREAT shareware  program is Graphic Workshop (t'}\n",
      "Result 10: {'id': 'id_2477', 'distance': 6.030846118927002, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': \"st any system:\\n\\nIf none of the above fits your situation, you can obtain and compile the free\\nJPEG conversion software described in 6B.  You'll also need a viewer program.\\nIf your display is 8 bits or less, any GIF viewer will do fine; if you have a\\n\"}\n",
      "\n",
      "Search query: What techniques are discussed in the context of quantizing 24-bit images down to 8 bits, and where can one find a relevant reference on this topic?,\n",
      "answer: for\n",
      "shading, chapter 19 for clipping, and branch out from there.\n",
      "\n",
      "\n",
      "3) Quantizing 24 bit images down to 8 bits.\n",
      "\n",
      "Find a copy of \"Color Image Quantization for Frame Buffer Display\" by\n",
      "Paul Heckbert, SIGGRAPH '82 Proceedings, page 297.  There are other\n",
      "\n",
      "Result 1: {'id': 'id_4304', 'distance': 4.755149841308594, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38682.txt'}, 'document': 'toring 24 bits images, even 8 bits images.\\n\\n  7. Not all subroutines are fully tested\\n\\n  8. This document is not well written. If you have any PROBLEM, SUGGESTION,\\n     COMMENT about this program,\\n     Please send to u7711501@bicmos.ee.nctu.edu.tw (1'}\n",
      "Result 2: {'id': 'id_3386', 'distance': 4.927762985229492, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38535.txt'}, 'document': \"to-gif-to-jpeg quality.\\nAlso, there's three kind of 8bit quantizers; your final image quality\\ndepends on them too.\\n \\nThis were the situation when I read jpeg FAQ a while ago.\\n \\nIMHO, it is design error of 'xv'; there should not be such confusing\\nerro\"}\n",
      "Result 3: {'id': 'id_3388', 'distance': 5.048422813415527, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38535.txt'}, 'document': \"mage instead of\\n   original 24bit should be a special case\\n  -xv allows saving the 8bit/rasterized image made with any quantizer\\n   -- the main case should be that 'xv' quantizes the image with the\\n   best quantizer available before saving the image \"}\n",
      "Result 4: {'id': 'id_2496', 'distance': 5.234501838684082, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'r JPEG image for display\\non 8-bit-or-less hardware requires color quantization.  This is true for\\n*all* color JPEGs: even if you feed a 256-or-less-color GIF into JPEG, what\\ncomes out of the decompressor is *not* 256 colors, but thousands of colors.\\n'}\n",
      "Result 5: {'id': 'id_3391', 'distance': 5.5457963943481445, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38535.txt'}, 'document': \"t, I'm sure when XV were designed 24bit displays were\\nknown. It is not bad error to program a program for 8bit images only\\nat that time, but when 24bit image formats are included to program the\\nwhole design should be changed to support 24bit images.\\n\"}\n",
      "Result 6: {'id': 'id_1521', 'distance': 5.580072402954102, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'rmats of a number of CCD cameras, and uncompressed binary\\n  images in byte, short integer, and 4-byte real pixel format in 1- or 2-\\n  dimensions. The result of an image processing operation can be short integer\\n  or real pixels, or the same as that o'}\n",
      "Result 7: {'id': 'id_2331', 'distance': 5.657174587249756, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'JPEG can store full color information: 24 bits/pixel\\n(16 million colors) instead of 8 or less (256 or fewer colors).  If you have\\nonly 8-bit display hardware then this may not seem like much of an advantage\\nto you.  Within a couple of years, though, '}\n",
      "Result 8: {'id': 'id_831', 'distance': 5.664295196533203, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38299.txt'}, 'document': \"ieve that if this thing can do 8 bit/pixel images\\nfrom the video source, it can't store 8 bits/pixel in the memory.  It's not\\nlike memory is that expensive any more.  If anybody has any information on\\ngetting 6 bit/pixel (or even 8 bit/pixel) images \"}\n",
      "Result 9: {'id': 'id_54', 'distance': 5.710365295410156, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37922.txt'}, 'document': \"y\\n>>zero or full intensity for each primary, I don't think you'd get great\\n>>equivalent 24-bit photographs.\\n>\\n>I have not suggested to do so; I wrote about problems, and the problem\\n>were clearly visible with 7 bit b&w images; not to mention 24 bit i\"}\n",
      "Result 10: {'id': 'id_832', 'distance': 5.720602989196777, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38299.txt'}, 'document': '\\ngetting 6 bit/pixel (or even 8 bit/pixel) images out of this thing, I would\\ngreatly appreciate your sending it to me.\\n\\nThanks.\\n\\nAllan Weber\\nSignal & Image Processing Institute\\nUniversity of Southern California\\nweber@sipi.usc.edu\\n'}\n",
      "\n",
      "Search query: How to FTP by email,\n",
      "answer:  9) Converting between vector formats.\n",
      "    10) How to get Pixar films.\n",
      "    11) How do I draw a circle as a Bezier (or B-spline) curve?\n",
      "    12) How to order standards documents.\n",
      "    13) How to FTP by email.\n",
      "    14) How to tell whether a point is withi\n",
      "Result 1: {'id': 'id_1865', 'distance': 5.343611240386963, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'llowing methods.\\n\\nftp:\\n  login to nic.switch.ch [130.59.1.40] as user anonymous and\\n  enter your internet-style address after being prompted for a\\n  password.\\n\\n\\tcd info_service/Usenet/periodic-postings\\n\\nmail:\\n  send e-mail to\\n\\nRFC-822:\\n   archive-ser'}\n",
      "Result 2: {'id': 'id_1875', 'distance': 6.006587982177734, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': '\\n\\n2. Notes\\n========\\n(Excerpted from the FAQ article)\\n\\nPlease do *not* post or mail messages saying \"I can\\'t FTP, could\\nsomeone mail this to me?\"  There are a number of automated mail servers\\nthat will send you things like this in response to a messag'}\n",
      "Result 3: {'id': 'id_3558', 'distance': 6.561342239379883, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38562.txt'}, 'document': 'upload to a more mainstream ftp place?\\n'}\n",
      "Result 4: {'id': 'id_2369', 'distance': 6.630157470703125, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'st of the programs described in this section are available by FTP.\\nIf you don\\'t know how to use FTP, see the FAQ article \"How to find sources\".\\n(If you don\\'t have direct access to FTP, read about ftpmail servers in the\\nsame article.)  That article ap'}\n",
      "Result 5: {'id': 'id_2020', 'distance': 6.712162017822266, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"ing back to you stuff.\\n\\nDEC's FTPMAIL\\n-------------\\n  Send a one-line message to ftpmail@decwrl.dec.com WITHOUT a Subject: field,\\n  and having a line containing the word 'help'.\\n  You should get back a message detailing the relevant procedures you\\n  \"}\n",
      "Result 6: {'id': 'id_2023', 'distance': 6.937989711761475, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"than to postmaster, since DECWRL's postmaster is not\\n  responsible for fixing ftpmail problems.\\n\\nBITFTP\\n------\\n  For BITNET sites ONLY, there's BITFTP@PUCC.\\n  Send a one-line 'help' message to this address for more info.\\n\\nLightwave 3D mail based file\"}\n",
      "Result 7: {'id': 'id_129', 'distance': 6.9785966873168945, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37935.txt'}, 'document': '                 508-277-6563\\n                                   ftp from\\n                              ptrg.eece.unm.edu\\n\\n    Login in anonyomus or ftp  with a valid email address as the password\\n               cd /pub/khoros/release\\n\\n   That will g'}\n",
      "Result 8: {'id': 'id_1864', 'distance': 6.992161750793457, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'net/periodic-postings directory. Search in the\\n  00index file by typing \"/\" and the word to look for.\\n  You may then just read the FAQ in the \"faqs\" directory, or decide\\n  to fetch it by one of the following methods.\\n\\nftp:\\n  login to nic.switch.ch [1'}\n",
      "Result 9: {'id': 'id_2018', 'distance': 6.997618675231934, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"e Franks <stevef@csl.sony.co.jp OR stevef@cs.umr.edu>\\n\\n\\n4. Mail servers and graphics-oriented BBSes\\n===========================================\\n\\nPlease check first with the FTP places above, with archie's help.\\nDon't overuse mail servers.\\n\\nThere are \"}\n",
      "Result 10: {'id': 'id_4825', 'distance': 7.052091121673584, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38759.txt'}, 'document': 'm an FTP site.  If any one can send me\\nsome good code, I will appreciate it a lot!  Thanks!\\n\\nStuart Denman\\nstusoft@u.washington.edu\\n'}\n",
      "\n",
      "Search query: What steps should you take to obtain information about using the mail handler and software distribution?,\n",
      "answer:  exercises.  To receive information describing\n",
      "how you can use the mail handler, simply mail graphtext@cs.brown.edu\n",
      "and put the word \"Help\" in the Subject line.  Use the Subject line\n",
      "\"Software-Distribution\" to receive information specifically concern\n",
      "Result 1: {'id': 'id_1966', 'distance': 7.183326721191406, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': ' stuff in various directories.\\n\\tAutomatic mailer is archive-server@siggraph.org (\"send index\").\\n\\nftp.cs.unc.edu [128.109.136.159]: pub/reaction_diffusion - Greg Turk\\'s work on\\n\\treaction-diffusion textures, X windows code (SIGGRAPH \\'91)\\n\\navs.ncsc.org '}\n",
      "Result 2: {'id': 'id_3368', 'distance': 7.243394374847412, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38534.txt'}, 'document': 'elpful. If you have a system or use a system that might be of use, could you\\n>mail me your system requirements, what it is used for, and all the hardware and\\n>software that will be necessary to set the system up.  If you need more \\n>info, you  can ma'}\n",
      "Result 3: {'id': 'id_2099', 'distance': 7.2642316818237305, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'anual, administration, and shipping.\\n\\n  We recommend that Vertigo users subscribe to our technical support\\n  services. For an annual fee you will receive: technical assistance\\n  on our support hotline, bug fixes, software upgrades and manual updates.'}\n",
      "Result 4: {'id': 'id_1422', 'distance': 7.418599605560303, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'nprotected software.\"\\n\\n  Process Software Solutions, PO Box 2110, Wollongong, New South Wales,\\n  Australia. 2500. Phone 61 42 261757  Fax 61 42 264190.\\n\\nEnhance\\n-------\\n  Enhance has a RrulerS tool that supports measurements and additionally\\n  provid'}\n",
      "Result 5: {'id': 'id_2137', 'distance': 7.46699333190918, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'n Exchange file parser,\\n  both available in source form (and for free) for research purposes.\\n  Soon they will also have an EXPRESS-based database system.\\n\\n  For the tools contact Mike Mead, Phone: +44 (0235) 44 6710 (FAX: x 5893),\\n  e-mail: mm@inf.r'}\n",
      "Result 6: {'id': 'id_2097', 'distance': 7.687284469604492, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"icipating in this program please send a\\n  letter by mail or fax (604/684-2108) on your institution's letterhead\\n  briefly outlining your potential uses for Vertigo together with the\\n  following information: 1. UNIX version 2. Model and number of SGI\\n\"}\n",
      "Result 7: {'id': 'id_1733', 'distance': 7.775486946105957, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': '1, Sicence Park Drive\\n  Singapore 0511\\n  Republic of Singapore\\n  Tel : (65)7720435\\n  Fax : (65)7795966\\n  Email : leehian@iti.gov.sg\\n\\n\\n---------------------------------------------------------\\nGVLware Distribution:\\n        Bob  - An interactive volume'}\n",
      "Result 8: {'id': 'id_4374', 'distance': 7.792003154754639, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38692.txt'}, 'document': 'HIC FUNCTIONS ARE AVAILABLE. THIS IS\\n   SUFFICIENT TO WORK WITH.\\n\\n   IF YOU ARE INTERESTED IN KEEPING \"SPHINX\", SEND US YOUR EMAIL\\n   AND YOU WILL RECEIVE NEWS ABOUT THE PACKAGE EVOLUTION.\\n\\n   THE SOFTWARE IS CHANGING WITH USER SUGGESTIONS WE WILL\\n  '}\n",
      "Result 9: {'id': 'id_1657', 'distance': 7.824957847595215, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': 's package)\\n\\t\\tPlatforms: Mac, SGI, Sun, DEC, HP, IBM\\n\\n  Contact:\\n  Spyglass, Inc.\\n  P.O. Box 6388\\n  Champaign, IL  61826\\n  (217) 355-6000\\n\\nKHOROS 1.0 Patch 5\\n------------------\\n  Available via anonymous ftp at pprg.eece.unm.edu (129.24.24.10).\\n  cd to'}\n",
      "Result 10: {'id': 'id_3081', 'distance': 7.949307441711426, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38482.txt'}, 'document': 'ight be of use, could you\\nmail me your system requirements, what it is used for, and all the hardware and\\nsoftware that will be necessary to set the system up.  If you need more \\ninfo, you  can mail me at   eylerken@u.washington.edu\\n\\nthanks in advanc'}\n",
      "\n",
      "Search query: How to join ACM/SIGGRAPH\n",
      ",\n",
      "answer: trace height fields\n",
      "    24) How to find the area of a 3D polygon\n",
      "    25) How to join ACM/SIGGRAPH\n",
      "    26) Where can I find MRI and CT scan volume data?\n",
      "    27) Specific references on spatial data structures including quadtrees\n",
      "\tand octrees\n",
      "    28) Wh\n",
      "Result 1: {'id': 'id_4136', 'distance': 5.816601753234863, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': 's.  In addition, this\\nform asks if  ACM SIGGRAPH may  use the your materials for conference and\\norganizational promotional material in exchange for full author/artist\\ncredit information.\\n'}\n",
      "Result 2: {'id': 'id_4128', 'distance': 6.258306503295898, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': 'aterial:  I grant ACM SIGGRAPH the right to use my\\nslides for conference and organization publicity, both now and in the\\nfuture.  This includes usage on posters, brochures, catalogs, promotional\\nitems, or media broadcast. In exchange, SIGGRAPH provid'}\n",
      "Result 3: {'id': 'id_4131', 'distance': 6.440707206726074, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': ' people and organizations preparing material for \\nSIGGRAPH conferences. This entry form explains the uses SIGGRAPH will \\nmake of the material and requires you to acknowledge that you have \\npermission to use this material.  This may involve seeking cl'}\n",
      "Result 4: {'id': 'id_1966', 'distance': 6.459078788757324, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': ' stuff in various directories.\\n\\tAutomatic mailer is archive-server@siggraph.org (\"send index\").\\n\\nftp.cs.unc.edu [128.109.136.159]: pub/reaction_diffusion - Greg Turk\\'s work on\\n\\treaction-diffusion textures, X windows code (SIGGRAPH \\'91)\\n\\navs.ncsc.org '}\n",
      "Result 5: {'id': 'id_1974', 'distance': 6.473857879638672, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"to exist.\\n\\tIt contains Powerglove code, VR papers, 3D images and IRC research\\n\\tmaterial.\\n\\tJonathan Magid <jem@sunSITE.unc.edu>\\n\\narchive.cis.ohio-state.edu [128.146.8.52]: pub/siggraph92 - Code for\\n\\tSiggraph '92 Course 23 (Procedural Modeling and Rend\"}\n",
      "Result 6: {'id': 'id_4104', 'distance': 6.4894256591796875, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': \"____________cut\\nhere__________________________________\\n\\n         ACM SIGGRAPH '93 SIGKIDS RESEARCH SHOWCASE ENTRY FORM\\n\\n\\nA copy of this form must accompany each proposal you submit.  Send SIGKids\\nResearch Showcase Entries to:\\n\\nDiane Schwartz\\nSIGGRAPH\"}\n",
      "Result 7: {'id': 'id_4129', 'distance': 6.651611328125, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': ', or media broadcast. In exchange, SIGGRAPH provides full\\nauthor/artist credit information on all promotional material.\\n\\n___Yes ___No  I grant ACM SIGGRAPH permission to use slides of my work\\n              for conference and organization publicity.\\n\\n'}\n",
      "Result 8: {'id': 'id_1912', 'distance': 6.665335655212402, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': ' to start is\\n        with the command\\n             send index\\n        which will give you an up-to-date list of available information.\\n\\n        Additions/corrections/suggestions may be directed to the admin,\\n        \"bibadmin@siggraph.org\".\\n\\nImage Ma'}\n",
      "Result 9: {'id': 'id_376', 'distance': 6.735665798187256, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38229.txt'}, 'document': 'Siggraph membership, contact Michael McCool via:\\n\\tInternet: mccool@dgp.utoronto.ca; \\n\\tVoice: 652-8072/978-6619/978-6027; \\n\\tFax: 653-1654\\n\\n'}\n",
      "Result 10: {'id': 'id_4127', 'distance': 6.742619037628174, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38658.txt'}, 'document': \"t SIGGRAPH'93\\npermission to consider my piece for the SIGKids Research Showcase.  I\\nmaintain the copyright to my work and will receive full credit wherever\\nthis work is used.\\n\\nConference promotional material:  I grant ACM SIGGRAPH the right to use my\"}\n",
      "\n",
      "Search query: How to get general information about the\n",
      "mail server?,\n",
      "answer: /news.answers/pictures-faq/part1\n",
      "send usenet/news.answers/pictures-faq/part2\n",
      "\n",
      "Send a message containing \"help\" to get general information about the\n",
      "mail server.\n",
      "\n",
      "Also, you could check out the resources described in sections 7, 8, and\n",
      "20 above for mor\n",
      "Result 1: {'id': 'id_2024', 'distance': 6.96358060836792, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'dress for more info.\\n\\nLightwave 3D mail based file-server\\n-----------------------------------\\n  A mail based file server for 3D objects, 24bit JPEG images, GIF images\\n  and image maps is now online for all those with Internet mail access.\\n  The serve'}\n",
      "Result 2: {'id': 'id_2025', 'distance': 7.1943769454956055, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': 'r all those with Internet mail access.\\n  The server is the official archive site for the Lightwave 3D mail-list\\n  and contains many PD and Shareware graphics utilities for\\n  several computer platforms including Amiga, Atari, IBM and Macintosh.\\n\\n  The'}\n",
      "Result 3: {'id': 'id_1876', 'distance': 7.701071739196777, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': ' send you things like this in response to a message.\\n\\nThere are a number of sites that archive the Usenet sources newsgroups\\nand make them available via an email query system.  You send a message\\nto an automated server saying something like \"send com'}\n",
      "Result 4: {'id': 'id_2019', 'distance': 7.823094367980957, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"ie's help.\\nDon't overuse mail servers.\\n\\nThere are some troubles with wrong return addresses. Many of these\\nmail servers have a command like\\n   path a_valid_return_e-mail_address\\nto get a hint for sending back to you stuff.\\n\\nDEC's FTPMAIL\\n------------\"}\n",
      "Result 5: {'id': 'id_1861', 'distance': 7.891814231872559, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"nder the\\nSubject 4: Mail servers )\\n\\n--\\n\\nThe Resource Listing is accesible through WAIS in the machine\\nenuxva.eas.asu.edu (port 8000) under the name graphics-resources-list.\\nIt's got a digest-type line before every numbered item for purposes of\\nindexi\"}\n",
      "Result 6: {'id': 'id_2018', 'distance': 7.90928316116333, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"e Franks <stevef@csl.sony.co.jp OR stevef@cs.umr.edu>\\n\\n\\n4. Mail servers and graphics-oriented BBSes\\n===========================================\\n\\nPlease check first with the FTP places above, with archie's help.\\nDon't overuse mail servers.\\n\\nThere are \"}\n",
      "Result 7: {'id': 'id_2118', 'distance': 7.909432888031006, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \", from DEC's Randy Rost (rost@kpc.com).\\n[ The object archive server seems to be mothballed. In a future version,\\n I'll remove the ref. to it -- nfotis ]\\n\\n  Available also through their mail server. To obtain help about using this\\n  service, send a me\"}\n",
      "Result 8: {'id': 'id_747', 'distance': 8.192117691040039, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38289.txt'}, 'document': \"ublic domain. If anyone knows a place where I can\\nget it (preferably FTP/gopher/mailserver etc.; otherwise snail mail) please\\nlet me know. I you have it yourself and are willing to send me the file,\\ndrop me a line.\\n\\nI'll be using it with a program ca\"}\n",
      "Result 9: {'id': 'id_1580', 'distance': 8.220966339111328, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': \"There's also an\\n        e-mail server for the people without Internet access: send a letter\\n        to archive-server@ames.arc.nasa.gov (or ames!archive-server). In the\\n        subject of your letter (or in the body), use commands like:\\n\\n        send\"}\n",
      "Result 10: {'id': 'id_1866', 'distance': 8.341137886047363, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"s\\n\\nmail:\\n  send e-mail to\\n\\nRFC-822:\\n   archive-server@nic.switch.ch\\nX.400:\\n  /S=archive-server/OU=nic/O=switch/PRMD=switch/ADMD=arcom/C=ch/\\n\\nEnter 'help' in the bodypart to receive instructions. No information\\nis required in the subject header line.\\n\"}\n",
      "\n",
      "Search query: How many tool the kit contains on image manipulation, digital halftoning?,\n",
      "answer: rting pixels of arbitrary channels,\n",
      "    components, and bit precisions while allowing compression and machine\n",
      "    byte-order independence.  The kit contains more than 50 tools with\n",
      "    extensive support of image manipulation, digital halftoning and f\n",
      "Result 1: {'id': 'id_2459', 'distance': 5.601728439331055, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 's JPEG.  The current version is 2.0.8.  A demo version\\nis available from amiga.physik.unizh.ch (and mirror sites), file\\namiga/gfx/edit/hamlab208d.lha.  The demo version will crop images larger\\nthan 512x512, but it is otherwise fully functional.\\n\\nRend'}\n",
      "Result 2: {'id': 'id_832', 'distance': 5.956019401550293, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38299.txt'}, 'document': '\\ngetting 6 bit/pixel (or even 8 bit/pixel) images out of this thing, I would\\ngreatly appreciate your sending it to me.\\n\\nThanks.\\n\\nAllan Weber\\nSignal & Image Processing Institute\\nUniversity of Southern California\\nweber@sipi.usc.edu\\n'}\n",
      "Result 3: {'id': 'id_1455', 'distance': 6.000551700592041, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'and other frame grabbers.\\n  Surely you can find much more PC-related stuff in it.\\n\\nMAXEN386\\n--------\\n  A couple of Canadians have written a program named MAXEN386 which does\\n  maximum entropy image deconvolution. Their company is named Digital\\n  Sign'}\n",
      "Result 4: {'id': 'id_2460', 'distance': 6.103735446929932, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': '2x512, but it is otherwise fully functional.\\n\\nRend24 (shareware, $30) is an image renderer that can display JPEG, ILBM,\\nand GIF images.  The program can be used to create animations, even\\ncapturing frames on-the-fly from rendering packages like Light'}\n",
      "Result 5: {'id': 'id_2407', 'distance': 6.126542091369629, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': \"other image formats.  It can also display images.\\nA demo version of Image Alchemy version 1.6.1 is available from Simtel20 and\\nmirror sites (see NOTE below), file msdos/graphics/alch161.zip.\\n\\nNOTE ABOUT SIMTEL20: The Internet's key archive site for P\"}\n",
      "Result 6: {'id': 'id_2463', 'distance': 6.148900508880615, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': \"amiga.physik.unizh.ch (and mirror sites), file\\namiga/gfx/show/ViewTek104.lha.\\n\\nIf you're willing to spend real money, there are several commercial packages\\nthat support JPEG.  Two are written by Thomas Krehbiel, the author of Rend24\\nand Viewtek.  The\"}\n",
      "Result 7: {'id': 'id_1415', 'distance': 6.151861190795898, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'or image enhancement tool.\\n  This tool should be used when the user intends to operate in grey-scale\\n  images only.  It should be noted that Digital Darkroom is not as\\n  powerful as either Adobe Photoshop or ColorStudio.\\n\\n  Silicon Beach Software 977'}\n",
      "Result 8: {'id': 'id_2368', 'distance': 6.185794353485107, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': ' as Image Alchemy, may use a completely different\\nquality scale.  Some programs don\\'t even provide a numeric scale, just\\n\"high\"/\"medium\"/\"low\"-style choices.)\\n\\n\\n[6]  Where can I get JPEG software?\\n\\nMost of the programs described in this section are a'}\n",
      "Result 9: {'id': 'id_2466', 'distance': 6.248229503631592, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38403.txt'}, 'document': 'oftware for Amigas.  ImageMaster, from Black Belt Systems, is another\\nwell-regarded commercial graphics package with JPEG support.\\n\\nThe free IJG JPEG software is available compiled for Amigas from\\namiga.physik.unizh.ch (and mirror sites) in directory'}\n",
      "Result 10: {'id': 'id_3467', 'distance': 6.260059356689453, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38546.txt'}, 'document': 'rigel.tamu.edu (PRESTON, LISA M)\\n\\nI have a trident card and fullview works real gif jpg try it#\\ndave\\n'}\n",
      "\n",
      "Search query: A Fast Algorithm for Raster\n",
      "Rotation,\n",
      "answer: implementation is\n",
      "also present in PBMPLUS.  Reference: \"A Fast Algorithm for Raster\n",
      "Rotation\", by Alan Paeth (awpaeth@watcgl.waterloo.edu) Graphics\n",
      "Interface '86 (Vancouver).  An article on the IM toolkit appears in\n",
      "the same journal.  An updated vers\n",
      "Result 1: {'id': 'id_1529', 'distance': 7.61704683303833, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38375.txt'}, 'document': 'ular equal weight filters, unsharp\\n   masking, median filters, user defined filter kernel.  Ellipse, rectangle,\\n   line, gradient, Gaussian, and user defined filters can be rotated to\\n   any specified angle.\\no  CCD data reduction: flat fielding, dark'}\n",
      "Result 2: {'id': 'id_404', 'distance': 7.764352798461914, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38236.txt'}, 'document': \"st: rs1.rrz.uni-koeln.de\\nKeywords: Polygon Reduction, Marching Cubes, Surfaces, Midical Visualisation\\n\\n\\nDear Reader,\\n\\n\\nI'am searching for an implementation of a polygon reduction algorithm\\nfor marching cubes surfaces. I think the best one is the redu\"}\n",
      "Result 3: {'id': 'id_4676', 'distance': 7.79599666595459, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38734.txt'}, 'document': 're there any better solutions to turning the outlines into\\npolgyons other than the trapezoid decomposer? I am not fond of this solution\\nsince it creates excess number of polygons.\\n\\nAnother question, for those in the know: what is the best algorithm t'}\n",
      "Result 4: {'id': 'id_2197', 'distance': 7.878731727600098, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38389.txt'}, 'document': \"ws.cso.uiuc.edu> osprey@ux4.cso.uiuc.edu (Lucas Adamski) writes:\\n>This may be a fairly routine request on here, but I'm looking for a fast\\n>polygon routine to be used in a 3D game.\\n\\n\\tA fast polygon routine to do WHAT?\\n\"}\n",
      "Result 5: {'id': 'id_2194', 'distance': 8.177529335021973, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38388.txt'}, 'document': \"tine request on here, but I'm looking for a fast\\npolygon routine to be used in a 3D game.  I have one that works right now, but\\nits very slow.  Could anyone point me to one, pref in ASM that is fairly well\\ndocumented and flexible?\\n\\tThanx,\\n           \"}\n",
      "Result 6: {'id': 'id_1078', 'distance': 8.249168395996094, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38336.txt'}, 'document': \"From: rws2v@uvacs.cs.Virginia.EDU (Richard Stoakley)\\nSubject: Need a good concave -> convex polygon algorithm\\nOrganization: University of Virginia Computer Science Department\\nLines: 6\\n\\n\\tWe need a good concave ->convex polygon conversion routine.\\nI've\"}\n",
      "Result 7: {'id': 'id_2947', 'distance': 8.293718338012695, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38462.txt'}, 'document': 'ching/contracting uniformly over x or y, or\\n>rotating the whole drawing, are not satisfactory.\\n>\\n>So the question is: does any kind soul know of an algorithm for\\n>removing such distortion?  In particular, if I have three sets of\\n>points \\n>\\n>Reference'}\n",
      "Result 8: {'id': 'id_1079', 'distance': 8.351133346557617, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38336.txt'}, 'document': \" concave ->convex polygon conversion routine.\\nI've tried a couple without much luck.  Please E-mail responses and I\\nwill post a summary of any replies.  Thank you.\\n\\nRichard Stoakley\\nrws2v@uvacs.cs.Virginia.EDU\\n\"}\n",
      "Result 9: {'id': 'id_194', 'distance': 8.59383487701416, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37949.txt'}, 'document': 'ti$aqe@travis.csd.harris.com> srp@travis.csd.harris.com (Stephen Pietrowicz) writes:\\n>How do you go about orienting all normals in the same direction, given a \\n>set of points, edges and faces?\\n\\nThis algorithm works well for me:\\n\\nAlgorithm to attempt '}\n",
      "Result 10: {'id': 'id_482', 'distance': 8.686746597290039, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38248.txt'}, 'document': '>  a polygon.  I would prefer a method that would do this in as little\\n>  time as possible.  I need this for use in a forward raytracing\\n>  program.\\n\\nI think that this is a very difficult problem.  To start with, lines and\\npolygons are semi-algebraic'}\n",
      "\n",
      "Search query: What are some examples of formats that can be converted or rendered by commercial PostScript clones for PCs?,\n",
      "answer:  to Sun raster format, or HPGL to\n",
      "X11 bitmap.  For example, some of the commercial PostScript clones for\n",
      "PC's allow you to render to a disk file as well as a printer.  Also,\n",
      "the PostScript interpreters in the NeXT box and in Sun's X11/NeWs can\n",
      "be use\n",
      "Result 1: {'id': 'id_3918', 'distance': 6.037430763244629, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38622.txt'}, 'document': '\\nIs there a way to create high quality postscript printouts?  What is the\\nlimiting component, the postscript language or the postscript interpretor on \\nthe printer?\\n \\nThe Big question:\\n\\nWhere can I get some software to drive the SCSI port for this pr'}\n",
      "Result 2: {'id': 'id_313', 'distance': 6.190304279327393, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38220.txt'}, 'document': 'ektonic esacpe sequences  \\ninto some useful formats. I would rather not have to goto a bitmap format.  \\nI can convert them to Window Meta FIles easily enough, but I would rather  \\nconvert them to Corel Draw, .CDR, or MS Power Point, .PPT, files.  \\nMi'}\n",
      "Result 3: {'id': 'id_2904', 'distance': 6.609923362731934, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38459.txt'}, 'document': 'and\\nso the fig format can not be able to be an interpreter of ANY arbitrary\\nps code. The only program I know to manipulate PostScript files is\\nIslandDraw.\\nI for myself use xfig and include the PostScript files (converted to\\nepsi format). Small change'}\n",
      "Result 4: {'id': 'id_4244', 'distance': 6.7269287109375, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38679.txt'}, 'document': 'put for the\\n>|> programme.Is there a utility that converts postscript to xfig format?\\n>|> \\tAny help would be greatly appreciated.\\n>|> \\t\\t\\t\\tNishantha\\nHave you checked out Adobe Illustrator? There are a few Unix versions\\nfor it available, depending on y'}\n",
      "Result 5: {'id': 'id_4328', 'distance': 6.736164093017578, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38686.txt'}, 'document': 'it is of no use since I cannot use postscript files as input for the\\n>>|> programme.Is there a utility that converts postscript to xfig format?\\n>>|> \\tAny help would be greatly appreciated.\\n>>|> \\t\\t\\t\\tNishantha\\n>Have you checked out Adobe Illustrator? T'}\n",
      "Result 6: {'id': 'id_4330', 'distance': 6.785569190979004, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38686.txt'}, 'document': \"e may be others, such\\n>as for Sun SparcStation, but I don't know for sure.\\n\\nYou can include postscript epsi files in xfig (encapsulated postscript\\ninfo files). You can't actually edit the postscript file, but you're able\\nto draw over the postscript f\"}\n",
      "Result 7: {'id': 'id_314', 'distance': 6.8157148361206055, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38220.txt'}, 'document': 'l Draw, .CDR, or MS Power Point, .PPT, files.  \\nMicrosoft would not give me the format. I was wondering if anybody out  \\nthere knows the formats for these two applications.\\n\\n'}\n",
      "Result 8: {'id': 'id_105', 'distance': 6.944218635559082, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\37931.txt'}, 'document': '. It gives (at least, the X11R4 version does) louzy\\noutput: the hardcopy looks very grainy to me.\\nInstead, I use pnmtops. This takes full advantage PostScript, and\\nlets the printer do the dirty job of dithering a (graylevel)\\nimage to black and white '}\n",
      "Result 9: {'id': 'id_3913', 'distance': 6.9865217208862305, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38622.txt'}, 'document': 'lication quality printer but the quality of our postscript printouts \\nare less than acceptable.  We create the postscript files with a variaty of \\nprograms, such as showcase, xv, and tops.  When we convert to postscript \\nwith tops and use the -l opti'}\n",
      "Result 10: {'id': 'id_4667', 'distance': 6.994150638580322, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38734.txt'}, 'document': ' some alternate solutions on how to turn a Postscript Type 1 or\\nTrueType font outline into polygons that can be subsequently scan converted\\nby a 3D scanline renderer. \\n\\nI have been studying the problem of font conversion for a few years but\\nhave neve'}\n",
      "\n",
      "Search query: Why is assembly language used for over 100 functions in the graphical interface?,\n",
      "answer: short or floating point arithmetic to maintain the precision\n",
      "  and accuracy of the pixel format. Over 100 functions are hand-coded in\n",
      "  assembly language for maximum speed on the Intel hardware.  The entire\n",
      "  graphical interface is also written in as\n",
      "Result 1: {'id': 'id_3106', 'distance': 7.474847316741943, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38485.txt'}, 'document': '>\\n>Just to clarify, the 3D routines that are mentioned in various places\\n>on the mac are in a libray, not the ROM of the mac.  A few years ago before\\n>I knew anything about implementing graphics, I came across a demo of the\\n>Apple GrafSys3D library a'}\n",
      "Result 2: {'id': 'id_3420', 'distance': 7.488521099090576, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38537.txt'}, 'document': \"s a bundle with Visual Edge's UIM/X product.\\n   This will enable user to use a GUI builder to create the graphical\\n   layout of an application.\\n \\nC Exponent Graphics 2.0 key facts:\\n \\n1. Written in C for C application programmers/developers.  The libr\"}\n",
      "Result 3: {'id': 'id_3421', 'distance': 7.505356788635254, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38537.txt'}, 'document': 'or C application programmers/developers.  The library\\n   is 100% written in C, and the programming interface conforms to C\\n   standards, taking advantage fo the most desirable features of C.\\n2. Build-in GUI for interactive plot customization.  Throug'}\n",
      "Result 4: {'id': 'id_2834', 'distance': 7.606469631195068, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38450.txt'}, 'document': \" the entity's name.  The number of entities < 1000\\n|> and vertices < 100000.  It would be nice if the tool minimized line\\n|> cross-overs and did a good job of layout.  ;-)\\n|> \\n|>   I have looked in the FAQ for comp.graphics and gnuplot without succes\"}\n",
      "Result 5: {'id': 'id_2088', 'distance': 7.659818649291992, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38377.txt'}, 'document': \"sible object types.\\n  Applications include: NC machining, Animation utilities,\\n    Dimensioning, FEM analysis, etc.\\n  Rendering subsystem, with support for animations.\\n  Support the following platforms: HP 300 and 800's (X11R4, HP-UX 6.5),\\n    SGI 4D\"}\n",
      "Result 6: {'id': 'id_1677', 'distance': 8.020668983459473, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': 'c.\\n  It seems more a image processing system than a generic SciVi system (IMHO)\\n  Major elements are:\\n\\n  - a visual programming language, which automatically exploits the inherent\\n        parallelism\\n  - a code generator which converts the graph to a'}\n",
      "Result 7: {'id': 'id_859', 'distance': 8.117411613464355, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38304.txt'}, 'document': 'ary and as such is a great, portable\\ninterface for the development of interactive 3D graphics applications. It\\nis not, however, an indicator of performance, as that will vary strongly\\nfrom machine to machine and vendor to vendor.  SGI is committed to'}\n",
      "Result 8: {'id': 'id_1659', 'distance': 8.152139663696289, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38376.txt'}, 'document': 'cs. Very extensive and at its heart is visual programming.\\n  Khoros components include a visual programming language, code\\n  generators for extending the visual language and adding new application\\n  packages to the system, an interactive user interfa'}\n",
      "Result 9: {'id': 'id_3710', 'distance': 8.34374713897705, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38582.txt'}, 'document': 'SITES\\n\\n\\tA one-day seminar devoted to practical applications of\\n\\tcomputer workstations for efficient processing, design, and\\n\\t\\t\\tManufacture of composites\\n\\nMay 18, 1993\\nat\\n The University of Akron\\n  Akron, Ohio\\n\\nSpeakers on:\\n Advancement in Graphics Vi'}\n",
      "Result 10: {'id': 'id_3107', 'distance': 8.363276481628418, 'metadata': {'source': '../../dataset/20news-bydate-train/comp.graphics\\\\38485.txt'}, 'document': \"me across a demo of the\\n>Apple GrafSys3D library and it actually did a lot.  However, it is quite\\n>limited in the sense that it's a low-level 3D library; your code still has\\n>to plot individual points, draw each line, etc ad nauseum.  It has nothing\\n\"}\n",
      "Статистика по позициям релевантных ответов: {'min': None, 'max': None, 'mean': None, 'not found': None}\n"
     ]
    }
   ],
   "source": [
    "#Нужно написать эксперимент для оценки полученной коллекции\n",
    "collector = ChromaCollector(splitter, embedder)\n",
    "evaluator = CollectorEvaluator(collector, n_top=n_top)\n",
    "\n",
    "stats = evaluator.explore_and_calculate(data)\n",
    "print(\"Статистика по позициям релевантных ответов:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "vnP32QsGMENI"
   },
   "outputs": [],
   "source": [
    "def generate(model_path, prompts, n_ctx=2000, top_k=30, top_p=0.9, temperature=0.2, repeat_penalty=1.1):\n",
    "  #Реализовать генерацию текста с помощью LLM модели\n",
    "  llm = Llama(model_path=model_path, n_ctx=n_ctx)\n",
    "\n",
    "  if isinstance(prompts, str):\n",
    "    prompts = [prompts]\n",
    "\n",
    "  responses = []\n",
    "\n",
    "  for prompt in prompts:\n",
    "    response = llm(prompt,\n",
    "                   top_k=top_k, top_p=top_p, temperature=temperature, \n",
    "                  #  repetition_penalty=repeat_penalty\n",
    "                   )\n",
    "    responses.append(response)\n",
    "\n",
    "  return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8Dij2fi3MQh_"
   },
   "outputs": [],
   "source": [
    "class QuestionAndAnswers:\n",
    "    # Класс для представления вопросов и ответов\n",
    "    def __init__(self, question, correct_answer, generated_answer=None, prompt=None):\n",
    "        self.question = question\n",
    "        self.correct_answer = correct_answer\n",
    "        self.generated_answer = generated_answer\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def __repr__(self):\n",
    "      return f\"Q: {self.question}\\nCorrect: {self.correct_answer}\\nGenerated: {self.generated_answer}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "JYgZ8Lr3MSZy"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # Класс для представления набора данных, содержащего вопросы и ответы.\n",
    "    def __init__(self, qa_list):\n",
    "      self.qa_list = qa_list\n",
    "\n",
    "def get_prompt(question, context):\n",
    "  return f'Answear the question: \"{question}\", using context: {context}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaGghTdGMX0C"
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e93b3899edc041ac8f7a8039d9e8fa52",
      "e7750855102c428e8d86079f10759d4d",
      "fe6cd592a4cb44299974814803d64dca",
      "f59614bafd17423eb0f28b0cf0404b50",
      "2b99c29b7c4049a0bb911b2024f4d9aa",
      "87a7758349104798b8eabaf4036b6916",
      "5b56b69baff44d24bc9b80f30ec5f245",
      "36ed2223fae948abbeebbbc6ff04ac75",
      "e013a4bc5377482489efae4adbbc1ea7",
      "49bf9f0bf07b4b9f820913d30a092cae",
      "f5dc20348ea340bdb636342351ae5d4e",
      "f4234ab97f4a4d94a76940170b4c0386",
      "941962a50b6b4cf19f0962e7c1d3f748",
      "f181fe130cb7439ca599c999333457d1",
      "347f07adeea34cdda852df42b897f0ba",
      "7981a4114e824bcd85d896fe2a261721",
      "754bf2b59aa94eb9840fbd655cfd5820",
      "fc55fd2dd6dd4915b30029ff1bce0a06",
      "085e9c2a2c434c2fab31c2badd6b376a",
      "3dc563a7806448bb89b40592d8f02ab4",
      "45dd02511b76415b82ba3485cca6bcfc",
      "18ad54a26ec5426ba16b2ad98945327f"
     ]
    },
    "id": "tBHRRUW5MZts",
    "outputId": "f77c10a5-bdc0-4c62-a0ed-a3fad44e4c85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    3331.24 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    90 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    5509.10 ms /   105 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is sun?\n",
      "Correct: The sun is an average star.\n",
      "Generated: [{'id': 'cmpl-884589a3-f7ba-4200-acd1-adcc95ab6fc3', 'object': 'text_completion', 'created': 1731330581, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe sun is a massive celestial object located at a distance of', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 90, 'completion_tokens': 16, 'total_tokens': 106}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Нужно написать эксперимент для генерации текста (ответа на вопрос) с помощью функции generate\n",
    "model_file=\"../assets/models/mistral-7b-openorca.Q4_K_M.gguf\" \n",
    "\n",
    "example_dataset = Dataset([\n",
    "    QuestionAndAnswers(\n",
    "        question='What is sun?',\n",
    "        correct_answer='The sun is an average star.'),\n",
    "])\n",
    "\n",
    "for qa in example_dataset.qa_list:\n",
    "  context = example_collector.get([qa.question], n_results=1)\n",
    "  qa.prompt = get_prompt(qa.question, context)\n",
    "\n",
    "  qa.generated_answer = generate(model_file, [qa.prompt])\n",
    "  print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe sun is a massive celestial object located at a distance of'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.generated_answer[0]['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    4077.94 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   110 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    4078.24 ms /   111 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How does Tom Van Flandern view the concept of \"dark matter\" and other unobservable phenomena in physics?\n",
      "Correct: Tom Van Flandern is skeptical of \"dark matter\" and other unobservable, purely theoretical constructs in physics, such as quarks and black holes. He questions whether their existence can be inferred solely from theory, suggesting that existence should be tied to observability.\n",
      "Generated: [{'id': 'cmpl-a39197a4-40ba-4d4a-a529-98120f6d4025', 'object': 'text_completion', 'created': 1731332776, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 110, 'completion_tokens': 0, 'total_tokens': 110}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    7255.05 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   200 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    7255.28 ms /   201 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the main point of disagreement between Tom Van Flandern and Bruce Scott on the concept of existence in physics?\n",
      "Correct: The main disagreement is that Bruce Scott argues \"existence\" should be synonymous with \"observable\" in physics, while Van Flandern challenges this view, particularly when considering phenomena like curvature, which he argues cannot exist without something \"non-curved\" to compare it to.\n",
      "Generated: [{'id': 'cmpl-d9619140-4f95-4a3e-9f46-2c754f690085', 'object': 'text_completion', 'created': 1731332781, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 200, 'completion_tokens': 0, 'total_tokens': 200}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    6726.18 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   187 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    8885.35 ms /   202 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: According to Nikola Tesla, why does he believe that space cannot be curved?\n",
      "Correct: Nikola Tesla argues that space cannot be curved because it has no properties on its own. He believes properties only apply to matter within space, and saying that large bodies curve space implies \"something can act upon nothing,\" a view he does not support.\n",
      "Generated: [{'id': 'cmpl-95d1e8f8-e349-47ff-b4f5-6db699340b79', 'object': 'text_completion', 'created': 1731332789, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nAnswer: Nikola Tesla believes that space cannot be curved', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 187, 'completion_tokens': 16, 'total_tokens': 203}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    6347.30 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   175 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    8491.70 ms /   190 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the escape velocity equation in a circular orbit, and how does it relate to circular orbital velocity?\n",
      "Correct:  The escape velocity Vesc in a circular orbit is given by the equation Vesc = sqrt(2 * M * G / r) = sqrt(2) * Vс  is the circular orbital velocity. This means the escape velocity is approximately 1.41 times the circular orbital velocity.\n",
      "Generated: [{'id': 'cmpl-30cb7fa5-8aa7-47e8-96ff-94436fb918a0', 'object': 'text_completion', 'created': 1731332799, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe escape velocity equation in a circular orbit relates to the circular orb', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 175, 'completion_tokens': 16, 'total_tokens': 191}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    7189.19 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   200 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9320.75 ms /   215 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the formula for calculating the Schwarzschild radius of a black hole, and what constants does it involve?\n",
      "Correct: The Schwarzschild radius of a black hole is calculated using the formula 2GM/c^2, where G is Newton's gravitational constant, M is the mass of the black hole, and c is the speed of light.\n",
      "Generated: [{'id': 'cmpl-fa61261e-6051-4dea-9f2b-560ad92ddf44', 'object': 'text_completion', 'created': 1731332808, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': \"}, {'id': 'id_680', 'distance': 8\", 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 200, 'completion_tokens': 16, 'total_tokens': 216}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    6979.12 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   196 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9344.47 ms /   211 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Where are the Saturn V blueprints kept, and what is the main challenge in recreating the rocket?\n",
      "Correct: The Saturn V blueprints are kept at the Marshall Space Flight Center on microfilm. The main challenge in recreating the rocket is not finding the drawings, but sourcing 1960s-era hardware, such as guidance components, and the fact that launch facilities have been modified for the Space Shuttle.\n",
      "Generated: [{'id': 'cmpl-074a9860-ae45-4231-9316-b7da24782069', 'object': 'text_completion', 'created': 1731332818, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe Saturn V blueprints are kept at the NASA John H.', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 196, 'completion_tokens': 16, 'total_tokens': 212}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    6794.51 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   191 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9169.47 ms /   206 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Why isn't data from space missions immediately available to the public after collection?\n",
      "Correct: NASA allows mission investigators exclusive access to data for one year after it's collected, giving them a chance to analyze and publish their results without competition. However, NASA often releases sample photos to the public early in a mission.\n",
      "Generated: [{'id': 'cmpl-5daf5e89-a273-444b-bffa-fb86f5bf6437', 'object': 'text_completion', 'created': 1731332828, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe question is \"Why isn\\'t data from space missions immediately available', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 191, 'completion_tokens': 16, 'total_tokens': 207}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    4090.58 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   112 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    4090.82 ms /   113 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the estimated environmental impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer?\n",
      "Correct: The impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer is minimal, contributing less than 0.25% of total stratospheric chlorine sources. The effect on global ozone levels is estimated to be a decrease of only 0.0065%.\n",
      "Generated: [{'id': 'cmpl-071530df-14fd-46d3-abca-3ec2d846f949', 'object': 'text_completion', 'created': 1731332838, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 0, 'total_tokens': 112}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    6153.38 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   173 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    6153.57 ms /   174 tokens\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from ../assets/models/mistral-7b-openorca.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 5\n",
      "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32002\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOG token        = 32000 '<dummy32000>'\n",
      "llm_load_print_meta: max token length = 48\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What risks are associated with nuclear (RTG) power sources on space probes, and what evidence exists about their safety?\n",
      "Correct: Studies suggest that risks from nuclear RTG power sources on space probes are very low, even in worst-case scenarios, such as launch failures or reentry. For example, in 1968, two RTGs were recovered intact after a satellite failure, and in 1970, the Apollo 13 RTG fell into the ocean and remains safely contained.\n",
      "Generated: [{'id': 'cmpl-21d2b951-1885-443b-b8ed-118f229ec4f1', 'object': 'text_completion', 'created': 1731332843, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 173, 'completion_tokens': 0, 'total_tokens': 173}}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  4165.38 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2016\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   252.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  252.00 MiB, K (f16):  126.00 MiB, V (f16):  126.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   161.94 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'general.name': 'open-orca_mistral-7b-openorca', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n",
      "llama_perf_context_print:        load time =    5933.08 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /   166 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    8060.95 ms /   181 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Why can't the Space Shuttle be used for missions beyond low Earth orbit?\n",
      "Correct: The Space Shuttle cannot be used for missions beyond low Earth orbit because it lacks sufficient fuel and is not designed for such missions. Its wings and other structural features are only useful near Earth, making it inefficient and costly for higher orbits.\n",
      "Generated: [{'id': 'cmpl-e121189d-806f-49f5-b062-1574b3f0dc48', 'object': 'text_completion', 'created': 1731332850, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe Space Shuttle was designed for specific missions and could not be', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 166, 'completion_tokens': 16, 'total_tokens': 182}}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Нужно написать эксперимент для генерации текста (ответа на вопрос) с помощью функции generate\n",
    "model_file=\"../assets/models/mistral-7b-openorca.Q4_K_M.gguf\" \n",
    "\n",
    "dataset = Dataset([\n",
    "    QuestionAndAnswers(\n",
    "        question='How does Tom Van Flandern view the concept of \"dark matter\" and other unobservable phenomena in physics?',\n",
    "        correct_answer='Tom Van Flandern is skeptical of \"dark matter\" and other unobservable, purely theoretical constructs in physics, such as quarks and black holes. He questions whether their existence can be inferred solely from theory, suggesting that existence should be tied to observability.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the main point of disagreement between Tom Van Flandern and Bruce Scott on the concept of existence in physics?',\n",
    "        correct_answer='The main disagreement is that Bruce Scott argues \"existence\" should be synonymous with \"observable\" in physics, while Van Flandern challenges this view, particularly when considering phenomena like curvature, which he argues cannot exist without something \"non-curved\" to compare it to.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='According to Nikola Tesla, why does he believe that space cannot be curved?',\n",
    "        correct_answer='Nikola Tesla argues that space cannot be curved because it has no properties on its own. He believes properties only apply to matter within space, and saying that large bodies curve space implies \"something can act upon nothing,\" a view he does not support.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the escape velocity equation in a circular orbit, and how does it relate to circular orbital velocity?',\n",
    "        correct_answer=' The escape velocity Vesc in a circular orbit is given by the equation Vesc = sqrt(2 * M * G / r) = sqrt(2) * Vс  is the circular orbital velocity. This means the escape velocity is approximately 1.41 times the circular orbital velocity.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the formula for calculating the Schwarzschild radius of a black hole, and what constants does it involve?',\n",
    "        correct_answer=\"The Schwarzschild radius of a black hole is calculated using the formula 2GM/c^2, where G is Newton's gravitational constant, M is the mass of the black hole, and c is the speed of light.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='Where are the Saturn V blueprints kept, and what is the main challenge in recreating the rocket?',\n",
    "        correct_answer='The Saturn V blueprints are kept at the Marshall Space Flight Center on microfilm. The main challenge in recreating the rocket is not finding the drawings, but sourcing 1960s-era hardware, such as guidance components, and the fact that launch facilities have been modified for the Space Shuttle.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"Why isn't data from space missions immediately available to the public after collection?\",\n",
    "        correct_answer=\"NASA allows mission investigators exclusive access to data for one year after it's collected, giving them a chance to analyze and publish their results without competition. However, NASA often releases sample photos to the public early in a mission.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"What is the estimated environmental impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer?\",\n",
    "        correct_answer=\"The impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer is minimal, contributing less than 0.25% of total stratospheric chlorine sources. The effect on global ozone levels is estimated to be a decrease of only 0.0065%.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What risks are associated with nuclear (RTG) power sources on space probes, and what evidence exists about their safety?',\n",
    "        correct_answer='Studies suggest that risks from nuclear RTG power sources on space probes are very low, even in worst-case scenarios, such as launch failures or reentry. For example, in 1968, two RTGs were recovered intact after a satellite failure, and in 1970, the Apollo 13 RTG fell into the ocean and remains safely contained.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"Why can't the Space Shuttle be used for missions beyond low Earth orbit?\",\n",
    "        correct_answer='The Space Shuttle cannot be used for missions beyond low Earth orbit because it lacks sufficient fuel and is not designed for such missions. Its wings and other structural features are only useful near Earth, making it inefficient and costly for higher orbits.'\n",
    "        ),\n",
    "])\n",
    "\n",
    "for qa in dataset.qa_list:\n",
    "  context = collector.get([qa.question], n_results=1)\n",
    "  qa.prompt = get_prompt(qa.question, context)\n",
    "\n",
    "  qa.generated_answer = generate(model_file, [qa.prompt])\n",
    "  print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q: How does Tom Van Flandern view the concept of \"dark matter\" and other unobservable phenomena in physics?\n",
      "Correct: Tom Van Flandern is skeptical of \"dark matter\" and other unobservable, purely theoretical constructs in physics, such as quarks and black holes. He questions whether their existence can be inferred solely from theory, suggesting that existence should be tied to observability.\n",
      "Generated: [{'id': 'cmpl-a39197a4-40ba-4d4a-a529-98120f6d4025', 'object': 'text_completion', 'created': 1731332776, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 110, 'completion_tokens': 0, 'total_tokens': 110}}]\n",
      ", Q: What is the main point of disagreement between Tom Van Flandern and Bruce Scott on the concept of existence in physics?\n",
      "Correct: The main disagreement is that Bruce Scott argues \"existence\" should be synonymous with \"observable\" in physics, while Van Flandern challenges this view, particularly when considering phenomena like curvature, which he argues cannot exist without something \"non-curved\" to compare it to.\n",
      "Generated: [{'id': 'cmpl-d9619140-4f95-4a3e-9f46-2c754f690085', 'object': 'text_completion', 'created': 1731332781, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 200, 'completion_tokens': 0, 'total_tokens': 200}}]\n",
      ", Q: According to Nikola Tesla, why does he believe that space cannot be curved?\n",
      "Correct: Nikola Tesla argues that space cannot be curved because it has no properties on its own. He believes properties only apply to matter within space, and saying that large bodies curve space implies \"something can act upon nothing,\" a view he does not support.\n",
      "Generated: [{'id': 'cmpl-95d1e8f8-e349-47ff-b4f5-6db699340b79', 'object': 'text_completion', 'created': 1731332789, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nAnswer: Nikola Tesla believes that space cannot be curved', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 187, 'completion_tokens': 16, 'total_tokens': 203}}]\n",
      ", Q: What is the escape velocity equation in a circular orbit, and how does it relate to circular orbital velocity?\n",
      "Correct:  The escape velocity Vesc in a circular orbit is given by the equation Vesc = sqrt(2 * M * G / r) = sqrt(2) * Vс  is the circular orbital velocity. This means the escape velocity is approximately 1.41 times the circular orbital velocity.\n",
      "Generated: [{'id': 'cmpl-30cb7fa5-8aa7-47e8-96ff-94436fb918a0', 'object': 'text_completion', 'created': 1731332799, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe escape velocity equation in a circular orbit relates to the circular orb', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 175, 'completion_tokens': 16, 'total_tokens': 191}}]\n",
      ", Q: What is the formula for calculating the Schwarzschild radius of a black hole, and what constants does it involve?\n",
      "Correct: The Schwarzschild radius of a black hole is calculated using the formula 2GM/c^2, where G is Newton's gravitational constant, M is the mass of the black hole, and c is the speed of light.\n",
      "Generated: [{'id': 'cmpl-fa61261e-6051-4dea-9f2b-560ad92ddf44', 'object': 'text_completion', 'created': 1731332808, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': \"}, {'id': 'id_680', 'distance': 8\", 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 200, 'completion_tokens': 16, 'total_tokens': 216}}]\n",
      ", Q: Where are the Saturn V blueprints kept, and what is the main challenge in recreating the rocket?\n",
      "Correct: The Saturn V blueprints are kept at the Marshall Space Flight Center on microfilm. The main challenge in recreating the rocket is not finding the drawings, but sourcing 1960s-era hardware, such as guidance components, and the fact that launch facilities have been modified for the Space Shuttle.\n",
      "Generated: [{'id': 'cmpl-074a9860-ae45-4231-9316-b7da24782069', 'object': 'text_completion', 'created': 1731332818, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe Saturn V blueprints are kept at the NASA John H.', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 196, 'completion_tokens': 16, 'total_tokens': 212}}]\n",
      ", Q: Why isn't data from space missions immediately available to the public after collection?\n",
      "Correct: NASA allows mission investigators exclusive access to data for one year after it's collected, giving them a chance to analyze and publish their results without competition. However, NASA often releases sample photos to the public early in a mission.\n",
      "Generated: [{'id': 'cmpl-5daf5e89-a273-444b-bffa-fb86f5bf6437', 'object': 'text_completion', 'created': 1731332828, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe question is \"Why isn\\'t data from space missions immediately available', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 191, 'completion_tokens': 16, 'total_tokens': 207}}]\n",
      ", Q: What is the estimated environmental impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer?\n",
      "Correct: The impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer is minimal, contributing less than 0.25% of total stratospheric chlorine sources. The effect on global ozone levels is estimated to be a decrease of only 0.0065%.\n",
      "Generated: [{'id': 'cmpl-071530df-14fd-46d3-abca-3ec2d846f949', 'object': 'text_completion', 'created': 1731332838, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 112, 'completion_tokens': 0, 'total_tokens': 112}}]\n",
      ", Q: What risks are associated with nuclear (RTG) power sources on space probes, and what evidence exists about their safety?\n",
      "Correct: Studies suggest that risks from nuclear RTG power sources on space probes are very low, even in worst-case scenarios, such as launch failures or reentry. For example, in 1968, two RTGs were recovered intact after a satellite failure, and in 1970, the Apollo 13 RTG fell into the ocean and remains safely contained.\n",
      "Generated: [{'id': 'cmpl-21d2b951-1885-443b-b8ed-118f229ec4f1', 'object': 'text_completion', 'created': 1731332843, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 173, 'completion_tokens': 0, 'total_tokens': 173}}]\n",
      ", Q: Why can't the Space Shuttle be used for missions beyond low Earth orbit?\n",
      "Correct: The Space Shuttle cannot be used for missions beyond low Earth orbit because it lacks sufficient fuel and is not designed for such missions. Its wings and other structural features are only useful near Earth, making it inefficient and costly for higher orbits.\n",
      "Generated: [{'id': 'cmpl-e121189d-806f-49f5-b062-1574b3f0dc48', 'object': 'text_completion', 'created': 1731332850, 'model': '../assets/models/mistral-7b-openorca.Q4_K_M.gguf', 'choices': [{'text': '\\n\\nThe Space Shuttle was designed for specific missions and could not be', 'index': 0, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 166, 'completion_tokens': 16, 'total_tokens': 182}}]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.qa_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1BChqg7McMG"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6x44JDLMees"
   },
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from typing import List\n",
    "\n",
    "class BERTScoreEvaluator:\n",
    "    # Класс для оценки качества сгенерированных ответов с использованием метрики BERTScore.\n",
    "    def __init__(self, model_type='distilbert-base-uncased'):\n",
    "        self.model_type = model_type\n",
    "    \n",
    "    def evaluate(self, reference: str, generated: str):\n",
    "        P, R, F1 = bert_score.score([generated], [reference], model_type=self.model_type)\n",
    "        return {\n",
    "            'precision': P.item(),\n",
    "            'recall': R.item(),\n",
    "            'f1': F1.item()\n",
    "        }\n",
    "\n",
    "    def evaluate_dataset(self, dataset: Dataset):\n",
    "        references = [qa.correct_answer for qa in dataset.qa_list]\n",
    "        generated_answers = [qa.generated_answer[0]['choices'][0]['text'] for qa in dataset.qa_list]\n",
    "\n",
    "        print(references)\n",
    "        print(generated_answers)\n",
    "\n",
    "        P, R, F1 = bert_score.score(generated_answers, references, model_type=self.model_type)\n",
    "        return {\n",
    "            'precision_mean': P.mean().item(),\n",
    "            'recall_mean': R.mean().item(),\n",
    "            'f1_mean': F1.mean().item()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "hKy4eQt6MkNW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tom Van Flandern is skeptical of \"dark matter\" and other unobservable, purely theoretical constructs in physics, such as quarks and black holes. He questions whether their existence can be inferred solely from theory, suggesting that existence should be tied to observability.', 'The main disagreement is that Bruce Scott argues \"existence\" should be synonymous with \"observable\" in physics, while Van Flandern challenges this view, particularly when considering phenomena like curvature, which he argues cannot exist without something \"non-curved\" to compare it to.', 'Nikola Tesla argues that space cannot be curved because it has no properties on its own. He believes properties only apply to matter within space, and saying that large bodies curve space implies \"something can act upon nothing,\" a view he does not support.', ' The escape velocity Vesc in a circular orbit is given by the equation Vesc = sqrt(2 * M * G / r) = sqrt(2) * Vс  is the circular orbital velocity. This means the escape velocity is approximately 1.41 times the circular orbital velocity.', \"The Schwarzschild radius of a black hole is calculated using the formula 2GM/c^2, where G is Newton's gravitational constant, M is the mass of the black hole, and c is the speed of light.\", 'The Saturn V blueprints are kept at the Marshall Space Flight Center on microfilm. The main challenge in recreating the rocket is not finding the drawings, but sourcing 1960s-era hardware, such as guidance components, and the fact that launch facilities have been modified for the Space Shuttle.', \"NASA allows mission investigators exclusive access to data for one year after it's collected, giving them a chance to analyze and publish their results without competition. However, NASA often releases sample photos to the public early in a mission.\", \"The impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer is minimal, contributing less than 0.25% of total stratospheric chlorine sources. The effect on global ozone levels is estimated to be a decrease of only 0.0065%.\", 'Studies suggest that risks from nuclear RTG power sources on space probes are very low, even in worst-case scenarios, such as launch failures or reentry. For example, in 1968, two RTGs were recovered intact after a satellite failure, and in 1970, the Apollo 13 RTG fell into the ocean and remains safely contained.', 'The Space Shuttle cannot be used for missions beyond low Earth orbit because it lacks sufficient fuel and is not designed for such missions. Its wings and other structural features are only useful near Earth, making it inefficient and costly for higher orbits.']\n",
      "['', '', '\\n\\nAnswer: Nikola Tesla believes that space cannot be curved', '\\n\\nThe escape velocity equation in a circular orbit relates to the circular orb', \"}, {'id': 'id_680', 'distance': 8\", '\\n\\nThe Saturn V blueprints are kept at the NASA John H.', '\\n\\nThe question is \"Why isn\\'t data from space missions immediately available', '', '', '\\n\\nThe Space Shuttle was designed for specific missions and could not be']\n",
      "{'precision_mean': 0.4940720200538635, 'recall_mean': 0.44898539781570435, 'f1_mean': 0.46996575593948364}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "#Нужно написать эксперимент для оценки сгенерированых ответов\n",
    "bertScoreEvaluator = BERTScoreEvaluator()\n",
    "\n",
    "bert_result = bertScoreEvaluator.evaluate_dataset(dataset)\n",
    "print(bert_result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "085e9c2a2c434c2fab31c2badd6b376a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18ad54a26ec5426ba16b2ad98945327f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b99c29b7c4049a0bb911b2024f4d9aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "347f07adeea34cdda852df42b897f0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45dd02511b76415b82ba3485cca6bcfc",
      "placeholder": "​",
      "style": "IPY_MODEL_18ad54a26ec5426ba16b2ad98945327f",
      "value": " 1/1 [00:00&lt;00:00, 52.74it/s]"
     }
    },
    "36ed2223fae948abbeebbbc6ff04ac75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dc563a7806448bb89b40592d8f02ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45dd02511b76415b82ba3485cca6bcfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49bf9f0bf07b4b9f820913d30a092cae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b56b69baff44d24bc9b80f30ec5f245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "754bf2b59aa94eb9840fbd655cfd5820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7981a4114e824bcd85d896fe2a261721": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87a7758349104798b8eabaf4036b6916": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "941962a50b6b4cf19f0962e7c1d3f748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_754bf2b59aa94eb9840fbd655cfd5820",
      "placeholder": "​",
      "style": "IPY_MODEL_fc55fd2dd6dd4915b30029ff1bce0a06",
      "value": "Fetching 1 files: 100%"
     }
    },
    "e013a4bc5377482489efae4adbbc1ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7750855102c428e8d86079f10759d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87a7758349104798b8eabaf4036b6916",
      "placeholder": "​",
      "style": "IPY_MODEL_5b56b69baff44d24bc9b80f30ec5f245",
      "value": "Fetching 1 files: 100%"
     }
    },
    "e93b3899edc041ac8f7a8039d9e8fa52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7750855102c428e8d86079f10759d4d",
       "IPY_MODEL_fe6cd592a4cb44299974814803d64dca",
       "IPY_MODEL_f59614bafd17423eb0f28b0cf0404b50"
      ],
      "layout": "IPY_MODEL_2b99c29b7c4049a0bb911b2024f4d9aa"
     }
    },
    "f181fe130cb7439ca599c999333457d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_085e9c2a2c434c2fab31c2badd6b376a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dc563a7806448bb89b40592d8f02ab4",
      "value": 1
     }
    },
    "f4234ab97f4a4d94a76940170b4c0386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_941962a50b6b4cf19f0962e7c1d3f748",
       "IPY_MODEL_f181fe130cb7439ca599c999333457d1",
       "IPY_MODEL_347f07adeea34cdda852df42b897f0ba"
      ],
      "layout": "IPY_MODEL_7981a4114e824bcd85d896fe2a261721"
     }
    },
    "f59614bafd17423eb0f28b0cf0404b50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49bf9f0bf07b4b9f820913d30a092cae",
      "placeholder": "​",
      "style": "IPY_MODEL_f5dc20348ea340bdb636342351ae5d4e",
      "value": " 1/1 [00:00&lt;00:00, 49.66it/s]"
     }
    },
    "f5dc20348ea340bdb636342351ae5d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc55fd2dd6dd4915b30029ff1bce0a06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe6cd592a4cb44299974814803d64dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36ed2223fae948abbeebbbc6ff04ac75",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e013a4bc5377482489efae4adbbc1ea7",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
